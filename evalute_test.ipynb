{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\vllm\\lib\\site-packages\\deepeval\\__init__.py:41: UserWarning: You are using deepeval version 0.21.27, however version 0.21.36 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json,re,os,datetime,time,string\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from langchain.llms.base import LLM\n",
    "from typing import *\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "import traceback,random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evalplus.sanitize,evalplus.syncheck\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnionFind:\n",
    "    def __init__(self,n):\n",
    "        self.n = n\n",
    "        self.parent = [i for i in range(n)]\n",
    "        self.size = n\n",
    "        self.keyset = [1]*n\n",
    "    def find(self,x):\n",
    "        if self.parent[x]!= x:\n",
    "            self.parent[x] = self.find(self.parent[x])\n",
    "        return self.parent[x]\n",
    "    \n",
    "    def union(self,x,y):\n",
    "        x = self.find(x)\n",
    "        y = self.find(y)\n",
    "        if x == y:\n",
    "            return False\n",
    "        if self.keyset[x] < self.keyset[y]:\n",
    "            x,y = y,x\n",
    "        self.parent[y] = x\n",
    "        self.keyset[x] += self.keyset[y]\n",
    "        self.size -= 1\n",
    "        return True\n",
    "    \n",
    "    def is_connected(self,x,y):\n",
    "        return self.find(x) == self.find(y)\n",
    "    def get_size(self,x):\n",
    "        return self.keyset[self.find(x)]\n",
    "    def get_size_all(self):\n",
    "        return self.size\n",
    "    \n",
    "def merge_same_item(file_path:Union[str,Path]):\n",
    "    def is_same_eval_item(x,item):\n",
    "        if x['id'] == item['id'] and  x['AnswerModel'] == item['AnswerModel'] :\n",
    "            return True\n",
    "        return False\n",
    "    with open(file_path,'r') as f:\n",
    "        data = json.load(f)\n",
    "    check = []\n",
    "    for item in data['data']:\n",
    "        if len(item[\"cached_metrics_data\"]) <2:\n",
    "            check.append(item)\n",
    "    check.sort(key=lambda x:(x['id'],x['AnswerModel']))\n",
    "    uf = UnionFind(len(check))\n",
    "    for i in range(len(check)):\n",
    "        for j in range(i+1,len(check)):\n",
    "            if is_same_eval_item(check[i],check[j]):\n",
    "                uf.union(i,j)\n",
    "    key_set = defaultdict(list)\n",
    "    for i in range(len(check)):\n",
    "        p = uf.find(i)\n",
    "        key_set[p].append(check[i])\n",
    "        \n",
    "    mergeList =  list(key_set.values())\n",
    "    for item in mergeList[:]:\n",
    "        if len(item)<2:\n",
    "            mergeList.remove(item)\n",
    "    for x,y in mergeList:\n",
    "        mergeItem = x.copy()\n",
    "        mergeItem['cached_metrics_data'].append(y['cached_metrics_data'][0])\n",
    "        data['data'].remove(x)\n",
    "        data['data'].remove(y)\n",
    "        data['data'].append(mergeItem)\n",
    "    with open(file_path,'w') as f:\n",
    "        json.dump(data,f,indent=4)\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data\\\\KoLA\\\\3-4_kqapro_sample.json') as f:\n",
    "#     data = json.load(f)\n",
    "# for i,item in enumerate(data['data']):\n",
    "#     item['id'] = \"%04d\"%i\n",
    "# with open('data\\\\KoLA\\\\3-4_kqapro_sample.json','w') as f:\n",
    "#     json.dump(data,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_same_eval_item(x,item):\n",
    "#     if   x['AnswerModel'] == item['AnswerModel'] and x[\"input\"] == item[\"input\"] and x[\"expected_output\"] == item[\"expected_output\"]:\n",
    "#         return True\n",
    "#     return False\n",
    "# with open('data\\\\KoLA\\\\3-4_kqapro_sample.json') as f:\n",
    "#     data_0 = json.load(f)\n",
    "# exFile ='KoLA\\\\data\\\\3-4_kqapro_sample.json' #'eval\\\\error\\\\3-4_kqapro_sample.json','eval\\\\save\\\\3-4_kqapro_sample.json'\n",
    "# with open(exFile) as f:\n",
    "#     data = json.load(f)\n",
    "# for item in data['data']:\n",
    "#     for std in data_0['data']:\n",
    "#         if is_same_eval_item(item,std):\n",
    "#             item['id'] = std['id']\n",
    "#             break\n",
    "# with open(exFile,'w') as f:\n",
    "#     json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir,subdir,files in os.walk('./eval/save'):\n",
    "    for file in files:\n",
    "        merge_same_item('./eval/save/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = {'fileName':\"math401.json\",'data':[]}\n",
    "# with open('E:/Repository/math401-llm-main/math401.json') as file:\n",
    "#     for line in file:\n",
    "#         data = json.loads(line)\n",
    "#         text = data['query']\n",
    "#         if '**' in text:\n",
    "#             text = text.replace('**','^')\n",
    "#         item = {'input':text,'expected_output':data['response']}\n",
    "#         question['data'].append(item.copy())\n",
    "# with open('./data/math401/math401.json','w') as file:\n",
    "#     json.dump(question,file,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFINI_API_List = [\"sk-c7cssl4bkglsrwf2\", \"sk-c7erk6qaqhkz5t72\",\"sk-c7etq7veyeie4dn2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelList = [\n",
    "    'llama-3-70b-instruct',\n",
    "    'llama-3-8b-instruct',\n",
    "    'chatglm3',\n",
    "    'chatglm2-6b',\n",
    "    'chatglm2-6b-32k',\n",
    "    'infini-megrez-7b',\n",
    "    'llama-2-7b-chat',\n",
    "    'llama-2-13b-chat',\n",
    "    'llama-2-70b-chat',\n",
    "    'llama-2-70b',\n",
    "    'baichuan2-7b-chat',\n",
    "    'baichuan2-13b-chat',\n",
    "    'baichuan2-13b-base',\n",
    "    'chatglm3-6b',\n",
    "    'chatglm3-6b-32k',\n",
    "    'chatglm3-6b-base',\n",
    "    'qwen-7b-chat',\n",
    "    'qwen-14b-chat',\n",
    "    'qwen-72b-chat',\n",
    "    'qwen-72b',\n",
    "    'qwen1.5-7b-chat',\n",
    "    'qwen1.5-14b-chat',\n",
    "    'qwen1.5-72b-chat',\n",
    "    'qwen1.5-72b',\n",
    "]\n",
    "evaluateModelList = ['llama-3-70b-instruct','qwen1.5-72b-chat',]\n",
    "answerModelList = [    \n",
    "    # 'llama-3-8b-instruct',\n",
    "    # 'chatglm3',\n",
    "    # 'chatglm2-6b',\n",
    "    # 'chatglm2-6b-32k',\n",
    "    'infini-megrez-7b',    \n",
    "    'baichuan2-7b-chat',\n",
    "    'baichuan2-13b-chat',\n",
    "    'baichuan2-13b-base',\n",
    "    # 'chatglm3-6b',\n",
    "    # 'chatglm3-6b-32k',\n",
    "    # 'chatglm3-6b-base',\n",
    "    'qwen-7b-chat',\n",
    "    'qwen-14b-chat',\n",
    "    'qwen-72b-chat',\n",
    "    'qwen-72b',\n",
    "    'qwen1.5-7b-chat',\n",
    "    'qwen1.5-14b-chat',\n",
    "    'qwen1.5-72b',#\n",
    "    # 'llama-2-70b-chat',#\n",
    "    'llama-2-70b',\n",
    "    'llama-2-7b-chat',\n",
    "    'llama-2-13b-chat',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01HX3RDG509PBR22TFAE82YS0V",
   "metadata": {},
   "source": [
    "# KoLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3RE3KJKBWVCCYFX0JD324A",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledgeList = ['Knowledge Memorization','Knowledge Understanding','Knowledge Applying','Knowledge Creating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "def LLMCompletions(prompt,modelName:str = \"infini-megrez-7b\",INFINI_API_List = [\"sk-c7cssl4bkglsrwf2\", \"sk-c7erk6qaqhkz5t72\",\"sk-c7etq7veyeie4dn2\"],returnContent:bool = True,**kwargs):\n",
    "    global index\n",
    "    url = \"https://cloud.infini-ai.com/maas/\"+modelName+\"/nvidia/chat/completions\"\n",
    "    payload = {\n",
    "        \"model\": modelName,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"temperature\": kwargs[\"temperature\"] if \"temperature\" in kwargs else 0.7,\n",
    "        \"top_p\": kwargs[\"top_p\"] if 'top_p' in kwargs else 1,\n",
    "        \"top_k\": kwargs['top_k'] if 'top_k' in kwargs else -1,\n",
    "        \"n\": kwargs['n'] if 'n' in kwargs else 1,\n",
    "        \"max_tokens\": kwargs['max_tokens'] if 'max_tokens' in kwargs else None,\n",
    "        \"stop\": kwargs['stop'] if 'stop' in kwargs else None,\n",
    "        \"presence_penalty\": kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else 0,\n",
    "        \"frequency_penalty\": kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else 0\n",
    "    }\n",
    "    idx = 0\n",
    "    while idx < len(INFINI_API_List):\n",
    "        headers = {\n",
    "                'Content-Type': \"application/json\",\n",
    "                'Accept': \"*/*\",\n",
    "                'Authorization': \"Bearer \"+INFINI_API_List[index%len(INFINI_API_List)],\n",
    "        } \n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            response.encoding = 'utf-8'\n",
    "            data = response.json()\n",
    "            content = data['choices'][0]['message']['content']\n",
    "            if isinstance(content,str):\n",
    "                content = content.replace(',\\n}','\\n}')\n",
    "                content = content.replace(']\\n}',']}')\n",
    "                content = content.replace('\\\\','\\\\\\\\')\n",
    "            if returnContent:\n",
    "                return content\n",
    "            try:\n",
    "                content = json.loads(content)\n",
    "            except:\n",
    "                pass\n",
    "            data['choices'][0]['message']['content'] = content\n",
    "            if isinstance(content,str):\n",
    "                return content\n",
    "            \n",
    "            return json.dumps(data['choices'][0]['message']['content'])\n",
    "        else:\n",
    "            print(response.status_code)\n",
    "            try:\n",
    "                print(response.json())\n",
    "            except:\n",
    "                pass\n",
    "        index = (index + 1) % len(INFINI_API_List)\n",
    "        idx += 1\n",
    "    return \"Cannot connect to the model \"+modelName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format = {\n",
    "    'id':0,\n",
    "    'AnswerModel':'',\n",
    "    'input':'',\n",
    "    'actual_output':'',\n",
    "    'expected_output':None,\n",
    "    'retrieval_context':None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3RYHNDN6RBVCB03F8GKK1M",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KoLA\n",
    "data_format_ins = {\n",
    "    'id':0,\n",
    "    'AnswerModel':'',\n",
    "    'input':'',\n",
    "    'actual_output':'',\n",
    "    'expected_output':None,\n",
    "    'retrieval_context':None,\n",
    "    'time':-1\n",
    "}\n",
    "def get_LLM_Reply_KoLA(filepath,savePath,errorPath,fileName = None,):\n",
    "    with open(filepath) as f:\n",
    "        data = json.load(f)\n",
    "    instructions = data['adapter_spec']['instructions']\n",
    "    questionList = data['request_states']\n",
    "    errorItem = []\n",
    "    if not fileName:\n",
    "        fileName = Path(filepath).name\n",
    "    save = {'fileName':fileName,'class':knowledgeList[int(fileName[0])-1],'data':[]}\n",
    "    for index,item in enumerate(questionList):\n",
    "        if 'id' in item['instance']:\n",
    "            data_format_ins['id'] = item['instance']['id']\n",
    "        else:\n",
    "            data_format_ins['id'] = fileName+'%04d'% index\n",
    "        prompt = instructions+'\\n'+item['instance']['input']['text']\n",
    "        data_format_ins['input'] = prompt\n",
    "        print(prompt)\n",
    "        if item['instance']['references'][0]['tags'][0] == 'correct':\n",
    "            data_format_ins['expected_output'] = item['instance']['references'][0]['output']['text']\n",
    "        else:\n",
    "            data_format_ins['expected_output'] = None\n",
    "        for model in answerModelList:\n",
    "            data_format_ins['AnswerModel'] = model\n",
    "            print(model)\n",
    "            start = time.perf_counter_ns()\n",
    "            actual_output =  LLMCompletions(prompt,modelName=model)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = end-start\n",
    "            idx = 0\n",
    "            while actual_output == \"Cannot connect to the model \"+model and idx<2:\n",
    "                start = time.perf_counter_ns()\n",
    "                actual_output =  LLMCompletions(prompt,modelName=model)\n",
    "                end = time.perf_counter_ns()\n",
    "                delta = end-start\n",
    "                idx += 1\n",
    "            if actual_output == \"Cannot connect to the model \"+model:\n",
    "                \n",
    "                errorItem.append({'fileName':fileName,'id':data_format_ins['id'],\"AnswerModel\":model,\"input\":prompt,\"expected_output\":data_format_ins['expected_output']})\n",
    "                continue\n",
    "            print(idx,delta,actual_output,sep='\\t')\n",
    "            data_format_ins['actual_output'] = actual_output\n",
    "            data_format_ins['time'] = delta\n",
    "            save['data'].append(data_format_ins.copy())\n",
    "            print('*'*70)\n",
    "        print('+'*70)\n",
    "    errorItemFinal = []\n",
    "    while errorItem:\n",
    "        item = errorItem.pop()\n",
    "        data_format_ins['id'] = item['id']\n",
    "        model = item['AnswerModel']\n",
    "        data_format_ins['AnswerModel'] = model\n",
    "        prompt = item['input']\n",
    "        data_format_ins['input'] = prompt\n",
    "        data_format_ins['expected_output'] = item['expected_output']\n",
    "        start = time.perf_counter_ns()\n",
    "        actual_output =  LLMCompletions(prompt,modelName=model)\n",
    "        end = time.perf_counter_ns()\n",
    "        delta = end-start\n",
    "        idx = 0\n",
    "        while actual_output == \"Cannot connect to the model \"+model and idx<2:\n",
    "            print('\\t'+str(idx)+'\\ttest')\n",
    "            start = time.perf_counter_ns()\n",
    "            actual_output =  LLMCompletions(prompt,modelName=model)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = end-start\n",
    "            idx += 1\n",
    "        if actual_output == \"Cannot connect to the model \"+model:\n",
    "            errorItemFinal.append(item)\n",
    "            print(\"[error]:\\t\"+str(errorItemFinal[-1]))\n",
    "            continue\n",
    "        print(idx,delta,actual_output,sep='\\t')\n",
    "        data_format_ins['actual_output'] = actual_output\n",
    "        data_format_ins['time'] = delta\n",
    "        save['data'].append(data_format_ins.copy())\n",
    "    with open(savePath,'w',encoding='utf-8') as out:\n",
    "        json.dump(save,out)\n",
    "    if errorItemFinal:\n",
    "        error = {'fileName':fileName,'class':knowledgeList[int(fileName[0])-1],'data':[]}\n",
    "        for i in errorItemFinal:\n",
    "            error['data'].append(i)\n",
    "        with open(errorPath,'w',encoding='utf-8') as out:\n",
    "            json.dump(error,out)\n",
    "    print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3S27ZKEB6474KDACZGGN45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirName,subDirName,fileNames in os.walk('E:\\\\Repository\\\\KoLA\\\\Sample_Data'):\n",
    "    print(fileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3S2F4DYNE8ZFBK9P0YXA1R",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/4-2_r_with_triples_sample.json') as f:\n",
    "    data_view = json.load(f)\n",
    "len(data_view['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3S2HSB3GYEZBAZ37JMX728",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames =['1-1_2_high_freq_ent_sample.json', '1-2_1_low_freq_ent_sample.json', '1-3_r_1_simple_sample_sample.json', '2-1_COPEN++csj_sample.json', '2-2_COPEN++cpj_sample.json', '2-3_COPEN++cic_sample.json', '2-4_FewNERD++inter_sample.json', '2-4_FewNERD++intra_sample.json', '2-4_FewNERD++supervised_sample.json', '2-5_DocRED_sample.json', '2-6_MAVEN_sample.json', '2-7_MAVEN-ERE_sample.json', '2-8_r_DocRED_sample.json', '3-1_hotpotqa_sample.json', '3-2_2wikimultihopqa_sample.json', '3-3_musique_sample.json', '3-4_kqapro_sample.json', '3-5_KoRC++ood_sample.json', '3-6_r_KoRC++ood_sample.json', '4-1_without_triples_sample.json', '4-1_with_triples_sample.json', '4-2_r_without_triples_sample.json', '4-2_r_with_triples_sample.json']\n",
    "dirName = 'E:/Repository/KoLA/Sample_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3S2MK8JCX3T5SA8EWRK7HA",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileName in fileNames:\n",
    "    get_LLM_Reply_KoLA(os.path.join(dirName, fileName),'./data/'+fileName,'./data/'+fileName.replace(\".json\",\"\")+'Error'+'.json',fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MATH\n",
    "def get_LLM_Reply_MATH(filepath,savePath,errorPath):\n",
    "    with open(filepath) as f:\n",
    "        data = json.load(f)\n",
    "    questionList = data['data']\n",
    "    instructions = 'Only return the correct answer of the question.\\n'\n",
    "    for model in answerModelList:\n",
    "        error = {'fileName':model.title()+'.json','model':model,'data':[]}\n",
    "        save = {'fileName':model.title()+'.json','model':model,'data':[]}\n",
    "        for index,item in enumerate(questionList):\n",
    "            data_format_ins = {\n",
    "                'id':0,\n",
    "                'AnswerModel':'',\n",
    "                'input':'',\n",
    "                'actual_output':'',\n",
    "                'expected_output':None,\n",
    "                'is_correct':-1,\n",
    "                'time':-1\n",
    "            }\n",
    "            if 'id' in item:\n",
    "                data_format_ins['id'] = item['id']\n",
    "            else:\n",
    "                data_format_ins['id'] = model+'-%04d'% index\n",
    "            prompt = instructions+item['input']\n",
    "            data_format_ins['input'] = prompt\n",
    "            print(prompt)\n",
    "            data_format_ins['expected_output'] = item['expected_output']\n",
    "            data_format_ins['AnswerModel'] = model\n",
    "            print(model)\n",
    "            start = time.perf_counter_ns()\n",
    "            actual_output =  LLMCompletions(prompt,modelName=model,top_p=0)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = end-start\n",
    "            idx = 0\n",
    "            while actual_output == \"Cannot connect to the model \"+model and idx<2:\n",
    "                start = time.perf_counter_ns()\n",
    "                actual_output =  LLMCompletions(prompt,modelName=model,top_p=0)\n",
    "                end = time.perf_counter_ns()\n",
    "                delta = end-start\n",
    "                idx += 1\n",
    "            if actual_output == \"Cannot connect to the model \"+model:\n",
    "                error['data'].append({'id':data_format_ins['id'],\"AnswerModel\":model,\"input\":prompt,\"expected_output\":data_format_ins['expected_output']})\n",
    "                continue\n",
    "            print(idx,delta//1000_000,actual_output,sep='\\t')\n",
    "            data_format_ins['actual_output'] = actual_output\n",
    "            data_format_ins['time'] = delta\n",
    "            save['data'].append(data_format_ins.copy())\n",
    "            print('*'*70)\n",
    "        errorItemFinal = []\n",
    "        while error['data']:\n",
    "            item = error['data'].pop()\n",
    "            data_format_ins['id'] = item['id']\n",
    "            model = item['AnswerModel']\n",
    "            data_format_ins['AnswerModel'] = model\n",
    "            prompt = item['input']\n",
    "            data_format_ins['input'] = prompt\n",
    "            data_format_ins['expected_output'] = item['expected_output']\n",
    "            start = time.perf_counter_ns()\n",
    "            actual_output =  LLMCompletions(prompt,modelName=model,top_p=0)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = end-start\n",
    "            idx = 0\n",
    "            while actual_output == \"Cannot connect to the model \"+model and idx<2:\n",
    "                print('\\t'+str(idx)+'\\ttest')\n",
    "                start = time.perf_counter_ns()\n",
    "                actual_output =  LLMCompletions(prompt,modelName=model,top_p=0)\n",
    "                end = time.perf_counter_ns()\n",
    "                delta = end-start\n",
    "                idx += 1\n",
    "            if actual_output == \"Cannot connect to the model \"+model:\n",
    "                errorItemFinal.append(item)\n",
    "                print(\"[error]:\\t\"+str(errorItemFinal[-1]))\n",
    "                continue\n",
    "            print(idx,delta,actual_output,sep='\\t')\n",
    "            data_format_ins['actual_output'] = actual_output\n",
    "            data_format_ins['time'] = delta\n",
    "            save['data'].append(data_format_ins.copy())\n",
    "        with open(os.path.join(savePath,model+'.json'),'w',encoding='utf-8') as out:\n",
    "            json.dump(save,out,indent=4)\n",
    "        if errorItemFinal:\n",
    "            for i in errorItemFinal:\n",
    "                error['data'].append(i)\n",
    "            with open(os.path.join(errorPath,model+'.json'),'w',encoding='utf-8') as out:\n",
    "                json.dump(error,out,indent=4)\n",
    "        print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3S2BS7S64MMCSYZ2BQ3EAJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_LLM_Reply_MATH('./data/math401/math50.json','./data/math401/save','./data/math401/error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EvaluteModel Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deepeval login --confident-api-key KSPBSFpiD1ZYuuMIBjoTRUrV3VqsbcYmbiW9obh95cI="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_format = {\n",
    "    'metric_metadata':{\n",
    "        'metric':None,\n",
    "        'threshold':0,\n",
    "        'success':True,\n",
    "        'score':0.8,\n",
    "        'reason':'',\n",
    "        'strictMode': False,\n",
    "        'evaluationModel': 'CustomLLM',\n",
    "        'evaluationCost': 0\n",
    "    },\n",
    "    'metric_configuration': {\n",
    "        'threshold': 0.5,\n",
    "        'evaluation_model': 'CustomLLM',\n",
    "        'strict_mode': False,\n",
    "        'include_reason': True\n",
    "    }\n",
    "}\n",
    "\n",
    "data_format = {\n",
    "    'id':0,\n",
    "    'AnswerModel':'',\n",
    "    'input':'',\n",
    "    'actual_output':'',\n",
    "    'expected_output':None,\n",
    "    'context':None,\n",
    "    'retrieval_context':None,\n",
    "    'cached_metrics_data':[\n",
    "        {\n",
    "            'metric_metadata':{\n",
    "                'metric':None,\n",
    "                'threshold':0,\n",
    "                'success':True,\n",
    "                'score':0.8,\n",
    "                'reason':'',\n",
    "                'strictMode': False,\n",
    "                'evaluationModel': 'CustomLLM',\n",
    "                'evaluationCost': 0\n",
    "            },\n",
    "            'metric_configuration': {\n",
    "                'threshold': 0.5,\n",
    "                'evaluation_model': 'CustomLLM',\n",
    "                'strict_mode': False,\n",
    "                'include_reason': True\n",
    "            }\n",
    "        },\n",
    "        metrics_format\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatLLM(LLM):\n",
    "    @property\n",
    "    def modelName(self)->str:\n",
    "        return \"qwen1.5-72b-chat\"\n",
    "    @property\n",
    "    def INFINI_API_List(self)->List[str]:\n",
    "        return [\"sk-c7cssl4bkglsrwf2\", \"sk-c7erk6qaqhkz5t72\",\"sk-c7etq7veyeie4dn2\"]\n",
    "    @property\n",
    "    def temperature(self)->float:\n",
    "        return 0.7\n",
    "    @property\n",
    "    def top_p(self)->float:\n",
    "        return 0.1\n",
    "    @property\n",
    "    def top_k(self)->int:\n",
    "        return -1\n",
    "    @property\n",
    "    def n(self)->int:\n",
    "        return 1\n",
    "    @property\n",
    "    def max_tokens(self)->int:\n",
    "        return None\n",
    "    @property\n",
    "    def stop(self)->Optional[List[str]]:\n",
    "        return None\n",
    "    @property\n",
    "    def presence_penalty(self)->float:\n",
    "        return 0\n",
    "    @property\n",
    "    def frequency_penalty(self)->float:\n",
    "        return 0\n",
    "    def getHeader(self,index_api):  \n",
    "        headers = {\n",
    "            'Content-Type': \"application/json\",\n",
    "            'Accept': \"*/*\",\n",
    "            'Authorization': \"Bearer \"+self.INFINI_API_List[index_api%len(self.INFINI_API_List)],\n",
    "        }\n",
    "        return headers\n",
    "    @property\n",
    "    def _llm_type(self)->str:\n",
    "        return \"ChatLLM\"\n",
    "    @property\n",
    "    def _identifying_params(self)->Mapping[str,Any]:\n",
    "        _param_dict = {\n",
    "            \"modelName\":self.modelName,\n",
    "            \"INFINI_API\":self.getHeader(self.__fields__['index_api'] if 'index_api' in self.__fields__ else 0),\n",
    "            \"stream\":bool(self.stream),\n",
    "            \"temperature\":self.temperature,\n",
    "            \"top_p\":self.top_p,\n",
    "            \"top_k\":self.top_k,\n",
    "            \"n\":self.n,\n",
    "            \"max_tokens\":self.max_tokens,\n",
    "            \"stop\":self.stop,\n",
    "            \"presence_penalty\":self.presence_penalty,\n",
    "            \"frequency_penalty\":self.frequency_penalty,\n",
    "        }\n",
    "        return _param_dict\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]]= None, run_manager= None,**kwargs: Any) -> str:\n",
    "        url = \"https://cloud.infini-ai.com/maas/\"+str(self.modelName)+\"/nvidia/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"string\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"stream\": False,\n",
    "            \"temperature\": kwargs[\"temperature\"] if \"temperature\" in kwargs else self.temperature,\n",
    "            \"top_p\": kwargs[\"top_p\"] if 'top_p' in kwargs else self.top_p,\n",
    "            \"top_k\": kwargs['top_k'] if 'top_k' in kwargs else self.top_k,\n",
    "            \"n\": kwargs['n'] if 'n' in kwargs else self.n,\n",
    "            \"max_tokens\": kwargs['max_tokens'] if 'max_tokens' in kwargs else self.max_tokens,\n",
    "            \"stop\": stop if stop else self.stop,\n",
    "            \"presence_penalty\": kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else self.presence_penalty,\n",
    "            \"frequency_penalty\": kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else self.frequency_penalty\n",
    "        }\n",
    "        index = 0\n",
    "\n",
    "        if 'index_api' not in self.__fields__:\n",
    "            self.__fields__['index_api'] = -1\n",
    "        index_api = self.__fields__['index_api']+1\n",
    "        length = len(self.INFINI_API_List)\n",
    "        while index < length:\n",
    "            response = requests.post(url, json=payload, headers=self.getHeader(index_api))\n",
    "            if response.status_code == 200:\n",
    "                response.encoding = 'utf-8'\n",
    "                data = response.json()\n",
    "                # print(data)\n",
    "                content = data['choices'][0]['message']['content']\n",
    "                # print(content)\n",
    "                # path.append(content)\n",
    "                if isinstance(content,str):    \n",
    "                    content = content.replace(',\\n}','\\n}')\n",
    "                    content = content.replace(']\\n}',']}')\n",
    "                    content = content.replace('\\\\','\\\\\\\\')\n",
    "                    # path.append(content)\n",
    "                    flag = False\n",
    "                    if 'statements' in content:\n",
    "                        regex = re.compile('\\\"statements\\\":\\s+\\[.*\\]\\}',re.DOTALL)\n",
    "                        flag = True\n",
    "                    elif 'verdicts' in content:\n",
    "                        regex = re.compile('\\\"verdicts\\\":\\s+\\[.*\\]\\}',re.DOTALL)\n",
    "                        flag = True\n",
    "                    if flag:\n",
    "                        matchStr =regex.search(content)\n",
    "                        # print(matchStr)\n",
    "                        if matchStr:\n",
    "                            content = '{'+matchStr.group()\n",
    "                            # path.append(content)\n",
    "                try:\n",
    "                    content = json.loads(content)\n",
    "                    # path.append(content)\n",
    "                except:\n",
    "                    pass\n",
    "                if isinstance(content,str):\n",
    "                    return content\n",
    "                data['choices'][0]['message']['content'] = content\n",
    "                return json.dumps(data['choices'][0]['message']['content'])\n",
    "\n",
    "            index += 1\n",
    "            index_api =  (index_api+1)%length\n",
    "            self.__fields__['index_api'] = index_api\n",
    "            print(response.status_code)\n",
    "            try:\n",
    "                print(response.json())\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(1)\n",
    "        return \"Cannot connect to the model \"+self.modelName\n",
    "    def setParameter(self,**kwargs):\n",
    "        self.temperature = kwargs[\"temperature\"] if \"temperature\" in kwargs else self.temperature\n",
    "        self.top_p = kwargs['top_p'] if 'top_p' in  kwargs else self.top_p\n",
    "        self.top_k = kwargs['top_k'] if 'top_k' in  kwargs else self.top_k\n",
    "        self.n = kwargs['n'] if 'n' in kwargs else self.n\n",
    "        self.max_tokens = kwargs['max_tokens'] if 'max_tokens' in kwargs else self.max_tokens\n",
    "        self.stop = kwargs['stop'] if 'stop' in kwargs else self.stop\n",
    "        self.presence_penalty = kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else self.presence_penalty\n",
    "        self.frequency_penalty = kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else self.frequency_penalty\n",
    "\n",
    "class CustomLLM(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model\n",
    "    ):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        # print(\"prompt:\\t\"+prompt)\n",
    "        ret = chat_model.invoke(prompt)\n",
    "        idx = 0\n",
    "        if ret == \"Cannot connect to the model \"+self.get_model_name() and idx<2:\n",
    "            time.sleep(5)\n",
    "            ret = chat_model.invoke(prompt)\n",
    "            idx += 1\n",
    "        # print('*invoke\\t'+ret)\n",
    "        return ret\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        try:\n",
    "            return self.model.modelName\n",
    "        except:\n",
    "            return \"CustomLLM\"\n",
    "custom_model = ChatLLM()\n",
    "evaluateModel = CustomLLM(model=custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.benchmarks import MMLU\n",
    "from deepeval.benchmarks.tasks import MMLUTask\n",
    "from deepeval.dataset.golden import Golden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  12%|█▏        | 12/100 [00:11<01:19,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  25%|██▌       | 25/100 [00:24<01:07,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  26%|██▌       | 26/100 [00:28<02:14,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  27%|██▋       | 27/100 [00:32<02:57,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  28%|██▊       | 28/100 [00:36<03:27,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  29%|██▉       | 29/100 [00:40<03:48,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  30%|███       | 30/100 [00:43<03:59,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  31%|███       | 31/100 [00:47<04:05,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  32%|███▏      | 32/100 [00:51<04:08,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  33%|███▎      | 33/100 [00:55<04:10,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  34%|███▍      | 34/100 [00:59<04:10,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  37%|███▋      | 37/100 [01:03<02:14,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  38%|███▊      | 38/100 [01:07<02:44,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  39%|███▉      | 39/100 [01:11<03:03,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  41%|████      | 41/100 [01:16<02:31,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  50%|█████     | 50/100 [01:25<00:48,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  62%|██████▏   | 62/100 [01:38<00:34,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  63%|██████▎   | 63/100 [01:42<01:06,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  64%|██████▍   | 64/100 [01:46<01:27,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  65%|██████▌   | 65/100 [01:49<01:40,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  66%|██████▌   | 66/100 [01:53<01:47,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  67%|██████▋   | 67/100 [01:57<01:52,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  68%|██████▊   | 68/100 [02:01<01:54,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  73%|███████▎  | 73/100 [02:07<00:39,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  74%|███████▍  | 74/100 [02:11<00:56,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  76%|███████▌  | 76/100 [02:16<00:52,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  86%|████████▌ | 86/100 [02:27<00:13,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  98%|█████████▊| 98/100 [02:39<00:01,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  99%|█████████▉| 99/100 [02:43<00:01,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science: 100%|██████████| 100/100 [02:47<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMLU Task Accuracy (task=high_school_computer_science): 0.8\n",
      "Overall MMLU Accuracy: 0.8\n",
      "0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark = MMLU(tasks=[MMLUTask.HIGH_SCHOOL_COMPUTER_SCIENCE])\n",
    "results = benchmark.evaluate(model=evaluateModel )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Let x = 1. What is x << 3 in Python 3?\\nA. 1\\nB. 3\\nC. 8\\nD. 16\\nAnswer:',\n",
       " 'actual_output': None,\n",
       " 'expected_output': 'C',\n",
       " 'context': None,\n",
       " 'retrieval_context': None,\n",
       " 'additional_metadata': None,\n",
       " 'source_file': None}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(benchmark.load_benchmark_dataset(task=[MMLUTask.HIGH_SCHOOL_COMPUTER_SCIENCE])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX490E9GSV8SHAB5YQA7XRDC",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.predictions.to_csv('./data/benchmark/qwen1.5-72b-chat.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task                               high_school_computer_science\n",
      "Input         Let x = 1. What is x << 3 in Python 3?\\nA. 1\\n...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 0, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, which of the following function c...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 1, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A user enters a Web address in a browser, and ...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 2, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Digital images are often represented by the re...\n",
      "Prediction                                                    D\n",
      "Correct                                                       0\n",
      "Name: 3, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A programmer is writing a program that is inte...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 4, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Suppose the characters 0,1, . . . ,8,9,A,B,C,D...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 5, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A large data set contains information about al...\n",
      "Prediction                                                    A\n",
      "Correct                                                       0\n",
      "Name: 6, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The code segment below uses the procedure IsFo...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 7, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A program is expressed in a programming langua...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 8, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, what is the output of print tuple...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 9, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Of the following potential benefits, which is ...\n",
      "Prediction                                                    D\n",
      "Correct                                                       0\n",
      "Name: 10, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Historically, it has been observed that comput...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 11, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A programmer wrote the program below. The prog...\n",
      "Prediction                                                    A\n",
      "Correct                                                       0\n",
      "Name: 12, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A computer simulation is created to simulate t...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 13, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Huffman coding assigns unique variable-length ...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 14, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, which of the following function c...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 15, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The code fragment below is intended to display...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 16, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A programmer uses code published online under ...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 17, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A new bank plans to make customer convenience ...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 18, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following best explains how data ...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 19, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A method is to be written to search an array f...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 20, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         What is the output of the statement \"a\" + \"ab\"...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 21, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In python 3, which of the following is floor d...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 22, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following school policies is most...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 23, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In a certain country, a person must be at leas...\n",
      "Prediction                                                    A\n",
      "Correct                                                       0\n",
      "Name: 24, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         An online store uses 6-bit binary sequences to...\n",
      "Prediction                                                    B\n",
      "Correct                                                       0\n",
      "Name: 25, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following programs is most likely...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 26, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the following code segment.\\n int num...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 27, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Two lists, list1 and list2, contain the names ...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 28, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Are Python variable names case-sensitive?\\nA. ...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 29, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A computer program uses 3 bits to represent in...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 30, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which is the largest asymptotically?\\nA. O(1)\\...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 31, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A programmer wrote the code segment below to d...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 32, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Both online newspapers and social media sites ...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 33, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A large Java program was tested extensively, a...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 34, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         What is the value of this python expression: 1...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 35, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Each student that enrolls at a school is assig...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 36, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, which of the following operator i...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 37, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following is the hexadecimal repr...\n",
      "Prediction                                                    B\n",
      "Correct                                                       0\n",
      "Name: 38, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following spreadsheet functions w...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 39, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A certain computer game is played between a hu...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 40, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, what is the output of print list[...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 41, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the code segment below.\\n Line 1: IF ...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 42, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A sorted list of 120 integers is to be searche...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 43, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following is correct about Python...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 44, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Let x = 8. What is x>>1 in Python 3?\\nA. 3\\nB....\n",
      "Prediction                                                    C\n",
      "Correct                                                       0\n",
      "Name: 45, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The color of a pixel can be represented using ...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 46, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The boolean expression a[i] == max || !(max !=...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 47, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A programmer is deciding between using a linea...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 48, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which types of functions grow the slowest?\\nA....\n",
      "Prediction                                                    B\n",
      "Correct                                                       0\n",
      "Name: 49, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A student is recording a song on her computer....\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 50, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, what is the following function re...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 51, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which is the smallest asymptotically?\\nA. O(1)...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 52, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following is LEAST likely to indi...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 53, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The algorithm below is used to simulate the re...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 54, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which pillar of cybersecurity is compromised w...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 55, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The following procedure is intended to return ...\n",
      "Prediction                                                    D\n",
      "Correct                                                       0\n",
      "Name: 56, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following is a true statement abo...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 57, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the following three scenarios, which ...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 58, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Let l = [1,2,3,4]. What is min(l) in Python3?\\...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 59, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Let l = [1,2,3,4]. What is max(l) in Python3?\\...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 60, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following is a characteristic of ...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 61, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the following numbers.\\n   ° Binary 1...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 62, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         What is the role of the compiler in the proces...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 63, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following is the most likely data...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 64, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         What is the output of \"abc\"[-1] in Python 3?\\n...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 65, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         An algorithm will be used to identify the maxi...\n",
      "Prediction                                                    A\n",
      "Correct                                                       0\n",
      "Name: 66, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the following instance variable and m...\n",
      "Prediction                                                    A\n",
      "Correct                                                       0\n",
      "Name: 67, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         What is the value of this python expression: 4...\n",
      "Prediction                                                    C\n",
      "Correct                                                       0\n",
      "Name: 68, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Airmail Express charges for shipping small pac...\n",
      "Prediction                                                    A\n",
      "Correct                                                       0\n",
      "Name: 69, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In the program below, y is a positive integer ...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 70, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A programmer is designing a program to catalog...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 71, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Let l = [1,2,3,4]. What is sum(l) in Python3?\\...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 72, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A Web site uses several strategies to prevent ...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 73, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The procedure below is intended to display the...\n",
      "Prediction                                                    D\n",
      "Correct                                                       0\n",
      "Name: 74, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         This question is based on the following declar...\n",
      "Prediction                                                    A\n",
      "Correct                                                       0\n",
      "Name: 75, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In the procedure Mystery below, the parameter ...\n",
      "Prediction                                                    D\n",
      "Correct                                                       0\n",
      "Name: 76, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         An Insect class is to be written, containing t...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 77, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A sorted list of numbers contains 500 elements...\n",
      "Prediction                                                    C\n",
      "Correct                                                       0\n",
      "Name: 78, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, which of the following function s...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 79, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, what is the output of ['Hi!'] * 4...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 80, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the following assumptions about elect...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 81, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A search engine has a trend-tracking feature t...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 82, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, what is ['a', 'Chemistry', 0, 1][...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 83, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following best describes the prim...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 84, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following has the greatest potent...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 85, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following best explains what happ...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 86, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         If a, b, and c are integers, which of the foll...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 87, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Let l = [1,2,2,3,4]. In Python3, what is a pos...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 88, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A retailer that sells footwear maintains a sin...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 89, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         What is the output of 4*1**4 in python?\\nA. 4\\...\n",
      "Prediction                                                    A\n",
      "Correct                                                       1\n",
      "Name: 90, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Refer to the nextIntInRangemethod below:\\n /**...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 91, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, b = [11,13,15,17,19,21]; print(b[...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 92, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         An algorithm for finding the average of N numb...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 93, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A large list of numbers is to be sorted into a...\n",
      "Prediction                                                    A\n",
      "Correct                                                       0\n",
      "Name: 94, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the following code segment, which use...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 95, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A digital photo file contains data representin...\n",
      "Prediction                                                    B\n",
      "Correct                                                       1\n",
      "Name: 96, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, what is ['a', 'Chemistry', 0, 1][...\n",
      "Prediction                                                    C\n",
      "Correct                                                       0\n",
      "Name: 97, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Two computers are built by different manufactu...\n",
      "Prediction                                                    D\n",
      "Correct                                                       1\n",
      "Name: 98, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following activities poses the gr...\n",
      "Prediction                                                    C\n",
      "Correct                                                       1\n",
      "Name: 99, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(benchmark.predictions)):\n",
    "    print(benchmark.predictions.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric,FaithfulnessMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Replace this with the actual output from your LLM application\n",
    "\n",
    "metric = AnswerRelevancyMetric(\n",
    "    threshold=0.5,\n",
    "    model=evaluateModel,\n",
    "    include_reason=True\n",
    ")\n",
    "metric2 = FaithfulnessMetric(\n",
    "    threshold=0.5,\n",
    "    model=evaluateModel,\n",
    "    include_reason=True,\n",
    "    # strict_mode=True\n",
    ")\n",
    "# test_case = LLMTestCase(\n",
    "#     input=\"What if these shoes don't fit?\",\n",
    "#     actual_output=actual_output\n",
    "# )\n",
    "test_case = LLMTestCase(\n",
    "    input=data['problem'],\n",
    "    retrieval_context=[data['solution']],\n",
    "    actual_output=actual_output,\n",
    "    # context=[\"All customers are eligible for a 30 day full refund at no extra cost.\"],\n",
    "    # retrieval_context=[\"Only shoes can be refunded.\"],\n",
    "    # latency=10.0\n",
    ")\n",
    "test_case2 = LLMTestCase(\n",
    "    input=data2['problem'],\n",
    "    # expected_output=data2['solution'],\n",
    "    actual_output=actual_output2,\n",
    "    # context=[\"All customers are eligible for a 30 day full refund at no extra cost.\"],\n",
    "    retrieval_context=[data2['solution']],\n",
    "    # latency=10.0\n",
    ")\n",
    "dataset = [test_case,test_case2]\n",
    "# for i in dataset:\n",
    "#     metric.measure(i)\n",
    "#     print(metric.__name__)\n",
    "#     print(i.input)\n",
    "#     print(i.actual_output)\n",
    "#     print(metric.score)\n",
    "#     print(metric.success)\n",
    "    \n",
    "#     metric2.measure(i)\n",
    "#     print(metric2.truths)\n",
    "#     print(metric2.reason)\n",
    "#     print(metric2.score)\n",
    "#     print(metric2.success)\n",
    "\n",
    "\n",
    "# or evaluate test cases in bulk\n",
    "evaluate(dataset, [metric,metric2,],run_async=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '{\"statements\": [\\n        \"To find the distance between two points in multivariate calculus, we use the formula for the distance between a point pair (x1, y1), (x2, y2) in n-dimensional space.\",\\n        \"Distance = sqrt[((x2 - x1)^2 + (y2 - y1)^2)]\",\\n        \"Here, we have two univariate polynomials in x and y, and we want to find the distance between the two polynomials in x and y.\",\\n        \"$x - 3y + 3z = 8$\",\\n        \"$2x - 6y + 6z = 2$\",\\n        \"To find the distance, we need to compare the coefficients of the two polynomials.\",\\n        \"The coefficients of the second polynomial with respect to x are -6 and 2.\",\\n        \"The coefficients of the second polynomial with respect to y are -3 and 0.\",\\n        \"So, the distance between the two polynomials is.\",\\n        \"$\\\\sqrt{(-6)^2 + 2^2} = \\\\sqrt{36 + 4} = \\\\sqrt{40} = 2\\\\sqrt{10}$\",\\n        \"Thus, the distance between the two polynomials is 2√10.\"\\n    ]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(text.replace('\\\\','\\\\\\\\'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./.deepeval-cache.json') as f:\n",
    "    text = f.read()\n",
    "json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://cloud.infini-ai.com/maas/qwen-7b-chat/nvidia/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"string\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write me a joke?\"\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"top_k\": -1,\n",
    "    \"n\": 1,\n",
    "    \"max_tokens\": None,\n",
    "    \"stop\": None,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"frequency_penalty\": 0\n",
    "}\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"Authorization\": \"Bearer \"+INFINI_API\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"请围绕一个法律主题，写一篇茹斯汀·特里耶导演2023年的电影《坠落的审判》的2000字影评，其中应包含不超过1/5的剧情梗概。\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in questions:\n",
    "    print(i,LLMCompletions(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatLLM(LLM):\n",
    "\n",
    "    modelName = \"infini-megrez-7b\"\n",
    "    INFINI_API = \"sk-c7cssl4bkglsrwf2\"\n",
    "    # hostname = \"cloud.infini-ai.com\"\n",
    "    temperature = 0.7\n",
    "    top_p = 1\n",
    "    top_k = -1\n",
    "    n = 1\n",
    "    max_tokens:int = None\n",
    "    stop:str = None\n",
    "    presence_penalty = 0\n",
    "    frequency_penalty = 0\n",
    "    \n",
    "    headers = {\n",
    "            'Content-Type': \"application/json\",\n",
    "            'Accept': \"*/*\",\n",
    "            'Authorization': \"Bearer \"+INFINI_API,\n",
    "    }\n",
    "    # def __init__(self,modelName:str = \"infini-megrez-7b\",\n",
    "    #         INFINI_API:str = \"sk-c7cssl4bkglsrwf2\",\n",
    "    #         hostname:str = \"cloud.infini-ai.com\",\n",
    "    #         temperature:float = 0.7,\n",
    "    #         top_p:float = 1,\n",
    "    #         top_k:int = -1,\n",
    "    #         n:int = 1,\n",
    "    #         max_tokens:int = None,\n",
    "    #         stop = None,\n",
    "    #         presence_penalty:float = 0,\n",
    "    #         frequency_penalty:float = 0):\n",
    "\n",
    "    #     self.modelName = modelName\n",
    "    #     self.INFINI_API = INFINI_API\n",
    "    #     self.hostname = hostname\n",
    "    #     self.temperature = temperature\n",
    "    #     self.top_p = top_p\n",
    "    #     self.top_k = top_k\n",
    "    #     self.n = n\n",
    "    #     self.max_tokens = max_tokens if max_tokens is not None else 'null'\n",
    "    #     self.stop = stop if stop is not None else 'null'\n",
    "    #     self.presence_penalty = presence_penalty\n",
    "    #     self.frequency_penalty = frequency_penalty\n",
    "    #     self.headers = {\n",
    "    #         'Content-Type': \"application/json\",\n",
    "    #         'Accept': \"*/*\",\n",
    "    #         'Authorization': \"Bearer \"+INFINI_API,\n",
    "    #     }\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self)->str:\n",
    "        return \"chatllm\"\n",
    "    @property\n",
    "    def _identifying_params(self)->Mapping[str,Any]:\n",
    "        _param_dict = {\n",
    "            \"modelName\":ChatLLM().modelName,\n",
    "            \"INFINI_API\":ChatLLM().INFINI_API,\n",
    "            \"stream\":bool(ChatLLM().stream),\n",
    "            \"temperature\":ChatLLM().temperature,\n",
    "            \"top_p\":ChatLLM().top_p,\n",
    "            \"top_k\":ChatLLM().top_k,\n",
    "            \"n\":ChatLLM().n,\n",
    "            \"max_tokens\":ChatLLM().max_tokens,\n",
    "            \"stop\":ChatLLM().stop,\n",
    "            \"presence_penalty\":ChatLLM().presence_penalty,\n",
    "            \"frequency_penalty\":ChatLLM().frequency_penalty,\n",
    "            \n",
    "        }\n",
    "        return _param_dict\n",
    "    @classmethod  \n",
    "    def _call(self, prompt: str, stop: Optional[List[str]]= None,  **kwargs: Any) -> str:\n",
    "        # temperature = kwargs[\"temperature\"] if \"temperature\" in kwargs else ChatLLM().temperature\n",
    "        # top_p = kwargs[\"top_p\"] if 'top_p' in kwargs else ChatLLM().top_p\n",
    "        # top_k = kwargs['top_k'] if 'top_k' in kwargs else ChatLLM().top_k\n",
    "        # n = kwargs['n'] if 'n' in kwargs else ChatLLM().n\n",
    "        # max_tokens = kwargs['max_tokens'] if 'max_tokens' in  kwargs else ChatLLM().max_tokens\n",
    "        # stop = stop if stop else ChatLLM().stop\n",
    "        # presence_penalty = kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else ChatLLM().presence_penalty\n",
    "        # frequency_penalty = kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else ChatLLM().frequency_penalty\n",
    "        # stream = 'false'\n",
    "        # temperature = 0.7\n",
    "        # top_p = 1\n",
    "        # top_k = -1\n",
    "        # n = 1\n",
    "        # max_tokens = 'null'\n",
    "        # stop = 'null'\n",
    "        # presence_penalty = 0\n",
    "        # frequency_penalty = 0\n",
    "        # conn = http.client.HTTPSConnection(ChatLLM().hostname)\n",
    "        # stream = 'false' if not bool(stream) else 'true'\n",
    "        # prompt = prompt.replace('\"','\\\\\"')\n",
    "        \n",
    "        url = \"https://cloud.infini-ai.com/maas/\"+ChatLLM().modelName+\"/nvidia/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"string\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"stream\": False,\n",
    "            \"temperature\": kwargs[\"temperature\"] if \"temperature\" in kwargs else ChatLLM().temperature,\n",
    "            \"top_p\": kwargs[\"top_p\"] if 'top_p' in kwargs else ChatLLM().top_p,\n",
    "            \"top_k\": kwargs['top_k'] if 'top_k' in kwargs else ChatLLM().top_k,\n",
    "            \"n\": kwargs['n'] if 'n' in kwargs else ChatLLM().n,\n",
    "            \"max_tokens\": kwargs['max_tokens'] if 'max_tokens' in kwargs else ChatLLM().max_tokens,\n",
    "            \"stop\": stop if stop else ChatLLM().stop,\n",
    "            \"presence_penalty\": kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else ChatLLM().presence_penalty,\n",
    "            \"frequency_penalty\": kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else ChatLLM().frequency_penalty\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=ChatLLM().headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['response']\n",
    "        else:\n",
    "            return \"请求模型\"\n",
    "        \n",
    "        # payload = f'{{\"model\": \"string\",\"messages\": [{{\"role\": \"user\",\"content\":\"{prompt}\"}}],\"stream\":{stream},\"temperature\": {temperature},\"top_p\": {top_p},\"top_k\": {top_k},\"n\":{n},\"max_tokens\": {max_tokens},\"stop\": {stop},\"presence_penalty\": {presence_penalty},\"frequency_penalty\": {frequency_penalty}}}'\n",
    "        # print(payload)\n",
    "        # conn.request(\"POST\",\"/maas/\"+ChatLLM().modelName+\"/nvidia/chat/completions\",payload.encode('utf-8'),ChatLLM().headers,)\n",
    "        \n",
    "        # res = conn.getresponse()\n",
    "        # if res.status == 200:\n",
    "        #     data = res.read().decode(\"utf-8\")\n",
    "        #     return data\n",
    "        #     # response = json.loads(data)\n",
    "        #     # return response\n",
    "        # else:\n",
    "        #     return \"请求模型\"\n",
    "        \n",
    "        \n",
    "    def setParameter(self,**kwargs):\n",
    "        # self.stream = kwargs[\"stream\"] if \"stream\" in kwargs else ChatLLM().stream\n",
    "        self.temperature = kwargs[\"temperature\"] if \"temperature\" in kwargs else ChatLLM().temperature\n",
    "        self.top_p = kwargs['top_p'] if 'top_p' in  kwargs else ChatLLM().top_p\n",
    "        self.top_k = kwargs['top_k'] if 'top_k' in  kwargs else ChatLLM().top_k\n",
    "        self.n = kwargs['n'] if 'n' in kwargs else ChatLLM().n\n",
    "        self.max_tokens = kwargs['max_tokens'] if 'max_tokens' in kwargs else ChatLLM().max_tokens\n",
    "        self.stop = kwargs['stop'] if 'stop' in kwargs else ChatLLM().stop\n",
    "        self.presence_penalty = kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else ChatLLM().presence_penalty\n",
    "        self.frequency_penalty = kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else ChatLLM().frequency_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMCompletion:\n",
    "    def __init__(self,index=0):\n",
    "        self.index = index\n",
    "    def GEN_SOLUTION(self,prompt,modelName:str = \"infini-megrez-7b\",INFINI_API_List = [\"sk-c7cssl4bkglsrwf2\", \"sk-c7erk6qaqhkz5t72\",\"sk-c7etq7veyeie4dn2\"],returnContent:bool = True,**kwargs):\n",
    "        url = \"https://cloud.infini-ai.com/maas/\"+modelName+\"/nvidia/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": modelName,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"stream\": False,\n",
    "            \"temperature\": kwargs[\"temperature\"] if \"temperature\" in kwargs else 0.7,\n",
    "            \"top_p\": kwargs[\"top_p\"] if 'top_p' in kwargs else 1,\n",
    "            \"top_k\": kwargs['top_k'] if 'top_k' in kwargs else -1,\n",
    "            \"n\": kwargs['n'] if 'n' in kwargs else 1,\n",
    "            \"max_tokens\": kwargs['max_tokens'] if 'max_tokens' in kwargs else None,\n",
    "            \"stop\": kwargs['stop'] if 'stop' in kwargs else None,\n",
    "            \"presence_penalty\": kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else 0,\n",
    "            \"frequency_penalty\": kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else 0\n",
    "        }\n",
    "        idx = 0\n",
    "        while idx < len(INFINI_API_List):\n",
    "            headers = {\n",
    "                    'Content-Type': \"application/json\",\n",
    "                    'Accept': \"*/*\",\n",
    "                    'Authorization': \"Bearer \"+INFINI_API_List[self.index%len(INFINI_API_List)],\n",
    "            } \n",
    "            # print(payload)\n",
    "            # print(headers)\n",
    "            response = requests.post(url, json=payload, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                response.encoding = 'utf-8'\n",
    "                data = response.json()\n",
    "                content = data['choices'][0]['message']['content']\n",
    "                print(content)\n",
    "                # if isinstance(content,str):\n",
    "                #     content = content.replace(',\\n}','\\n}')\n",
    "                #     content = content.replace(']\\n}',']}')\n",
    "                #     content = content.replace('\\\\','\\\\\\\\')\n",
    "                if returnContent:\n",
    "                    return content\n",
    "                try:\n",
    "                    content = json.loads(content)\n",
    "                except:\n",
    "                    pass\n",
    "                data['choices'][0]['message']['content'] = content\n",
    "                if isinstance(content,str):\n",
    "                    return content\n",
    "                \n",
    "                return json.dumps(data['choices'][0]['message']['content'])\n",
    "            else:\n",
    "                print(response.status_code)\n",
    "                try:\n",
    "                    print(response.json())\n",
    "                except:\n",
    "                    pass\n",
    "            self.index = (self.index + 1) % len(INFINI_API_List)\n",
    "            idx += 1\n",
    "        print((\"=\"*35)+'Error:\\t'+prompt+('='*35))\n",
    "        return \"Cannot connect to the model \"+modelName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalplus.data import write_jsonl,get_human_eval_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = get_human_eval_plus()\n",
    "# dataset_copy  = dataset.copy()\n",
    "# for i,key in enumerate(dataset.keys()):\n",
    "#     if i % 6 != 0:\n",
    "#         del dataset_copy[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/codeEval/data.json','w') as f:\n",
    "#     json.dump(dataset_copy,f,ensure_ascii=False,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_human_eval_plus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerModelList = [    \n",
    "    'baichuan2-7b-chat',\n",
    "    'baichuan2-13b-chat',\n",
    "    'baichuan2-13b-base',\n",
    "    'qwen-7b-chat',\n",
    "    'qwen-14b-chat',\n",
    "    'qwen-72b-chat',\n",
    "    'qwen-72b',\n",
    "    'qwen1.5-7b-chat',\n",
    "    'qwen1.5-14b-chat',\n",
    "    'qwen1.5-72b',\n",
    "    #'llama-2-70b-chat',#deprecated,can not connect to the model\n",
    "    'llama-2-70b',\n",
    "    'llama-2-7b-chat',\n",
    "    'llama-2-13b-chat',\n",
    "    'infini-megrez-7b',  \n",
    "]\n",
    "productor = LLMCompletion()\n",
    "with open('./data/codeEval/data.json','r') as f:\n",
    "    dataset = json.load(f)\n",
    "for modelName in answerModelList:\n",
    "    samples = [dict(task_id=task_id, solution=productor.GEN_SOLUTION(problem[\"prompt\"],modelName=modelName)) for task_id, problem in dataset.items()]\n",
    "    write_jsonl('./data/codeEval/code_all/'+modelName+\".jsonl\", samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir,subdir,files in os.walk('./data/codeEval/code_raw'):\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_code = ['baichuan2-13b-base.jsonl', 'baichuan2-13b-chat.jsonl', 'baichuan2-7b-chat.jsonl', 'infini-megrez-7b.jsonl',  'llama-2-13b-chat.jsonl', 'llama-2-70b-chat.jsonl', 'llama-2-70b.jsonl', 'llama-2-7b-chat.jsonl', 'qwen-14b-chat.jsonl', 'qwen-72b-chat.jsonl','qwen-72b.jsonl', 'qwen-7b-chat.jsonl', 'qwen1.5-14b-chat.jsonl', 'qwen1.5-72b.jsonl', 'qwen1.5-7b-chat.jsonl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/codeEval/data.json','r') as f:\n",
    "    dataset = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"HumanEval/156\"]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"import bin\\ndef solve(N):\\n    # Convert the number to binary\\n    binary = ''.join(map(ord, [range(N) if _ <= ord(N) else [] for _ in range(N)]))\\n    # Append the leading '0' if needed\\n    return ''.join(binary[:8]) + '0' * (N // 9)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = 'qwen1.5-7b-chat.jsonl'\n",
    "# data = []\n",
    "# with open('./data/codeEval/code_raw/'+file_name, 'r') as f:\n",
    "#     for line in f.readlines():\n",
    "#         data.append(json.loads(line))\n",
    "# data_sanitize = []\n",
    "# with open('./data/codeEval/code_sanitize/'+file_name,'r') as f:\n",
    "#     for line in f.readlines():\n",
    "#         data_sanitize.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 27\n",
    "# print(data[i]['task_id'])\n",
    "# print(data[i]['solution'])\n",
    "# print('='*70)\n",
    "# print(data_sanitize[i]['task_id'])\n",
    "# print(data_sanitize[i]['solution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(data_sanitize)):\n",
    "#     print(data_sanitize[i]['solution'])\n",
    "#     print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"def int_to_mini_roman(self, number):\\n    \\\"\\\"\\\"\\n    Given a positive integer, obtain its roman numeral equivalent as a string,\\n    and return it in lowercase.\\n    Restrictions: 1 <= num <= 1000\\n\\n\\n\\n    Examples:\\n    >>> int_to_mini_roman(19) == 'xix'\\n    >>> int_to_mini_roman(152) == 'clii'\\n    >>> int_to_mini_roman(426) == 'cdxxvi'\\n    \\\"\\\"\\\"\\n    def roman_to_int(roman_num):\\n        \\\"\\\"\\\"\\n        Converts a roman numeral to an integer.\\n        \\\"\\\"\\\"\\n        num = 0\\n        for i in range(len(roman_num) - 1, -1, -1):\\n            if roman_num[i] == 'i':\\n                num += 1\\n            elif roman_num[i] == 'v':\\n                num += 5\\n            elif roman_num[i] == 'x':\\n                num += 10\\n            elif roman_num[i] == 'l':\\n                num += 50\\n            elif roman_num[i] == 'c':\\n                num += 100\\n            elif roman_num[i] == 'd':\\n                num += 500\\n            elif roman_num[i] == 'm':\\n                num += 1000\\n            else:\\n                pass\\n        return num\\n    def int_to_roman(num):\\n        \\\"\\\"\\\"\\n        Converts a integer to a roman numeral.\\n        \\\"\\\"\\\"\\n        roman_str = ''\\n        for i in range(len(self.roman_map)):\\n            while num >= self.roman_map[i]:\\n                roman_str += self.roman_map[i]\\n                num -= self.roman_map[i]\\n        return roman_str \\n    # Your code here\\n    if number == 0:\\n        return 'i'\\n    if number <= 4000:\\n        return int_to_roman(number)\\n    else:\\n        return int_to_roman(roman_to_int(number))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3YCQ5TM6S89W1HPP6HWWDD",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {\"task_id\": \"HumanEval/66\",\"model\":'infini-megrez-7b'},\n",
    "    {\"task_id\": \"HumanEval/84\",\"model\":'infini-megrez-7b'},\n",
    "    {\"task_id\": \"HumanEval/156\",\"model\":'llama-2-70b'}\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"def int_to_mini_roman(self, number):\\n    \\\"\\\"\\\"\\n    Given a positive integer, obtain its roman numeral equivalent as a string,\\n    and return it in lowercase.\\n    Restrictions: 1 <= num <= 1000\\n\\n\\n\\n    Examples:\\n    >>> int_to_mini_roman(19) == 'xix'\\n    >>> int_to_mini_roman(152) == 'clii'\\n    >>> int_to_mini_roman(426) == 'cdxxvi'\\n    \\\"\\\"\\\"\\n    def roman_to_int(roman_num):\\n        \\\"\\\"\\\"\\n        Converts a roman numeral to an integer.\\n        \\\"\\\"\\\"\\n        num = 0\\n        for i in range(len(roman_num) - 1, -1, -1):\\n            if roman_num[i] == 'i':\\n                num += 1\\n            elif roman_num[i] == 'v':\\n                num += 5\\n            elif roman_num[i] == 'x':\\n                num += 10\\n            elif roman_num[i] == 'l':\\n                num += 50\\n            elif roman_num[i] == 'c':\\n                num += 100\\n            elif roman_num[i] == 'd':\\n                num += 500\\n            elif roman_num[i] == 'm':\\n                num += 1000\\n            else:\\n                pass\\n        return num\\n    def int_to_roman(num):\\n        \\\"\\\"\\\"\\n        Converts a integer to a roman numeral.\\n        \\\"\\\"\\\"\\n        roman_str = ''\\n        for i in range(len(self.roman_map)):\\n            while num >= self.roman_map[i]:\\n                roman_str += self.roman_map[i]\\n                num -= self.roman_map[i]\\n        return roman_str \\n    # Your code here\\n    if number == 0:\\n        return 'i'\\n    if number <= 4000:\\n        return int_to_roman(number)\\n    else:\\n        return int_to_roman(roman_to_int(number))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalplus.sanitize import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalplus.syncheck import  main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('./data/codeEval/code_sanitize/qwen-72b.jsonl','humaneval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_args = argv\n",
    "argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_args.append('--dataset=humaneval')\n",
    "local_args.append('--samples=./data/codeEval/code_sanitize/qwen-72b.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_args.append('--i-just-wanna-run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_args.append('--min-time-limit=100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_args.append('--test-details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_args.append('--base-only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalplus.evaluate import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01HX3XAQBAA1KABTSDJYTN4E0B",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/codeEval/code_eval')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path('./data/codeEval/code_sanitize/').parent/'code_eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in files_code:\n",
    "#     main('./data/codeEval/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('./data/codeEval/code_raw/qwen-72b.jsonl','r') as f:\n",
    "    for line in f.readlines():\n",
    "        data.append(json.loads(line))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task_id': 'HumanEval/0',\n",
       "  'solution': 'from typing import List\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False'},\n",
       " {'task_id': 'HumanEval/6',\n",
       "  'solution': \"from typing import List\\ndef parse_nested_parens(paren_string: str) -> List[int]:\\n    result = []\\n    for group in paren_string.split():\\n        stack = []\\n        max_depth = 0\\n        for char in group:\\n            if char == '(':\\n                stack.append(char)\\n                if len(stack) > max_depth:\\n                    max_depth = len(stack)\\n            elif char == ')':\\n                stack.pop()\\n        result.append(max_depth)\\n    return result\"},\n",
       " {'task_id': 'HumanEval/12',\n",
       "  'solution': 'from typing import List, Optional\\n\\ndef longest(strings: List[str]) -> Optional[str]:\\n    \"\"\" Out of list of strings, return the longest one. Return the first one in case of multiple\\n    strings of the same length. Return None in case the input list is empty.\\n    >>> longest([])\\n\\n    >>> longest([\\'a\\', \\'b\\', \\'c\\'])\\n    \\'a\\'\\n    >>> longest([\\'a\\', \\'bb\\', \\'ccc\\'])\\n    \\'ccc\\'\\n    \"\"\"\\n    if not strings:\\n        return None\\n\\n    longest_string = strings[0]\\n    for string in strings[1:]:\\n        if len(string) > len(longest_string):\\n            longest_string = string\\n\\n    return longest_string'},\n",
       " {'task_id': 'HumanEval/18',\n",
       "  'solution': 'def how_many_times(string: str, substring: str) -> int:\\n    count = 0\\n    for i in range(len(string) - len(substring) + 1):\\n        if string[i:i+len(substring)] == substring:\\n            count += 1\\n    return count'},\n",
       " {'task_id': 'HumanEval/24',\n",
       "  'solution': 'def largest_divisor(n: int) -> int:\\n    for i in range(n // 2, 0, -1):\\n        if n % i == 0:\\n            return i\\n    return 1'},\n",
       " {'task_id': 'HumanEval/30',\n",
       "  'solution': 'def get_positive(l: list) -> list:\\n    return [num for num in l if num > 0]'},\n",
       " {'task_id': 'HumanEval/36',\n",
       "  'solution': 'def fizz_buzz(n: int) -> int:\\n    count = 0\\n    for i in range(1, n):\\n        if i % 11 == 0 or i % 13 == 0:\\n            count += str(i).count(\"7\")\\n    return count'},\n",
       " {'task_id': 'HumanEval/42',\n",
       "  'solution': 'def incr_list(l: list) -> list:\\n    return [x + 1 for x in l]'},\n",
       " {'task_id': 'HumanEval/48',\n",
       "  'solution': 'def is_palindrome(text: str) -> bool:\\n    \"\"\"\\n    Checks if given string is a palindrome\\n    >>> is_palindrome(\\'\\')\\n    True\\n    >>> is_palindrome(\\'aba\\')\\n    True\\n    >>> is_palindrome(\\'aaaaa\\')\\n    True\\n    >>> is_palindrome(\\'zbcd\\')\\n    False\\n    \"\"\"\\n    return text == text[::-1]'},\n",
       " {'task_id': 'HumanEval/54',\n",
       "  'solution': 'def same_chars(s0: str, s1: str) -> bool:\\n    # Create sets of unique characters for each string\\n    set0 = set(s0)\\n    set1 = set(s1)\\n    \\n    # Check if the sets are equal\\n    return set0 == set1'},\n",
       " {'task_id': 'HumanEval/60',\n",
       "  'solution': 'def sum_to_n(n: int) -> int:\\n    return (n * (n + 1)) // 2'},\n",
       " {'task_id': 'HumanEval/66',\n",
       "  'solution': 'def digitSum(s):\\n    sum = 0\\n    for c in s:\\n        if c.isupper():\\n            sum += ord(c)\\n    return sum'},\n",
       " {'task_id': 'HumanEval/72',\n",
       "  'solution': 'def will_it_fly(q, w):\\n    if q == q[::-1] and sum(q) <= w:\\n        return True\\n    else:\\n        return False'},\n",
       " {'task_id': 'HumanEval/78',\n",
       "  'solution': \"def hex_key(num):\\n    primes = {'2', '3', '5', '7', 'B', 'D'}\\n    count = 0\\n    for digit in num:\\n        if digit in primes:\\n            count += 1\\n    return count\"},\n",
       " {'task_id': 'HumanEval/84',\n",
       "  'solution': 'def solve(N):\\n    binary = bin(N)[2:]  # Convert N to binary and remove the \"0b\" prefix\\n    digit_sum = sum(int(digit) for digit in binary)  # Sum the digits in the binary number\\n    return bin(digit_sum)[2:]  # Convert the digit sum to binary and remove the \"0b\" prefix'},\n",
       " {'task_id': 'HumanEval/90',\n",
       "  'solution': 'def next_smallest(lst):\\n    if len(lst) < 2:\\n        return None\\n    smallest = None\\n    second_smallest = None\\n    for num in lst:\\n        if smallest is None or num < smallest:\\n            second_smallest = smallest\\n            smallest = num\\n        elif second_smallest is None or num < second_smallest:\\n            second_smallest = num\\n    return second_smallest'},\n",
       " {'task_id': 'HumanEval/96',\n",
       "  'solution': 'def is_prime(n):\\n    \"\"\"Check if a number is prime.\"\"\"\\n    if n <= 1:\\n        return False\\n    for i in range(2, int(n ** 0.5) + 1):\\n        if n % i == 0:\\n            return False\\n    return True\\n\\ndef count_up_to(n):\\n    \"\"\"Return the first n prime numbers that are less than n.\"\"\"\\n    primes = []\\n    i = 2\\n    while len(primes) < n and i < n:\\n        if is_prime(i):\\n            primes.append(i)\\n        i += 1\\n    return primes'},\n",
       " {'task_id': 'HumanEval/102',\n",
       "  'solution': 'def choose_num(x, y):\\n    # Check if x and y are positive integers\\n    if not isinstance(x, int) or not isinstance(y, int) or x <= 0 or y <= 0:\\n        return \"Both x and y must be positive integers.\"\\n    \\n    # Check if y is greater than x\\n    if y < x:\\n        return \"y must be greater than or equal to x.\"\\n    \\n    # Find the largest even number in the range [x, y]\\n    for i in range(y, x-1, -1):\\n        if i % 2 == 0:\\n            return i\\n    \\n    # If no even number was found, return -1\\n    return -1'},\n",
       " {'task_id': 'HumanEval/108',\n",
       "  'solution': 'def count_nums(arr):\\n    count = 0\\n    for num in arr:\\n        # check if the number is negative\\n        if num < 0:\\n            # convert the first digit to negative\\n            num = -int(str(abs(num))[0]) + int(str(abs(num))[1:])\\n        # calculate the sum of digits\\n        digits_sum = sum(map(int, str(num)))\\n        # increment the count if the sum of digits is greater than 0\\n        if digits_sum > 0:\\n            count += 1\\n    return count'},\n",
       " {'task_id': 'HumanEval/114',\n",
       "  'solution': 'def minSubArraySum(nums):\\n    n = len(nums)\\n    min_sum = nums[0]\\n\\n    for i in range(n):\\n        for j in range(i+1, n+1):\\n            sum = 0\\n            for k in range(i, j):\\n                sum += nums[k]\\n            min_sum = min(min_sum, sum)\\n\\n    return min_sum'},\n",
       " {'task_id': 'HumanEval/120',\n",
       "  'solution': 'def maximum(arr, k):\\n    # Sort the array in descending order\\n    arr.sort(reverse=True)\\n    # Return the first k elements of the sorted array\\n    return arr[:k]'},\n",
       " {'task_id': 'HumanEval/126',\n",
       "  'solution': 'def is_sorted(lst):\\n    if len(lst) == 1:\\n        return True\\n    elif len(lst) == 2:\\n        return lst[0] < lst[1]\\n    else:\\n        for i in range(len(lst)-1):\\n            if lst[i] >= lst[i+1]:\\n                return False\\n        return True'},\n",
       " {'task_id': 'HumanEval/132',\n",
       "  'solution': 'def is_nested(string):\\n    stack = []\\n    for bracket in string:\\n        if bracket == \"[\":\\n            stack.append(bracket)\\n        elif bracket == \"]\":\\n            if len(stack) == 0 or stack[-1] != \"[\":\\n                return False\\n            stack.pop()\\n    \\n    return len(stack) != 0'},\n",
       " {'task_id': 'HumanEval/138',\n",
       "  'solution': 'def is_equal_to_sum_even(n):\\n    if n < 8:\\n        return False\\n    for i in range(2, n//2 + 1, 2):\\n        for j in range(2, n//2 + 1, 2):\\n            for k in range(2, n//2 + 1, 2):\\n                for l in range(2, n//2 + 1, 2):\\n                    if i + j + k + l == n:\\n                        return True\\n    return False'},\n",
       " {'task_id': 'HumanEval/144',\n",
       "  'solution': \"def simplify(x, n):\\n    num_x, den_x = map(int, x.split('/'))\\n    num_n, den_n = map(int, n.split('/'))\\n    num = num_x * num_n\\n    den = den_x * den_n\\n    return num % den == 0\"},\n",
       " {'task_id': 'HumanEval/150',\n",
       "  'solution': 'def is_prime(n):\\n    if n <= 1:\\n        return False\\n    for i in range(2, int(n**0.5) + 1):\\n        if n % i == 0:\\n            return False\\n    return True\\n\\ndef x_or_y(n, x, y):\\n    if is_prime(n):\\n        return x\\n    else:\\n        return y'},\n",
       " {'task_id': 'HumanEval/156',\n",
       "  'solution': \"def int_to_mini_roman(number):\\n    lookup = {\\n        1000: 'm',\\n        900: 'cm',\\n        500: 'd',\\n        400: 'cd',\\n        100: 'c',\\n        90: 'xc',\\n        50: 'l',\\n        40: 'xl',\\n        10: 'x',\\n        9: 'ix',\\n        5: 'v',\\n        4: 'iv',\\n        1: 'i'\\n    }\\n\\n    result = ''\\n    for value, symbol in sorted(lookup.items(), reverse=True):\\n        while number >= value:\\n            result += symbol\\n            number -= value\\n    return result.lower()\"},\n",
       " {'task_id': 'HumanEval/162',\n",
       "  'solution': \"import hashlib\\n\\ndef string_to_md5(text):\\n    if not text:\\n        return None\\n    else:\\n        md5hash = hashlib.md5()\\n        md5hash.update(text.encode('utf-8'))\\n        return md5hash.hexdigest()\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_san = []\n",
    "with open('./data/codeEval/code_sanitize/qwen-72b.jsonl','r') as f:\n",
    "    for line in f.readlines():\n",
    "        data_san.append(json.loads(line))\n",
    "data_san"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dir,subdir,files in os.walk('./data/codeEval/code_sanitize'):\n",
    "#     for file in files:\n",
    "#         shutil.move(os.path.join(dir,file),os.path.join(dir,file.replace('-sanitized','')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simcse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

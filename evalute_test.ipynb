{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json,time\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFINI_API = \"sk-c7cssl4bkglsrwf2\"\n",
    "INFINI_API_2 = \"sk-c7erk6qaqhkz5t72\"\n",
    "INFINI_API_List = [\"sk-c7cssl4bkglsrwf2\", \"sk-c7erk6qaqhkz5t72\",\"sk-c7etq7veyeie4dn2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelList = [\n",
    "    'llama-3-70b-instruct',\n",
    "    'llama-3-8b-instruct',\n",
    "    'chatglm3',\n",
    "    'chatglm2-6b',\n",
    "    'chatglm2-6b-32k',\n",
    "    'infini-megrez-7b',\n",
    "    'llama-2-7b-chat',\n",
    "    'llama-2-13b-chat',\n",
    "    'llama-2-70b-chat',\n",
    "    'llama-2-70b',\n",
    "    'baichuan2-7b-chat',\n",
    "    'baichuan2-13b-chat',\n",
    "    'baichuan2-13b-base',\n",
    "    'chatglm3-6b',\n",
    "    'chatglm3-6b-32k',\n",
    "    'chatglm3-6b-base',\n",
    "    'qwen-7b-chat',\n",
    "    'qwen-14b-chat',\n",
    "    'qwen-72b-chat',\n",
    "    'qwen-72b',\n",
    "    'qwen1.5-7b-chat',\n",
    "    'qwen1.5-14b-chat',\n",
    "    'qwen1.5-72b-chat',\n",
    "    'qwen1.5-72b',\n",
    "]\n",
    "evaluateModelList = ['llama-3-70b-instruct','qwen1.5-72b-chat',]\n",
    "answerModelList = [    \n",
    "    'llama-3-8b-instruct',\n",
    "    # 'chatglm3',\n",
    "    # 'chatglm2-6b',\n",
    "    # 'chatglm2-6b-32k',\n",
    "    'infini-megrez-7b',\n",
    "    'llama-2-7b-chat',\n",
    "    'llama-2-13b-chat',\n",
    "    'llama-2-70b-chat',\n",
    "    'llama-2-70b',\n",
    "    'baichuan2-7b-chat',\n",
    "    'baichuan2-13b-chat',\n",
    "    'baichuan2-13b-base',\n",
    "    # 'chatglm3-6b',\n",
    "    # 'chatglm3-6b-32k',\n",
    "    # 'chatglm3-6b-base',\n",
    "    'qwen-7b-chat',\n",
    "    'qwen-14b-chat',\n",
    "    'qwen-72b-chat',\n",
    "    'qwen-72b',\n",
    "    'qwen1.5-7b-chat',\n",
    "    'qwen1.5-14b-chat',\n",
    "    'qwen1.5-72b',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledgeList = ['Knowledge Memorization','Knowledge Understanding','Knowledge Applying','Knowledge Creating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLMCompletions(prompt,modelName:str = \"infini-megrez-7b\",INFINI_API = \"sk-c7cssl4bkglsrwf2\",returnContent:bool = True,**kwargs):\n",
    "    url = \"https://cloud.infini-ai.com/maas/\"+modelName+\"/nvidia/chat/completions\"\n",
    "    payload = {\n",
    "        \"model\": \"string\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"temperature\": kwargs[\"temperature\"] if \"temperature\" in kwargs else 0.7,\n",
    "        \"top_p\": kwargs[\"top_p\"] if 'top_p' in kwargs else 1,\n",
    "        \"top_k\": kwargs['top_k'] if 'top_k' in kwargs else -1,\n",
    "        \"n\": kwargs['n'] if 'n' in kwargs else 1,\n",
    "        \"max_tokens\": kwargs['max_tokens'] if 'max_tokens' in kwargs else None,\n",
    "        \"stop\": kwargs['stop'] if 'stop' in kwargs else None,\n",
    "        \"presence_penalty\": kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else 0,\n",
    "        \"frequency_penalty\": kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else 0\n",
    "    }\n",
    "    index = 0\n",
    "    while index < len(INFINI_API_List):\n",
    "        headers = {\n",
    "                'Content-Type': \"application/json\",\n",
    "                'Accept': \"*/*\",\n",
    "                'Authorization': \"Bearer \"+INFINI_API_List[index],\n",
    "        } \n",
    "        response = requests.post(url, json=payload, headers=headers,)\n",
    "        if response.status_code == 200:\n",
    "            response.encoding = 'utf-8'\n",
    "            data = response.json()\n",
    "            content = data['choices'][0]['message']['content']\n",
    "            content = content.replace(',\\n}','\\n}')\n",
    "            if returnContent:\n",
    "                return content\n",
    "            try:\n",
    "                content = json.loads(content)\n",
    "            except:\n",
    "                content = content.replace('\\n','')\n",
    "            data['choices'][0]['message']['content'] = content\n",
    "            \n",
    "            return json.dumps(data['choices'][0]['message']['content'])\n",
    "\n",
    "        else:\n",
    "            print(response.status_code)\n",
    "            try:\n",
    "                print(response.json())\n",
    "            except:\n",
    "                pass\n",
    "        index += 1\n",
    "    return \"Cannot connect to the model \"+modelName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format = {\n",
    "    'id':0,\n",
    "    'AnswerModel':'',\n",
    "    'input':'',\n",
    "    'actual_output':'',\n",
    "    'expected_output':None,\n",
    "    'context':None,\n",
    "    'retrieval_context':None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format_ins = {\n",
    "    'id':0,\n",
    "    'AnswerModel':'',\n",
    "    'input':'',\n",
    "    'actual_output':'',\n",
    "    'expected_output':None,\n",
    "    'context':None,\n",
    "    'retrieval_context':None,\n",
    "    'time':-1\n",
    "}\n",
    "def get_LLM_Reply(filepath,savePath,errorPath,fileName = None,):\n",
    "    with open(filepath) as f:\n",
    "        data = json.load(f)\n",
    "    instructions = data['adapter_spec']['instructions']\n",
    "    questionList = data['request_states']\n",
    "    errorItem = []\n",
    "    if not fileName:\n",
    "        fileName = Path(filepath).name\n",
    "    save = {'fileName':fileName,'class':knowledgeList[int(fileName[0])-1],'data':[]}\n",
    "    for index,item in enumerate(questionList):\n",
    "        if 'id' in item['instance']:\n",
    "            data_format_ins['id'] = item['instance']['id']\n",
    "        else:\n",
    "            data_format_ins['id'] = fileName+'%04d'% index\n",
    "        prompt = instructions+'\\n'+item['instance']['input']['text']\n",
    "        data_format_ins['input'] = prompt\n",
    "        print(prompt)\n",
    "        if item['instance']['references'][0]['tags'][0] == 'correct':\n",
    "            data_format_ins['expected_output'] = item['instance']['references'][0]['output']['text']\n",
    "        else:\n",
    "            data_format_ins['expected_output'] = None\n",
    "        for model in answerModelList:\n",
    "            data_format_ins['AnswerModel'] = model\n",
    "            print(model)\n",
    "            start = time.perf_counter_ns()\n",
    "            actual_output =  LLMCompletions(prompt,modelName=model)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = end-start\n",
    "            idx = 0\n",
    "            while actual_output == \"Cannot connect to the model \"+model and idx<2:\n",
    "                start = time.perf_counter_ns()\n",
    "                actual_output =  LLMCompletions(prompt,modelName=model)\n",
    "                end = time.perf_counter_ns()\n",
    "                delta = end-start\n",
    "                idx += 1\n",
    "            if actual_output == \"Cannot connect to the model \"+model:\n",
    "                \n",
    "                errorItem.append({'fileName':fileName,'id':data_format_ins['id'],\"AnswerModel\":model,\"input\":prompt,\"expected_output\":data_format_ins['expected_output']})\n",
    "                continue\n",
    "            print(idx,delta,actual_output,sep='\\t')\n",
    "            data_format_ins['actual_output'] = actual_output\n",
    "            data_format_ins['time'] = delta\n",
    "            save['data'].append(data_format_ins.copy())\n",
    "            print('*'*70)\n",
    "        print('+'*70)\n",
    "    errorItemFinal = []\n",
    "    while errorItem:\n",
    "        item = errorItem.pop()\n",
    "        data_format_ins['id'] = item['id']\n",
    "        model = item['AnswerModel']\n",
    "        data_format_ins['AnswerModel'] = model\n",
    "        prompt = item['input']\n",
    "        data_format_ins['input'] = prompt\n",
    "        data_format_ins['expected_output'] = item['expected_output']\n",
    "        start = time.perf_counter_ns()\n",
    "        actual_output =  LLMCompletions(prompt,modelName=model)\n",
    "        end = time.perf_counter_ns()\n",
    "        delta = end-start\n",
    "        idx = 0\n",
    "        while actual_output == \"Cannot connect to the model \"+model and idx<2:\n",
    "            print('\\t'+str(idx)+'\\ttest')\n",
    "            start = time.perf_counter_ns()\n",
    "            actual_output =  LLMCompletions(prompt,modelName=model)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = end-start\n",
    "            idx += 1\n",
    "        if actual_output == \"Cannot connect to the model \"+model:\n",
    "            errorItemFinal.append(item)\n",
    "            print(\"[error]:\\t\"+str(errorItemFinal[-1]))\n",
    "            continue\n",
    "        print(idx,delta,actual_output,sep='\\t')\n",
    "        data_format_ins['actual_output'] = actual_output\n",
    "        data_format_ins['time'] = delta\n",
    "        save['data'].append(data_format_ins.copy())\n",
    "    with open(savePath,'w',encoding='utf-8') as out:\n",
    "        json.dump(save,out)\n",
    "    if errorItemFinal:\n",
    "        error = {'fileName':fileName,'class':knowledgeList[int(fileName[0])-1],'data':[]}\n",
    "        for i in errorItemFinal:\n",
    "            error['data'].append(i)\n",
    "        with open(errorPath,'w',encoding='utf-8') as out:\n",
    "            json.dump(error,out)\n",
    "    print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1-1_2_high_freq_ent_sample.json', '1-2_1_low_freq_ent_sample.json', '1-3_r_1_simple_sample_sample.json', '2-1_COPEN++csj_sample.json', '2-2_COPEN++cpj_sample.json', '2-3_COPEN++cic_sample.json', '2-4_FewNERD++inter_sample.json', '2-4_FewNERD++intra_sample.json', '2-4_FewNERD++supervised_sample.json', '2-5_DocRED_sample.json', '2-6_MAVEN_sample.json', '2-7_MAVEN-ERE_sample.json', '2-8_r_DocRED_sample.json', '3-1_hotpotqa_sample.json', '3-2_2wikimultihopqa_sample.json', '3-3_musique_sample.json', '3-4_kqapro_sample.json', '3-5_KoRC++ood_sample.json', '3-6_r_KoRC++ood_sample.json', '4-1_without_triples_sample.json', '4-1_with_triples_sample.json', '4-2_r_without_triples_sample.json', '4-2_r_with_triples_sample.json', 'README.md']\n"
     ]
    }
   ],
   "source": [
    "for dirName,subDirName,fileNames in os.walk('E:\\\\Repository\\\\KoLA\\\\Sample_Data'):\n",
    "    print(fileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/4-2_r_with_triples_sample.json') as f:\n",
    "    data_view = json.load(f)\n",
    "len(data_view['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames =['1-1_2_high_freq_ent_sample.json', '1-2_1_low_freq_ent_sample.json', '1-3_r_1_simple_sample_sample.json', '2-1_COPEN++csj_sample.json', '2-2_COPEN++cpj_sample.json', '2-3_COPEN++cic_sample.json', '2-4_FewNERD++inter_sample.json', '2-4_FewNERD++intra_sample.json', '2-4_FewNERD++supervised_sample.json', '2-5_DocRED_sample.json', '2-6_MAVEN_sample.json', '2-7_MAVEN-ERE_sample.json', '2-8_r_DocRED_sample.json', '3-1_hotpotqa_sample.json', '3-2_2wikimultihopqa_sample.json', '3-3_musique_sample.json', '3-4_kqapro_sample.json', '3-5_KoRC++ood_sample.json', '3-6_r_KoRC++ood_sample.json', '4-1_without_triples_sample.json', '4-1_with_triples_sample.json', '4-2_r_without_triples_sample.json', '4-2_r_with_triples_sample.json', 'README.md']\n",
    "dirName = 'E:/Repository/KoLA/Sample_Data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileName = '1-1_2_high_freq_ent_sample.json'\n",
    "# for fileName in fileNames[:5]:\n",
    "#     get_LLM_Reply(os.path.join(dirName, fileName),'./data/'+fileName,'./data/'+fileName[:-5]+'Error'+'.json',fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fileName in fileNames[5:7]:\n",
    "#     get_LLM_Reply(os.path.join(dirName, fileName),'./data/'+fileName,'./data/'+fileName[:-5]+'Error'+'.json',fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dirName,subDirName,fileNames in os.walk('E:\\\\Repository\\\\KoLA\\\\Sample_Data'):\n",
    "#     regex = re.compile('\\.json$')\n",
    "#     for fileName in fileNames[1:]+[fileNames[0]]:\n",
    "#         if regex.search(fileName):\n",
    "#             get_LLM_Reply(os.path.join(dirName,fileName),'./data/'+fileName[:3]+'.json','./data/'+fileName[:3]+'Error'+'.json',fileName)\n",
    "dirName = 'E:\\\\Repository\\\\KoLA\\\\Sample_Data'            \n",
    "# fileNames = ['2-4_FewNERD++intra_sample.json','4-1_without_triples_sample.json','4-1_with_triples_sample.json','4-2_r_without_triples_sample.json','4-2_r_with_triples_sample.json',]\n",
    "# for fileName in fileNames:\n",
    "#     get_LLM_Reply(os.path.join(dirName,fileName),'./data/'+fileName,'./data/'+fileName[:-5]+'Error'+'.json',fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./MATH/MATH/test/counting_and_probability/0.json') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./MATH/MATH/train/precalculus/11.json') as f:\n",
    "    data2 = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The probability of rain tomorrow is $\\\\frac{1}{11}$.  What is the probability that it will not rain tomorrow?  Express your answer as a common fraction.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['problem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Find the distance between the planes $x - 3y + 3z = 8$ and $2x - 6y + 6z = 2.$'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['problem']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EvaluteModel Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deepeval login --confident-api-key KSPBSFpiD1ZYuuMIBjoTRUrV3VqsbcYmbiW9obh95cI="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\vllm\\lib\\site-packages\\deepeval\\__init__.py:41: UserWarning: You are using deepeval version 0.21.27, however version 0.21.32 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Optional,Dict, Mapping, Union\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "metrics_format = {\n",
    "    'metric_metadata':{\n",
    "        'metric':None,\n",
    "        'threshold':0,\n",
    "        'success':True,\n",
    "        'score':0.8,\n",
    "        'reason':'',\n",
    "        'strictMode': False,\n",
    "        'evaluationModel': 'CustomLLM',\n",
    "        'evaluationCost': 0\n",
    "    },\n",
    "    'metric_configuration': {\n",
    "        'threshold': 0.5,\n",
    "        'evaluation_model': 'CustomLLM',\n",
    "        'strict_mode': False,\n",
    "        'include_reason': True\n",
    "    }\n",
    "}\n",
    "\n",
    "data_format = {\n",
    "    'id':0,\n",
    "    'AnswerModel':'',\n",
    "    'input':'',\n",
    "    'actual_output':'',\n",
    "    'expected_output':None,\n",
    "    'context':None,\n",
    "    'retrieval_context':None,\n",
    "    'cached_metrics_data':[\n",
    "        {\n",
    "            'metric_metadata':{\n",
    "                'metric':None,\n",
    "                'threshold':0,\n",
    "                'success':True,\n",
    "                'score':0.8,\n",
    "                'reason':'',\n",
    "                'strictMode': False,\n",
    "                'evaluationModel': 'CustomLLM',\n",
    "                'evaluationCost': 0\n",
    "            },\n",
    "            'metric_configuration': {\n",
    "                'threshold': 0.5,\n",
    "                'evaluation_model': 'CustomLLM',\n",
    "                'strict_mode': False,\n",
    "                'include_reason': True\n",
    "            }\n",
    "        },\n",
    "        metrics_format\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatLLM(LLM):\n",
    "    @property\n",
    "    def modelName(self)->str:\n",
    "        return \"qwen1.5-72b-chat\"\n",
    "    @property\n",
    "    def INFINI_API_List(self)->List[str]:\n",
    "        return [\"sk-c7cssl4bkglsrwf2\", \"sk-c7erk6qaqhkz5t72\",\"sk-c7etq7veyeie4dn2\"]\n",
    "    @property\n",
    "    def temperature(self)->float:\n",
    "        return 0.7\n",
    "    @property\n",
    "    def top_p(self)->float:\n",
    "        return 0.1\n",
    "    @property\n",
    "    def top_k(self)->int:\n",
    "        return -1\n",
    "    @property\n",
    "    def n(self)->int:\n",
    "        return 1\n",
    "    @property\n",
    "    def max_tokens(self)->int:\n",
    "        return None\n",
    "    @property\n",
    "    def stop(self)->Optional[List[str]]:\n",
    "        return None\n",
    "    @property\n",
    "    def presence_penalty(self)->float:\n",
    "        return 0\n",
    "    @property\n",
    "    def frequency_penalty(self)->float:\n",
    "        return 0\n",
    "    def getHeader(self,index_api):  \n",
    "        headers = {\n",
    "            'Content-Type': \"application/json\",\n",
    "            'Accept': \"*/*\",\n",
    "            'Authorization': \"Bearer \"+self.INFINI_API_List[index_api%len(self.INFINI_API_List)],\n",
    "        }\n",
    "        return headers\n",
    "    @property\n",
    "    def _llm_type(self)->str:\n",
    "        return \"ChatLLM\"\n",
    "    @property\n",
    "    def _identifying_params(self)->Mapping[str,Any]:\n",
    "        _param_dict = {\n",
    "            \"modelName\":self.modelName,\n",
    "            \"INFINI_API\":self.getHeader(self.__fields__['index_api'] if 'index_api' in self.__fields__ else 0),\n",
    "            \"stream\":bool(self.stream),\n",
    "            \"temperature\":self.temperature,\n",
    "            \"top_p\":self.top_p,\n",
    "            \"top_k\":self.top_k,\n",
    "            \"n\":self.n,\n",
    "            \"max_tokens\":self.max_tokens,\n",
    "            \"stop\":self.stop,\n",
    "            \"presence_penalty\":self.presence_penalty,\n",
    "            \"frequency_penalty\":self.frequency_penalty,\n",
    "        }\n",
    "        return _param_dict\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]]= None, run_manager= None,**kwargs: Any) -> str:\n",
    "        url = \"https://cloud.infini-ai.com/maas/\"+str(self.modelName)+\"/nvidia/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"string\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"stream\": False,\n",
    "            \"temperature\": kwargs[\"temperature\"] if \"temperature\" in kwargs else self.temperature,\n",
    "            \"top_p\": kwargs[\"top_p\"] if 'top_p' in kwargs else self.top_p,\n",
    "            \"top_k\": kwargs['top_k'] if 'top_k' in kwargs else self.top_k,\n",
    "            \"n\": kwargs['n'] if 'n' in kwargs else self.n,\n",
    "            \"max_tokens\": kwargs['max_tokens'] if 'max_tokens' in kwargs else self.max_tokens,\n",
    "            \"stop\": stop if stop else self.stop,\n",
    "            \"presence_penalty\": kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else self.presence_penalty,\n",
    "            \"frequency_penalty\": kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else self.frequency_penalty\n",
    "        }\n",
    "        index = 0\n",
    "\n",
    "        if 'index_api' not in self.__fields__:\n",
    "            self.__fields__['index_api'] = -1\n",
    "        index_api = self.__fields__['index_api']+1\n",
    "        length = len(self.INFINI_API_List)\n",
    "        while index < length:\n",
    "            response = requests.post(url, json=payload, headers=self.getHeader(index_api))\n",
    "            if response.status_code == 200:\n",
    "                response.encoding = 'utf-8'\n",
    "                data = response.json()\n",
    "                # print(data)\n",
    "                content = data['choices'][0]['message']['content']\n",
    "                # print(content)\n",
    "                # path.append(content)\n",
    "                if isinstance(content,str):    \n",
    "                    content = content.replace(',\\n}','\\n}')\n",
    "                    content = content.replace(']\\n}',']}')\n",
    "                    content = content.replace('\\\\','\\\\\\\\')\n",
    "                    # path.append(content)\n",
    "                    flag = False\n",
    "                    if 'statements' in content:\n",
    "                        regex = re.compile('\\\"statements\\\":\\s+\\[.*\\]\\}',re.DOTALL)\n",
    "                        flag = True\n",
    "                    elif 'verdicts' in content:\n",
    "                        regex = re.compile('\\\"verdicts\\\":\\s+\\[.*\\]\\}',re.DOTALL)\n",
    "                        flag = True\n",
    "                    if flag:\n",
    "                        matchStr =regex.search(content)\n",
    "                        # print(matchStr)\n",
    "                        if matchStr:\n",
    "                            content = '{'+matchStr.group()\n",
    "                            # path.append(content)\n",
    "                try:\n",
    "                    content = json.loads(content)\n",
    "                    # path.append(content)\n",
    "                except:\n",
    "                    pass\n",
    "                if isinstance(content,str):\n",
    "                    return content\n",
    "                data['choices'][0]['message']['content'] = content\n",
    "                return json.dumps(data['choices'][0]['message']['content'])\n",
    "\n",
    "            index += 1\n",
    "            index_api =  (index_api+1)%length\n",
    "            self.__fields__['index_api'] = index_api\n",
    "            print(response.status_code)\n",
    "            try:\n",
    "                print(response.json())\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(1)\n",
    "        return \"Cannot connect to the model \"+self.modelName\n",
    "    def setParameter(self,**kwargs):\n",
    "        self.temperature = kwargs[\"temperature\"] if \"temperature\" in kwargs else self.temperature\n",
    "        self.top_p = kwargs['top_p'] if 'top_p' in  kwargs else self.top_p\n",
    "        self.top_k = kwargs['top_k'] if 'top_k' in  kwargs else self.top_k\n",
    "        self.n = kwargs['n'] if 'n' in kwargs else self.n\n",
    "        self.max_tokens = kwargs['max_tokens'] if 'max_tokens' in kwargs else self.max_tokens\n",
    "        self.stop = kwargs['stop'] if 'stop' in kwargs else self.stop\n",
    "        self.presence_penalty = kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else self.presence_penalty\n",
    "        self.frequency_penalty = kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else self.frequency_penalty\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLLM(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model\n",
    "    ):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        # print(\"prompt:\\t\"+prompt)\n",
    "        ret = chat_model.invoke(prompt)\n",
    "        idx = 0\n",
    "        if ret == \"Cannot connect to the model \"+self.get_model_name() and idx<2:\n",
    "            time.sleep(5)\n",
    "            ret = chat_model.invoke(prompt)\n",
    "            idx += 1\n",
    "        # print('*invoke\\t'+ret)\n",
    "        return ret\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        try:\n",
    "            return self.model.modelName\n",
    "        except:\n",
    "            return \"CustomLLM\"\n",
    "# Replace these with real values\n",
    "custom_model = ChatLLM()\n",
    "\n",
    "evaluateModel = CustomLLM(model=custom_model)\n",
    "# print(azure_openai.generate(\"Write me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qwen1.5-72b-chat'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateModel.get_model_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.benchmarks import MMLU\n",
    "from deepeval.benchmarks.tasks import MMLUTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   1%|          | 1/100 [00:00<01:27,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   2%|▏         | 2/100 [00:01<01:27,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   3%|▎         | 3/100 [00:02<01:26,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   4%|▍         | 4/100 [00:03<01:27,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   5%|▌         | 5/100 [00:04<01:25,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   6%|▌         | 6/100 [00:05<01:25,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   7%|▋         | 7/100 [00:06<01:28,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA, B, C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   8%|▊         | 8/100 [00:07<01:25,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   9%|▉         | 9/100 [00:08<01:23,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  10%|█         | 10/100 [00:09<01:22,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  11%|█         | 11/100 [00:10<01:21,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  12%|█▏        | 12/100 [00:10<01:20,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  13%|█▎        | 13/100 [00:13<01:58,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  14%|█▍        | 14/100 [00:14<01:47,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  15%|█▌        | 15/100 [00:15<01:38,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  16%|█▌        | 16/100 [00:16<01:31,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  17%|█▋        | 17/100 [00:17<01:24,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  18%|█▊        | 18/100 [00:17<01:20,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  19%|█▉        | 19/100 [00:18<01:17,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  20%|██        | 20/100 [00:19<01:16,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  21%|██        | 21/100 [00:20<01:14,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  22%|██▏       | 22/100 [00:21<01:12,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  23%|██▎       | 23/100 [00:22<01:11,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  24%|██▍       | 24/100 [00:23<01:10,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  25%|██▌       | 25/100 [00:25<01:42,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  26%|██▌       | 26/100 [00:26<01:30,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  27%|██▋       | 27/100 [00:27<01:21,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  28%|██▊       | 28/100 [00:28<01:15,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  29%|██▉       | 29/100 [00:29<01:12,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  30%|███       | 30/100 [00:30<01:08,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  31%|███       | 31/100 [00:31<01:06,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  32%|███▏      | 32/100 [00:32<01:04,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  33%|███▎      | 33/100 [00:33<01:02,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  34%|███▍      | 34/100 [00:33<01:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  35%|███▌      | 35/100 [00:34<00:58,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  36%|███▌      | 36/100 [00:36<01:19,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  37%|███▋      | 37/100 [00:51<05:25,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tCannot connect to the model qwen1.5-72b-chat\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  38%|███▊      | 38/100 [01:03<07:25,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  39%|███▉      | 39/100 [01:03<05:22,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  40%|████      | 40/100 [01:04<03:58,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  41%|████      | 41/100 [01:05<02:59,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  42%|████▏     | 42/100 [01:06<02:19,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  43%|████▎     | 43/100 [01:07<01:51,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  44%|████▍     | 44/100 [01:08<01:31,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  45%|████▌     | 45/100 [01:09<01:17,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  46%|████▌     | 46/100 [01:10<01:08,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  47%|████▋     | 47/100 [01:11<01:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  48%|████▊     | 48/100 [01:11<00:55,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  49%|████▉     | 49/100 [01:12<00:51,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  50%|█████     | 50/100 [01:15<01:11,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  51%|█████     | 51/100 [01:16<01:02,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  52%|█████▏    | 52/100 [01:17<00:55,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  53%|█████▎    | 53/100 [01:17<00:50,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  54%|█████▍    | 54/100 [01:18<00:47,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  55%|█████▌    | 55/100 [01:19<00:44,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  56%|█████▌    | 56/100 [01:20<00:42,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  57%|█████▋    | 57/100 [01:21<00:40,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  58%|█████▊    | 58/100 [01:22<00:39,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  59%|█████▉    | 59/100 [01:23<00:37,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  60%|██████    | 60/100 [01:24<00:36,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  61%|██████    | 61/100 [01:25<00:35,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  62%|██████▏   | 62/100 [01:27<00:51,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  63%|██████▎   | 63/100 [01:28<00:44,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  64%|██████▍   | 64/100 [01:29<00:40,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  65%|██████▌   | 65/100 [01:30<00:37,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  66%|██████▌   | 66/100 [01:31<00:34,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  67%|██████▋   | 67/100 [01:32<00:32,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  68%|██████▊   | 68/100 [01:33<00:30,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  69%|██████▉   | 69/100 [01:33<00:29,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  70%|███████   | 70/100 [01:34<00:28,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  71%|███████   | 71/100 [01:35<00:27,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  72%|███████▏  | 72/100 [01:36<00:26,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  73%|███████▎  | 73/100 [01:37<00:24,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  74%|███████▍  | 74/100 [01:51<02:05,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tCannot connect to the model qwen1.5-72b-chat\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  75%|███████▌  | 75/100 [02:03<02:52,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  76%|███████▌  | 76/100 [02:04<02:02,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  77%|███████▋  | 77/100 [02:05<01:28,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  78%|███████▊  | 78/100 [02:06<01:05,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  79%|███████▉  | 79/100 [02:07<00:49,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  80%|████████  | 80/100 [02:07<00:38,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  81%|████████  | 81/100 [02:08<00:30,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  82%|████████▏ | 82/100 [02:09<00:25,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  83%|████████▎ | 83/100 [02:10<00:21,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  84%|████████▍ | 84/100 [02:11<00:18,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  85%|████████▌ | 85/100 [02:12<00:15,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  86%|████████▌ | 86/100 [02:13<00:13,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  87%|████████▋ | 87/100 [02:15<00:18,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  88%|████████▊ | 88/100 [02:16<00:15,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  89%|████████▉ | 89/100 [02:17<00:12,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  90%|█████████ | 90/100 [02:18<00:11,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA, C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  91%|█████████ | 91/100 [02:19<00:09,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  92%|█████████▏| 92/100 [02:20<00:07,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  93%|█████████▎| 93/100 [02:21<00:06,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  94%|█████████▍| 94/100 [02:21<00:05,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  95%|█████████▌| 95/100 [02:22<00:04,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tA, B, C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  96%|█████████▌| 96/100 [02:23<00:03,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  97%|█████████▋| 97/100 [02:24<00:02,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  98%|█████████▊| 98/100 [02:25<00:01,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n",
      "429\n",
      "{'code': 20013, 'data': None, 'msg': 'Too Many Requests'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:  99%|█████████▉| 99/100 [02:27<00:01,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science: 100%|██████████| 100/100 [02:28<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*invoke\tC\n",
      "MMLU Task Accuracy (task=high_school_computer_science): 0.78\n",
      "Overall MMLU Accuracy: 0.78\n",
      "0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark = MMLU(tasks=[MMLUTask.HIGH_SCHOOL_COMPUTER_SCIENCE])\n",
    "results = benchmark.evaluate(model=evaluateModel )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.load_benchmark_dataset(task=[MMLUTask.HIGH_SCHOOL_COMPUTER_SCIENCE])[0].expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Input</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>Let x = 1. What is x &lt;&lt; 3 in Python 3?\\nA. 1\\n...</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>In Python 3, which of the following function c...</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>A user enters a Web address in a browser, and ...</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>Digital images are often represented by the re...</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>A programmer is writing a program that is inte...</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>Consider the following code segment, which use...</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>A digital photo file contains data representin...</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>In Python 3, what is ['a', 'Chemistry', 0, 1][...</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>Two computers are built by different manufactu...</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>Which of the following activities poses the gr...</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Task  \\\n",
       "0   high_school_computer_science   \n",
       "1   high_school_computer_science   \n",
       "2   high_school_computer_science   \n",
       "3   high_school_computer_science   \n",
       "4   high_school_computer_science   \n",
       "..                           ...   \n",
       "95  high_school_computer_science   \n",
       "96  high_school_computer_science   \n",
       "97  high_school_computer_science   \n",
       "98  high_school_computer_science   \n",
       "99  high_school_computer_science   \n",
       "\n",
       "                                                Input Prediction  Correct  \n",
       "0   Let x = 1. What is x << 3 in Python 3?\\nA. 1\\n...          C        1  \n",
       "1   In Python 3, which of the following function c...          A        1  \n",
       "2   A user enters a Web address in a browser, and ...          A        1  \n",
       "3   Digital images are often represented by the re...          D        0  \n",
       "4   A programmer is writing a program that is inte...          B        1  \n",
       "..                                                ...        ...      ...  \n",
       "95  Consider the following code segment, which use...          C        1  \n",
       "96  A digital photo file contains data representin...          B        1  \n",
       "97  In Python 3, what is ['a', 'Chemistry', 0, 1][...          C        0  \n",
       "98  Two computers are built by different manufactu...          D        1  \n",
       "99  Which of the following activities poses the gr...          C        1  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"C\"'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str('\"C\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task                               high_school_computer_science\n",
      "Input         Let x = 1. What is x << 3 in Python 3?\\nA. 1\\n...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 0, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, which of the following function c...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 1, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A user enters a Web address in a browser, and ...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 2, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Digital images are often represented by the re...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 3, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A programmer is writing a program that is inte...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 4, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Suppose the characters 0,1, . . . ,8,9,A,B,C,D...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 5, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A large data set contains information about al...\n",
      "Prediction                                            \"A, B, C\"\n",
      "Correct                                                       0\n",
      "Name: 6, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The code segment below uses the procedure IsFo...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 7, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A program is expressed in a programming langua...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 8, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, what is the output of print tuple...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 9, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Of the following potential benefits, which is ...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 10, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Historically, it has been observed that comput...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 11, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A programmer wrote the program below. The prog...\n",
      "Prediction         Cannot connect to the model qwen1.5-72b-chat\n",
      "Correct                                                       0\n",
      "Name: 12, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A computer simulation is created to simulate t...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 13, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Huffman coding assigns unique variable-length ...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 14, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, which of the following function c...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 15, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The code fragment below is intended to display...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 16, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A programmer uses code published online under ...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 17, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A new bank plans to make customer convenience ...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 18, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following best explains how data ...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 19, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A method is to be written to search an array f...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 20, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         What is the output of the statement \"a\" + \"ab\"...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 21, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In python 3, which of the following is floor d...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 22, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following school policies is most...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 23, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In a certain country, a person must be at leas...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 24, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         An online store uses 6-bit binary sequences to...\n",
      "Prediction         Cannot connect to the model qwen1.5-72b-chat\n",
      "Correct                                                       0\n",
      "Name: 25, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following programs is most likely...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 26, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the following code segment.\\n int num...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 27, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Two lists, list1 and list2, contain the names ...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 28, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Are Python variable names case-sensitive?\\nA. ...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 29, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A computer program uses 3 bits to represent in...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 30, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which is the largest asymptotically?\\nA. O(1)\\...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 31, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A programmer wrote the code segment below to d...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 32, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Both online newspapers and social media sites ...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 33, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A large Java program was tested extensively, a...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 34, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         What is the value of this python expression: 1...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 35, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Each student that enrolls at a school is assig...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 36, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, which of the following operator i...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 37, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following is the hexadecimal repr...\n",
      "Prediction         Cannot connect to the model qwen1.5-72b-chat\n",
      "Correct                                                       0\n",
      "Name: 38, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following spreadsheet functions w...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 39, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A certain computer game is played between a hu...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 40, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, what is the output of print list[...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 41, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the code segment below.\\n Line 1: IF ...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 42, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A sorted list of 120 integers is to be searche...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 43, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following is correct about Python...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 44, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Let x = 8. What is x>>1 in Python 3?\\nA. 3\\nB....\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 45, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The color of a pixel can be represented using ...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 46, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The boolean expression a[i] == max || !(max !=...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 47, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A programmer is deciding between using a linea...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 48, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which types of functions grow the slowest?\\nA....\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 49, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A student is recording a song on her computer....\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 50, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, what is the following function re...\n",
      "Prediction         Cannot connect to the model qwen1.5-72b-chat\n",
      "Correct                                                       0\n",
      "Name: 51, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which is the smallest asymptotically?\\nA. O(1)...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 52, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following is LEAST likely to indi...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 53, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The algorithm below is used to simulate the re...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 54, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which pillar of cybersecurity is compromised w...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 55, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The following procedure is intended to return ...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 56, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following is a true statement abo...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 57, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the following three scenarios, which ...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 58, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Let l = [1,2,3,4]. What is min(l) in Python3?\\...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 59, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Let l = [1,2,3,4]. What is max(l) in Python3?\\...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 60, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following is a characteristic of ...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 61, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the following numbers.\\n   ° Binary 1...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 62, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         What is the role of the compiler in the proces...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 63, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following is the most likely data...\n",
      "Prediction         Cannot connect to the model qwen1.5-72b-chat\n",
      "Correct                                                       0\n",
      "Name: 64, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         What is the output of \"abc\"[-1] in Python 3?\\n...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 65, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         An algorithm will be used to identify the maxi...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 66, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the following instance variable and m...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 67, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         What is the value of this python expression: 4...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 68, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Airmail Express charges for shipping small pac...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 69, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In the program below, y is a positive integer ...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 70, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A programmer is designing a program to catalog...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 71, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Let l = [1,2,3,4]. What is sum(l) in Python3?\\...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 72, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A Web site uses several strategies to prevent ...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 73, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         The procedure below is intended to display the...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 74, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         This question is based on the following declar...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 75, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In the procedure Mystery below, the parameter ...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 76, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         An Insect class is to be written, containing t...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 77, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A sorted list of numbers contains 500 elements...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 78, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, which of the following function s...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 79, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, what is the output of ['Hi!'] * 4...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 80, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the following assumptions about elect...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 81, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A search engine has a trend-tracking feature t...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 82, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, what is ['a', 'Chemistry', 0, 1][...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 83, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following best describes the prim...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 84, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following has the greatest potent...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 85, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following best explains what happ...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 86, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         If a, b, and c are integers, which of the foll...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 87, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Let l = [1,2,2,3,4]. In Python3, what is a pos...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 88, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A retailer that sells footwear maintains a sin...\n",
      "Prediction                                               \"A, C\"\n",
      "Correct                                                       0\n",
      "Name: 89, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         What is the output of 4*1**4 in python?\\nA. 4\\...\n",
      "Prediction                                                  \"A\"\n",
      "Correct                                                       0\n",
      "Name: 90, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Refer to the nextIntInRangemethod below:\\n /**...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 91, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, b = [11,13,15,17,19,21]; print(b[...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 92, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         An algorithm for finding the average of N numb...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 93, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A large list of numbers is to be sorted into a...\n",
      "Prediction                                            \"A, B, C\"\n",
      "Correct                                                       0\n",
      "Name: 94, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Consider the following code segment, which use...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 95, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         A digital photo file contains data representin...\n",
      "Prediction                                                  \"B\"\n",
      "Correct                                                       0\n",
      "Name: 96, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         In Python 3, what is ['a', 'Chemistry', 0, 1][...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 97, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Two computers are built by different manufactu...\n",
      "Prediction                                                  \"D\"\n",
      "Correct                                                       0\n",
      "Name: 98, dtype: object\n",
      "Task                               high_school_computer_science\n",
      "Input         Which of the following activities poses the gr...\n",
      "Prediction                                                  \"C\"\n",
      "Correct                                                       0\n",
      "Name: 99, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(benchmark.predictions)):\n",
    "    print(benchmark.predictions.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actual_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 25\u001b[0m\n\u001b[0;32m     12\u001b[0m metric2 \u001b[38;5;241m=\u001b[39m FaithfulnessMetric(\n\u001b[0;32m     13\u001b[0m     threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39mevaluateModel,\n\u001b[0;32m     15\u001b[0m     include_reason\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# strict_mode=True\u001b[39;00m\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# test_case = LLMTestCase(\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#     input=\"What if these shoes don't fit?\",\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#     actual_output=actual_output\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m     22\u001b[0m test_case \u001b[38;5;241m=\u001b[39m LLMTestCase(\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     24\u001b[0m     retrieval_context\u001b[38;5;241m=\u001b[39m[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolution\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[1;32m---> 25\u001b[0m     actual_output\u001b[38;5;241m=\u001b[39m\u001b[43mactual_output\u001b[49m,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# context=[\"All customers are eligible for a 30 day full refund at no extra cost.\"],\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# retrieval_context=[\"Only shoes can be refunded.\"],\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# latency=10.0\u001b[39;00m\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     30\u001b[0m test_case2 \u001b[38;5;241m=\u001b[39m LLMTestCase(\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mdata2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# expected_output=data2['solution'],\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# latency=10.0\u001b[39;00m\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m dataset \u001b[38;5;241m=\u001b[39m [test_case,test_case2]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'actual_output' is not defined"
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric,FaithfulnessMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Replace this with the actual output from your LLM application\n",
    "\n",
    "metric = AnswerRelevancyMetric(\n",
    "    threshold=0.5,\n",
    "    model=evaluateModel,\n",
    "    include_reason=True\n",
    ")\n",
    "metric2 = FaithfulnessMetric(\n",
    "    threshold=0.5,\n",
    "    model=evaluateModel,\n",
    "    include_reason=True,\n",
    "    # strict_mode=True\n",
    ")\n",
    "# test_case = LLMTestCase(\n",
    "#     input=\"What if these shoes don't fit?\",\n",
    "#     actual_output=actual_output\n",
    "# )\n",
    "test_case = LLMTestCase(\n",
    "    input=data['problem'],\n",
    "    retrieval_context=[data['solution']],\n",
    "    actual_output=actual_output,\n",
    "    # context=[\"All customers are eligible for a 30 day full refund at no extra cost.\"],\n",
    "    # retrieval_context=[\"Only shoes can be refunded.\"],\n",
    "    # latency=10.0\n",
    ")\n",
    "test_case2 = LLMTestCase(\n",
    "    input=data2['problem'],\n",
    "    # expected_output=data2['solution'],\n",
    "    actual_output=actual_output2,\n",
    "    # context=[\"All customers are eligible for a 30 day full refund at no extra cost.\"],\n",
    "    retrieval_context=[data2['solution']],\n",
    "    # latency=10.0\n",
    ")\n",
    "dataset = [test_case,test_case2]\n",
    "# for i in dataset:\n",
    "#     metric.measure(i)\n",
    "#     print(metric.__name__)\n",
    "#     print(i.input)\n",
    "#     print(i.actual_output)\n",
    "#     print(metric.score)\n",
    "#     print(metric.success)\n",
    "    \n",
    "#     metric2.measure(i)\n",
    "#     print(metric2.truths)\n",
    "#     print(metric2.reason)\n",
    "#     print(metric2.score)\n",
    "#     print(metric2.success)\n",
    "\n",
    "\n",
    "# or evaluate test cases in bulk\n",
    "evaluate(dataset, [metric,metric2,],run_async=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '{\"statements\": [\\n        \"To find the distance between two points in multivariate calculus, we use the formula for the distance between a point pair (x1, y1), (x2, y2) in n-dimensional space.\",\\n        \"Distance = sqrt[((x2 - x1)^2 + (y2 - y1)^2)]\",\\n        \"Here, we have two univariate polynomials in x and y, and we want to find the distance between the two polynomials in x and y.\",\\n        \"$x - 3y + 3z = 8$\",\\n        \"$2x - 6y + 6z = 2$\",\\n        \"To find the distance, we need to compare the coefficients of the two polynomials.\",\\n        \"The coefficients of the second polynomial with respect to x are -6 and 2.\",\\n        \"The coefficients of the second polynomial with respect to y are -3 and 0.\",\\n        \"So, the distance between the two polynomials is.\",\\n        \"$\\\\sqrt{(-6)^2 + 2^2} = \\\\sqrt{36 + 4} = \\\\sqrt{40} = 2\\\\sqrt{10}$\",\\n        \"Thus, the distance between the two polynomials is 2√10.\"\\n    ]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(text.replace('\\\\','\\\\\\\\'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./.deepeval-cache.json') as f:\n",
    "    text = f.read()\n",
    "json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMOutputSave().LLMCompletions(data['problem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://cloud.infini-ai.com/maas/qwen-7b-chat/nvidia/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"string\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write me a joke?\"\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"top_k\": -1,\n",
    "    \"n\": 1,\n",
    "    \"max_tokens\": None,\n",
    "    \"stop\": None,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"frequency_penalty\": 0\n",
    "}\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"Authorization\": \"Bearer \"+INFINI_API\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"请围绕一个法律主题，写一篇茹斯汀·特里耶导演2023年的电影《坠落的审判》的2000字影评，其中应包含不超过1/5的剧情梗概。\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in questions:\n",
    "    print(i,LLMCompletions(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatLLM(LLM):\n",
    "\n",
    "    modelName = \"infini-megrez-7b\"\n",
    "    INFINI_API = \"sk-c7cssl4bkglsrwf2\"\n",
    "    # hostname = \"cloud.infini-ai.com\"\n",
    "    temperature = 0.7\n",
    "    top_p = 1\n",
    "    top_k = -1\n",
    "    n = 1\n",
    "    max_tokens:int = None\n",
    "    stop:str = None\n",
    "    presence_penalty = 0\n",
    "    frequency_penalty = 0\n",
    "    \n",
    "    headers = {\n",
    "            'Content-Type': \"application/json\",\n",
    "            'Accept': \"*/*\",\n",
    "            'Authorization': \"Bearer \"+INFINI_API,\n",
    "    }\n",
    "    # def __init__(self,modelName:str = \"infini-megrez-7b\",\n",
    "    #         INFINI_API:str = \"sk-c7cssl4bkglsrwf2\",\n",
    "    #         hostname:str = \"cloud.infini-ai.com\",\n",
    "    #         temperature:float = 0.7,\n",
    "    #         top_p:float = 1,\n",
    "    #         top_k:int = -1,\n",
    "    #         n:int = 1,\n",
    "    #         max_tokens:int = None,\n",
    "    #         stop = None,\n",
    "    #         presence_penalty:float = 0,\n",
    "    #         frequency_penalty:float = 0):\n",
    "\n",
    "    #     self.modelName = modelName\n",
    "    #     self.INFINI_API = INFINI_API\n",
    "    #     self.hostname = hostname\n",
    "    #     self.temperature = temperature\n",
    "    #     self.top_p = top_p\n",
    "    #     self.top_k = top_k\n",
    "    #     self.n = n\n",
    "    #     self.max_tokens = max_tokens if max_tokens is not None else 'null'\n",
    "    #     self.stop = stop if stop is not None else 'null'\n",
    "    #     self.presence_penalty = presence_penalty\n",
    "    #     self.frequency_penalty = frequency_penalty\n",
    "    #     self.headers = {\n",
    "    #         'Content-Type': \"application/json\",\n",
    "    #         'Accept': \"*/*\",\n",
    "    #         'Authorization': \"Bearer \"+INFINI_API,\n",
    "    #     }\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self)->str:\n",
    "        return \"chatllm\"\n",
    "    @property\n",
    "    def _identifying_params(self)->Mapping[str,Any]:\n",
    "        _param_dict = {\n",
    "            \"modelName\":ChatLLM().modelName,\n",
    "            \"INFINI_API\":ChatLLM().INFINI_API,\n",
    "            \"stream\":bool(ChatLLM().stream),\n",
    "            \"temperature\":ChatLLM().temperature,\n",
    "            \"top_p\":ChatLLM().top_p,\n",
    "            \"top_k\":ChatLLM().top_k,\n",
    "            \"n\":ChatLLM().n,\n",
    "            \"max_tokens\":ChatLLM().max_tokens,\n",
    "            \"stop\":ChatLLM().stop,\n",
    "            \"presence_penalty\":ChatLLM().presence_penalty,\n",
    "            \"frequency_penalty\":ChatLLM().frequency_penalty,\n",
    "            \n",
    "        }\n",
    "        return _param_dict\n",
    "    @classmethod  \n",
    "    def _call(self, prompt: str, stop: Optional[List[str]]= None,  **kwargs: Any) -> str:\n",
    "        # temperature = kwargs[\"temperature\"] if \"temperature\" in kwargs else ChatLLM().temperature\n",
    "        # top_p = kwargs[\"top_p\"] if 'top_p' in kwargs else ChatLLM().top_p\n",
    "        # top_k = kwargs['top_k'] if 'top_k' in kwargs else ChatLLM().top_k\n",
    "        # n = kwargs['n'] if 'n' in kwargs else ChatLLM().n\n",
    "        # max_tokens = kwargs['max_tokens'] if 'max_tokens' in  kwargs else ChatLLM().max_tokens\n",
    "        # stop = stop if stop else ChatLLM().stop\n",
    "        # presence_penalty = kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else ChatLLM().presence_penalty\n",
    "        # frequency_penalty = kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else ChatLLM().frequency_penalty\n",
    "        # stream = 'false'\n",
    "        # temperature = 0.7\n",
    "        # top_p = 1\n",
    "        # top_k = -1\n",
    "        # n = 1\n",
    "        # max_tokens = 'null'\n",
    "        # stop = 'null'\n",
    "        # presence_penalty = 0\n",
    "        # frequency_penalty = 0\n",
    "        # conn = http.client.HTTPSConnection(ChatLLM().hostname)\n",
    "        # stream = 'false' if not bool(stream) else 'true'\n",
    "        # prompt = prompt.replace('\"','\\\\\"')\n",
    "        \n",
    "        url = \"https://cloud.infini-ai.com/maas/\"+ChatLLM().modelName+\"/nvidia/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"string\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"stream\": False,\n",
    "            \"temperature\": kwargs[\"temperature\"] if \"temperature\" in kwargs else ChatLLM().temperature,\n",
    "            \"top_p\": kwargs[\"top_p\"] if 'top_p' in kwargs else ChatLLM().top_p,\n",
    "            \"top_k\": kwargs['top_k'] if 'top_k' in kwargs else ChatLLM().top_k,\n",
    "            \"n\": kwargs['n'] if 'n' in kwargs else ChatLLM().n,\n",
    "            \"max_tokens\": kwargs['max_tokens'] if 'max_tokens' in kwargs else ChatLLM().max_tokens,\n",
    "            \"stop\": stop if stop else ChatLLM().stop,\n",
    "            \"presence_penalty\": kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else ChatLLM().presence_penalty,\n",
    "            \"frequency_penalty\": kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else ChatLLM().frequency_penalty\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=ChatLLM().headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['response']\n",
    "        else:\n",
    "            return \"请求模型\"\n",
    "        \n",
    "        # payload = f'{{\"model\": \"string\",\"messages\": [{{\"role\": \"user\",\"content\":\"{prompt}\"}}],\"stream\":{stream},\"temperature\": {temperature},\"top_p\": {top_p},\"top_k\": {top_k},\"n\":{n},\"max_tokens\": {max_tokens},\"stop\": {stop},\"presence_penalty\": {presence_penalty},\"frequency_penalty\": {frequency_penalty}}}'\n",
    "        # print(payload)\n",
    "        # conn.request(\"POST\",\"/maas/\"+ChatLLM().modelName+\"/nvidia/chat/completions\",payload.encode('utf-8'),ChatLLM().headers,)\n",
    "        \n",
    "        # res = conn.getresponse()\n",
    "        # if res.status == 200:\n",
    "        #     data = res.read().decode(\"utf-8\")\n",
    "        #     return data\n",
    "        #     # response = json.loads(data)\n",
    "        #     # return response\n",
    "        # else:\n",
    "        #     return \"请求模型\"\n",
    "        \n",
    "        \n",
    "    def setParameter(self,**kwargs):\n",
    "        # self.stream = kwargs[\"stream\"] if \"stream\" in kwargs else ChatLLM().stream\n",
    "        self.temperature = kwargs[\"temperature\"] if \"temperature\" in kwargs else ChatLLM().temperature\n",
    "        self.top_p = kwargs['top_p'] if 'top_p' in  kwargs else ChatLLM().top_p\n",
    "        self.top_k = kwargs['top_k'] if 'top_k' in  kwargs else ChatLLM().top_k\n",
    "        self.n = kwargs['n'] if 'n' in kwargs else ChatLLM().n\n",
    "        self.max_tokens = kwargs['max_tokens'] if 'max_tokens' in kwargs else ChatLLM().max_tokens\n",
    "        self.stop = kwargs['stop'] if 'stop' in kwargs else ChatLLM().stop\n",
    "        self.presence_penalty = kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else ChatLLM().presence_penalty\n",
    "        self.frequency_penalty = kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else ChatLLM().frequency_penalty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simcse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

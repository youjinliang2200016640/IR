{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,re,os,datetime,time,string\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from langchain.llms.base import LLM\n",
    "from typing import *\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "import traceback,random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evalplus.sanitize,evalplus.syncheck\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3SNRXQ5WMAQ2FREZH1HJ08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连接无问芯穷的API列表\n",
    "INFINI_API_List = [\"sk-c7cssl4bkglsrwf2\", \"sk-c7erk6qaqhkz5t72\",\"sk-c7etq7veyeie4dn2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3SP9PE51MESBZ17QHEKZEW",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelList = [\n",
    "    'llama-3-70b-instruct',\n",
    "    'llama-3-8b-instruct',\n",
    "    'chatglm3',\n",
    "    'chatglm2-6b',\n",
    "    'chatglm2-6b-32k',\n",
    "    'infini-megrez-7b',\n",
    "    'llama-2-7b-chat',\n",
    "    'llama-2-13b-chat',\n",
    "    'llama-2-70b-chat',\n",
    "    'llama-2-70b',\n",
    "    'baichuan2-7b-chat',\n",
    "    'baichuan2-13b-chat',\n",
    "    'baichuan2-13b-base',\n",
    "    'chatglm3-6b',\n",
    "    'chatglm3-6b-32k',\n",
    "    'chatglm3-6b-base',\n",
    "    'qwen-7b-chat',\n",
    "    'qwen-14b-chat',\n",
    "    'qwen-72b-chat',\n",
    "    'qwen-72b',\n",
    "    'qwen1.5-7b-chat',\n",
    "    'qwen1.5-14b-chat',\n",
    "    'qwen1.5-72b-chat',\n",
    "    'qwen1.5-72b',\n",
    "]\n",
    "modelProfileDict = {\n",
    "    'llama-3-70b-instruct':\"Llama3系列是由Meta开发的Llama系列全新的第三代版本，包含一系列预训练和指令调优的文本生成式模型。Llama3基于优化后的Transformer架构，预训练过程中使用了超过15T tokens的数据，调优后的模型使用SFT和RLHF，以更好地贴合人类对可用性和安全性的偏好。Llama3-70b-Instruct是此系列里，700亿参数的指令调优的模型，针对对话场景用例进行了优化，并在常见的行业基准测试中超越了许多可用的开源聊天模型。Llama3-70b-Instruct支持模型上下文至8k tokens，该模型的数据的知识截止日期为2023年12月。\",\n",
    "    'llama-3-8b-instruct':\"Llama3系列是由Meta开发的Llama系列全新的第三代版本，包含一系列预训练和指令调优的文本生成式模型。Llama3基于优化后的Transformer架构，预训练过程中使用了超过15T tokens的数据，调优后的模型使用SFT和RLHF，以更好地贴合人类对可用性和安全性的偏好。Llama3-8b-Instruct是此系列里，80亿参数的指令调优的模型，针对对话场景用例进行了优化，并在常见的行业基准测试中超越了许多可用的开源聊天模型。Llama3-8b-Instruct支持模型上下文至8k tokens，该模型的数据的知识截止日期为2023年3月。\",\n",
    "    'chatglm3':\"ChatGLM3是智谱AI与清华KEG实验室发布的闭源模型，支持 8K 上下文，经过海量中英标识符的预训练与人类偏好对齐训练，相比一代模型在 MMLU、C-Eval、GSM8K 分别取得了16%、36%、280%的提升，并登顶中文任务榜单C-Eval。适用于对知识量、推理能力、创造力要求较高的场景，比如广告文案、小说写作、知识类写作、代码生成等。\",\n",
    "    'chatglm2-6b':\"ChatGLM2-6b 是由智谱开发的 ChatGLM 系列的第二代版本，支持中英双语的60亿参数规模的开源模型。在保留了初代模型对话流畅、部署门槛较低等众多优秀特性的基础之上，在 MMLU、C-Eval、GSM8K、BBH等主流学术数据集上，都得到了显著的性能提升，并通过基于 FlashAttention 技术，将对话模型的上下文长度（Context Length）提升至 8k tokens，允许更多轮次的对话。\",\n",
    "    'chatglm2-6b-32k':\"ChatGLM2-6b 是由智谱开发的 ChatGLM 系列的第二代版本，支持中英双语的60亿参数规模的开源模型。相较于ChatGLM2-6B，ChatGLM2-6b-32k支持更长的模型上下文至32k tokens。\",\n",
    "    'infini-megrez-7b':\"由无问芯穹公司自主研发的70亿参数大语言模型。在逻辑推理、对话能力等方面有优秀的性能表现。配合无问芯穹自研高效推理引擎，同时支持Nvidia和AMD的GPU，具备更快的推理速度，在性能表现方面更上一层楼。\",\n",
    "    'llama-2-7b-chat':\"Llama2是由Meta开发并开源的大型语言模型（LLM）系列，这是一组从70亿到700亿参数不同规模、经过预训练和微调的生成式文本模型。架构层面，Llama2是一个使用优化型转换器架构的自动回归语言模型。调整后的版本使用有监督的微调（SFT）和带有人类反馈的强化学习（RLHF）以对齐人类对有用性和安全性的偏好。Llama2较Llama系列在多种学术数据集上有着更加不俗的表现，为大量其他模型提供了设计和开发的思路。Llama2-7b-chat是其中70亿的主流参数大小的模型，适用于chat场景，更擅长英文相关的内容。模型支持 4k tokens上下文。\",\n",
    "    'llama-2-13b-chat':\"Llama2是由Meta开发并开源的大型语言模型（LLM）系列，这是一组从70亿到700亿参数不同规模、经过预训练和微调的生成式文本模型。架构层面，Llama2是一个使用优化型转换器架构的自动回归语言模型。调整后的版本使用有监督的微调（SFT）和带有人类反馈的强化学习（RLHF）以对齐人类对有用性和安全性的偏好。Llama2较Llama系列在多种学术数据集上有着更加不俗的表现，为大量其他模型提供了设计和开发的思路。Llama2-7b-chat是其中70亿的主流参数大小的模型，适用于chat场景，更擅长英文相关的内容。模型支持 4k tokens上下文。\",\n",
    "    'llama-2-70b-chat':\"Llama2是由Meta开发并开源的大型语言模型（LLM）系列，这是一组从70亿到700亿参数不同规模、经过预训练和微调的生成式文本模型。架构层面，Llama2是一个使用优化型转换器架构的自动回归语言模型。调整后的版本使用有监督的微调（SFT）和带有人类反馈的强化学习（RLHF）以对齐人类对有用性和安全性的偏好。Llama2较Llama系列在多种学术数据集上有着更加不俗的表现，为大量其他模型提供了设计和开发的思路。Llama2-70b-chat是其中700亿参数的大模型，适用于chat场景，更擅长英文相关的内容，相较该系列里其他规模的的模型，有更强的综合能力。模型支持 4k tokens上下文。\",\n",
    "    'llama-2-70b':\"Llama2是由Meta开发并开源的大型语言模型（LLM）系列，这是一组从70亿到700亿参数不同规模、经过预训练和微调的生成式文本模型。架构层面，Llama2是一个使用优化型转换器架构的自动回归语言模型。调整后的版本使用有监督的微调（SFT）和带有人类反馈的强化学习（RLHF）以对齐人类对有用性和安全性的偏好。Llama2较Llama系列在多种学术数据集上有着更加不俗的表现，为大量其他模型提供了设计和开发的思路。Llama2-70b-base是其中700亿参数的基础大模型，适用于通用语言任务场景，更擅长英文相关的内容，相较该系列里其他规模的的模型，有更强的综合能力。模型支持 4k tokens上下文。\",\n",
    "    'baichuan2-7b-chat':\"Baichuan 2 是百川智能推出的新一代开源大语言模型，采用 2.6 万亿 Tokens 的高质量语料训练。Baichuan2-7b-chat是130亿参数规模用于对话的模型，在C-Eval、MMLU、CMMLU等主流评测数据集上都有不俗的表现。该基模型支持4k tokens上下文。\",\n",
    "    'baichuan2-13b-chat':\"Baichuan 2 是百川智能推出的新一代开源大语言模型，采用 2.6 万亿 Tokens 的高质量语料训练。Baichuan2-13b-chat是130亿参数规模用于对话的模型，在C-Eval、MMLU、CMMLU等主流评测数据集上都有不俗的表现。该基模型支持8k tokens上下文。\",\n",
    "    'baichuan2-13b-base':\"Baichuan 2 是百川智能推出的新一代开源大语言模型，采用 2.6 万亿 Tokens 的高质量语料训练。Baichuan2-13b-base是130亿参数规模的基础模型，适用于通用对话和文本续写，较chat模型更适合于复杂场景的微调后使用。该基模型支持4k tokens上下文。\",\n",
    "    'chatglm3-6b':\"ChatGLM3-6b 是由智谱开发的 ChatGLM 系列最新一代的60亿参数规模的开源模型。ChatGLM3采用了全新设计的 Prompt 格式，并原生支持工具调用（Function Call）、代码执行（Code Interpreter）和 Agent 任务等复杂场景。模型支持 8k tokens上下文。\",\n",
    "    'chatglm3-6b-32k':\"ChatGLM3-6b 是由智谱开发的 ChatGLM 系列最新一代的60亿参数规模的开源模型。相较于ChatGLM之前系列的模型，ChatGLM3采用了更多样的训练数据，并原生支持工具调用（Function Call）、代码执行（Code Interpreter）和 Agent 任务等复杂场景。ChatGLM3-6b-32k在ChatGLM3-6b 基础上进一步强化了对于长文本的理解能力，能够更好的处理最多32k tokens长度的上下文。\",\n",
    "    'chatglm3-6b-base':\"ChatGLM3-6b-base 是由智谱开发的 ChatGLM 系列最新一代的60亿参数规模的开源的基础模型。ChatGLM3-6B-Base 采用了更多样的训练数据、更充分的训练步数和更合理的训练策略。基础模型更适合于复杂场景的微调后使用，该基模型支持32k tokens上下文。\",\n",
    "    'qwen-7b-chat':\"通义千问-7B-chat（Qwen-7B-chat）是阿里云研发的基于Transformer，在超大规模的预训练数据上进行训练得到的70亿参数规模的大语言模型。相较于Qwen-7B-Base模型，Qwen-7B-chat是针对于对话场景以及一些常见的智能对话需求指令对齐的AI助手模型，在更多文本相关的问答场景上有更好的指令跟随能力。模型支持 8k tokens上下文。\",\n",
    "    'qwen-14b-chat':\"通义千问-14B-chat（Qwen-14B-chat）是阿里云研发的基于Transformer，在超大规模的预训练数据上进行训练得到的140亿参数规模的大语言模型。相较于Qwen-14B-Base模型，Qwen-14B-chat是针对于对话场景以及一些常见的智能对话需求指令对齐的AI助手模型，在更多文本相关的问答场景上有更好的指令跟随能力。模型支持 8k tokens上下文。\",\n",
    "    'qwen-72b-chat':\"通义千问-72B-chat（Qwen-72B-chat）是阿里云研发的基于Transformer，在超大规模的预训练数据上进行训练得到的720亿参数规模的大语言模型。相较于Qwen-72B-Base模型，Qwen-72B-chat是针对于对话场景以及一些常见的智能对话需求指令对齐的AI助手模型，在更多文本相关的问答场景上有更好的指令跟随能力。模型支持 32k tokens上下文。\",\n",
    "    'qwen-72b':\"通义千问-72B（Qwen-72B）是阿里云研发的通义千问大模型系列的720亿参数规模的模型。Qwen-72B是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。模型支持 32k tokens上下文。\",\n",
    "    'qwen1.5-7b-chat':\"Qwen1.5系列是Qwen2的Beta版本，是一个基于Transformer的仅解码语言模型，在海量数据上进行预训练。与之前发布的Qwen系列版本相比，Qwen1.5系列base与chat模型均能支持多种语言，在整体聊天和基础能力上都得到了提升，并且支持32k tokens上下文。Qwen1.5-7b-chat是其中专用于chat场景的70亿参数的主流大小模型。\",\n",
    "    'qwen1.5-14b-chat':\"Qwen1.5系列是Qwen2的Beta版本，是一个基于Transformer的仅解码语言模型，在海量数据上进行预训练。与之前发布的Qwen系列版本相比，Qwen1.5系列base与chat模型均能支持多种语言，在整体聊天和基础能力上都得到了提升，并且支持32k tokens上下文。Qwen1.5-14b-chat是其中专用于chat场景的140亿参数的主流大小模型。\",\n",
    "    'qwen1.5-72b-chat':\"Qwen1.5系列是Qwen2的Beta版本，是一个基于Transformer的仅解码语言模型，在海量数据上进行预训练。与之前发布的Qwen系列版本相比，Qwen1.5系列base与chat模型均能支持多种语言，在整体聊天和基础能力上都得到了提升，并且支持32k tokens上下文。Qwen1.5-72b-chat是其中专用于chat场景的720亿参数的大模型。\",\n",
    "    'qwen1.5-72b':\"Qwen1.5系列是Qwen2的Beta版本，是一个基于Transformer的仅解码语言模型，在海量数据上进行预训练。与之前发布的Qwen系列版本相比，Qwen1.5系列base与chat模型均能支持多种语言，在整体聊天和基础能力上都得到了提升，并且支持32k tokens上下文。Qwen1.5-72b-base是其中的720亿参数的基础大模型，适合多种场景的使用。\",\n",
    "}\n",
    "evaluateModelList = ['llama-3-70b-instruct','qwen1.5-72b-chat',]\n",
    "# 测评模型列表\n",
    "answerModelList = [    \n",
    "    'llama-3-8b-instruct',\n",
    "    'baichuan2-7b-chat',\n",
    "    'baichuan2-13b-chat',\n",
    "    'baichuan2-13b-base',\n",
    "    'infini-megrez-7b', \n",
    "    'qwen-7b-chat',\n",
    "    'qwen-14b-chat',\n",
    "    'qwen-72b-chat',\n",
    "    'qwen-72b',\n",
    "    'qwen1.5-7b-chat',\n",
    "    'qwen1.5-14b-chat',\n",
    "    'qwen1.5-72b',\n",
    "    'llama-2-70b',\n",
    "    'llama-2-7b-chat',\n",
    "    'llama-2-13b-chat',\n",
    "    'llama-2-70b-chat'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KoLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3SPW6ABQX9J20163521X4Y",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledgeList = ['Knowledge Memorization','Knowledge Understanding','Knowledge Applying','Knowledge Creating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Model Reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3SQ4DW0S67QH7AYG9VNJYV",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "def LLMCompletions(prompt:str,modelName:str = \"infini-megrez-7b\",INFINI_API_List:List[str] = [\"sk-c7cssl4bkglsrwf2\", \"sk-c7erk6qaqhkz5t72\",\"sk-c7etq7veyeie4dn2\"],returnContent:bool = True,**kwargs)->str:\n",
    "    \"\"\"_summary_\n",
    "        invoke the model `modelName` with the `prompt` and configuration in kwargs to get the reply\n",
    "    Args:\n",
    "        prompt (str): question profile\n",
    "        modelName (str, optional): the model name that will be called. Defaults to \"infini-megrez-7b\".\n",
    "        INFINI_API_List (List[str], optional): _description_. Defaults to [\"sk-c7cssl4bkglsrwf2\", \"sk-c7erk6qaqhkz5t72\",\"sk-c7etq7veyeie4dn2\"].\n",
    "        returnContent (bool, optional): whether return the model reply string directly or not. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        str: return the model reply string \n",
    "    \"\"\"\n",
    "    global index\n",
    "    url = \"https://cloud.infini-ai.com/maas/\"+modelName+\"/nvidia/chat/completions\"\n",
    "    payload = {\n",
    "        \"model\": modelName,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"temperature\": kwargs[\"temperature\"] if \"temperature\" in kwargs else 0.7,\n",
    "        \"top_p\": kwargs[\"top_p\"] if 'top_p' in kwargs else 1,\n",
    "        \"top_k\": kwargs['top_k'] if 'top_k' in kwargs else -1,\n",
    "        \"n\": kwargs['n'] if 'n' in kwargs else 1,\n",
    "        \"max_tokens\": kwargs['max_tokens'] if 'max_tokens' in kwargs else None,\n",
    "        \"stop\": kwargs['stop'] if 'stop' in kwargs else None,\n",
    "        \"presence_penalty\": kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else 0,\n",
    "        \"frequency_penalty\": kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else 0\n",
    "    }\n",
    "    idx = 0\n",
    "    while idx < len(INFINI_API_List):\n",
    "        headers = {\n",
    "                'Content-Type': \"application/json\",\n",
    "                'Accept': \"*/*\",\n",
    "                'Authorization': \"Bearer \"+INFINI_API_List[index%len(INFINI_API_List)],\n",
    "        } \n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            response.encoding = 'utf-8'\n",
    "            data = response.json()\n",
    "            content = data['choices'][0]['message']['content']\n",
    "            if isinstance(content,str):\n",
    "                content = content.replace(',\\n}','\\n}')\n",
    "                content = content.replace(']\\n}',']}')\n",
    "                content = content.replace('\\\\','\\\\\\\\')\n",
    "            if returnContent:\n",
    "                return content\n",
    "            try:\n",
    "                content = json.loads(content)\n",
    "            except:\n",
    "                pass\n",
    "            data['choices'][0]['message']['content'] = content\n",
    "            if isinstance(content,str):\n",
    "                return content\n",
    "            \n",
    "            return json.dumps(data['choices'][0]['message']['content'])\n",
    "        else:\n",
    "            print(response.status_code)\n",
    "            try:\n",
    "                print(response.json())\n",
    "            except:\n",
    "                pass\n",
    "        index = (index + 1) % len(INFINI_API_List)\n",
    "        idx += 1\n",
    "    return \"Cannot connect to the model \"+modelName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### the first time to get the model reply "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3SQ4DW6YA9S51SVHR3DK87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format_ins = {\n",
    "    'id':0,\n",
    "    'AnswerModel':'',\n",
    "    'input':'',\n",
    "    'actual_output':'',\n",
    "    'expected_output':None,\n",
    "    'retrieval_context':None,\n",
    "    'time':-1\n",
    "}\n",
    "def get_LLM_Reply_KoLA(filepath:Union[str,Path],savePath:Union[str,Path],errorPath:Union[str,Path],fileName:str = None,)->None:\n",
    "    \"\"\"_summary_\n",
    "        get evaluation questions from `filepath` and save the reply of the model in answerModelList to `savePath` ,and error item to `errorPath`\n",
    "    Args:\n",
    "        filepath (Union[str,Path]): _description_\n",
    "        savePath (Union[str,Path]): the path to save LLM reply\n",
    "        errorPath (Union[str,Path]): the path to save error items\n",
    "        fileName (str, optional): _description_. Defaults to None.\n",
    "    \"\"\"\n",
    "    with open(filepath) as f:\n",
    "        data = json.load(f)\n",
    "    instructions = data['adapter_spec']['instructions']\n",
    "    questionList = data['request_states']\n",
    "    errorItem = []\n",
    "    if not fileName:\n",
    "        fileName = Path(filepath).name\n",
    "    save = {'fileName':fileName,'class':knowledgeList[int(fileName[0])-1],'data':[]}\n",
    "    for index,item in enumerate(questionList):\n",
    "        if 'id' in item['instance']:\n",
    "            data_format_ins['id'] = item['instance']['id']\n",
    "        else:\n",
    "            data_format_ins['id'] = fileName+'%04d'% index\n",
    "        prompt = instructions+'\\n'+item['instance']['input']['text']\n",
    "        data_format_ins['input'] = prompt\n",
    "        print(prompt)\n",
    "        if item['instance']['references'][0]['tags'][0] == 'correct':\n",
    "            data_format_ins['expected_output'] = item['instance']['references'][0]['output']['text']\n",
    "        else:\n",
    "            data_format_ins['expected_output'] = None\n",
    "        for model in answerModelList:\n",
    "            data_format_ins['AnswerModel'] = model\n",
    "            print(model)\n",
    "            start = time.perf_counter_ns()\n",
    "            actual_output =  LLMCompletions(prompt,modelName=model)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = end-start\n",
    "            idx = 0\n",
    "            while actual_output == \"Cannot connect to the model \"+model and idx<2:\n",
    "                start = time.perf_counter_ns()\n",
    "                actual_output =  LLMCompletions(prompt,modelName=model)\n",
    "                end = time.perf_counter_ns()\n",
    "                delta = end-start\n",
    "                idx += 1\n",
    "            if actual_output == \"Cannot connect to the model \"+model:\n",
    "                \n",
    "                errorItem.append({'fileName':fileName,'id':data_format_ins['id'],\"AnswerModel\":model,\"input\":prompt,\"expected_output\":data_format_ins['expected_output']})\n",
    "                continue\n",
    "            print(idx,delta,actual_output,sep='\\t')\n",
    "            data_format_ins['actual_output'] = actual_output\n",
    "            data_format_ins['time'] = delta\n",
    "            save['data'].append(data_format_ins.copy())\n",
    "            print('*'*70)\n",
    "        print('+'*70)\n",
    "    errorItemFinal = []\n",
    "    while errorItem:\n",
    "        item = errorItem.pop()\n",
    "        data_format_ins['id'] = item['id']\n",
    "        model = item['AnswerModel']\n",
    "        data_format_ins['AnswerModel'] = model\n",
    "        prompt = item['input']\n",
    "        data_format_ins['input'] = prompt\n",
    "        data_format_ins['expected_output'] = item['expected_output']\n",
    "        start = time.perf_counter_ns()\n",
    "        actual_output =  LLMCompletions(prompt,modelName=model)\n",
    "        end = time.perf_counter_ns()\n",
    "        delta = end-start\n",
    "        idx = 0\n",
    "        while actual_output == \"Cannot connect to the model \"+model and idx<2:\n",
    "            print('\\t'+str(idx)+'\\ttest')\n",
    "            start = time.perf_counter_ns()\n",
    "            actual_output =  LLMCompletions(prompt,modelName=model)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = end-start\n",
    "            idx += 1\n",
    "        if actual_output == \"Cannot connect to the model \"+model:\n",
    "            errorItemFinal.append(item)\n",
    "            print(\"[error]:\\t\"+str(errorItemFinal[-1]))\n",
    "            continue\n",
    "        print(idx,delta,actual_output,sep='\\t')\n",
    "        data_format_ins['actual_output'] = actual_output\n",
    "        data_format_ins['time'] = delta\n",
    "        save['data'].append(data_format_ins.copy())\n",
    "    with open(savePath,'w',encoding='utf-8') as out:\n",
    "        json.dump(save,out)\n",
    "    if errorItemFinal:\n",
    "        error = {'fileName':fileName,'class':knowledgeList[int(fileName[0])-1],'data':[]}\n",
    "        for i in errorItemFinal:\n",
    "            error['data'].append(i)\n",
    "        with open(errorPath,'w',encoding='utf-8') as out:\n",
    "            json.dump(error,out)\n",
    "    print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01HX3SQ4DW77FZHQ2BVP5QVCTK",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1-1_2_high_freq_ent_sample.json', '1-2_1_low_freq_ent_sample.json', '1-3_r_1_simple_sample_sample.json', '2-1_COPEN++csj_sample.json', '2-2_COPEN++cpj_sample.json', '2-3_COPEN++cic_sample.json', '2-4_FewNERD++inter_sample.json', '2-4_FewNERD++intra_sample.json', '2-4_FewNERD++supervised_sample.json', '2-5_DocRED_sample.json', '2-6_MAVEN_sample.json', '2-7_MAVEN-ERE_sample.json', '2-8_r_DocRED_sample.json', '3-1_hotpotqa_sample.json', '3-2_2wikimultihopqa_sample.json', '3-3_musique_sample.json', '3-4_kqapro_sample.json', '3-5_KoRC++ood_sample.json', '3-6_r_KoRC++ood_sample.json', '4-1_without_triples_sample.json', '4-1_with_triples_sample.json', '4-2_r_without_triples_sample.json', '4-2_r_with_triples_sample.json', 'README.md']\n"
     ]
    }
   ],
   "source": [
    "for dirName,subDirName,fileNames in os.walk('E:\\\\Repository\\\\KoLA\\\\Sample_Data'):\n",
    "    print(fileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3SQ4DWDX2K27D72Z71CY1C",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames =['1-1_2_high_freq_ent_sample.json', '1-2_1_low_freq_ent_sample.json', '1-3_r_1_simple_sample_sample.json', '2-1_COPEN++csj_sample.json', '2-2_COPEN++cpj_sample.json', '2-3_COPEN++cic_sample.json', '2-4_FewNERD++inter_sample.json', '2-4_FewNERD++intra_sample.json', '2-4_FewNERD++supervised_sample.json', '2-5_DocRED_sample.json', '2-6_MAVEN_sample.json', '2-7_MAVEN-ERE_sample.json', '2-8_r_DocRED_sample.json', '3-1_hotpotqa_sample.json', '3-2_2wikimultihopqa_sample.json', '3-3_musique_sample.json', '3-4_kqapro_sample.json', '3-5_KoRC++ood_sample.json', '3-6_r_KoRC++ood_sample.json', '4-1_without_triples_sample.json', '4-1_with_triples_sample.json', '4-2_r_without_triples_sample.json', '4-2_r_with_triples_sample.json']\n",
    "dirName = 'E:/Repository/KoLA/Sample_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3SQ4DW1T2MGJ6MHHDZ3G41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileName in fileNames:\n",
    "    get_LLM_Reply_KoLA(os.path.join(dirName, fileName),'./data/KoLA/save/'+fileName,'./data/KoLA/error/'+fileName.replace(\".json\",\"\")+'Error'+'.json',fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### handle error items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3TVD0KFQFHV3A88AYF7Y37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format_ins = {\n",
    "    'id':0,\n",
    "    'AnswerModel':'',\n",
    "    'input':'',\n",
    "    'actual_output':'',\n",
    "    'expected_output':None,\n",
    "    'retrieval_context':None,\n",
    "    'time':-1\n",
    "}\n",
    "def joinErrorToData(errorFile:Union[str,Path],saveFile:Union[str,Path])->None:\n",
    "    \"\"\"rerun the error items in `saveFile` and append results to 'saveFile'\n",
    "\n",
    "    Args:\n",
    "        errorFile (Union[str,Path]): \n",
    "        saveFile (Union[str,Path]): \n",
    "    \"\"\"\n",
    "    with open(errorFile, 'r') as ef:\n",
    "        data_ef = json.load(ef)\n",
    "    fileName = data_ef['fileName']\n",
    "    with open(saveFile) as sf:\n",
    "        data_sf = json.load(sf)\n",
    "    if fileName != data_sf['fileName']:\n",
    "        print('FileName not match')\n",
    "        return \n",
    "    if not data_ef['data']:\n",
    "        print('The Errors of this ErrorFile all have been solved!')\n",
    "        return \n",
    "    errorItem = []\n",
    "    for item in data_ef['data']:\n",
    "        data_format_ins['id'] = item['id']\n",
    "        model = item['AnswerModel']\n",
    "        data_format_ins['AnswerModel'] = model\n",
    "        prompt = item['input']\n",
    "        data_format_ins['input'] = prompt\n",
    "        data_format_ins['expected_output'] = item['expected_output']\n",
    "        start = time.perf_counter_ns()\n",
    "        actual_output =  LLMCompletions(prompt,modelName=model,INFINI_API=INFINI_API_2)\n",
    "        end = time.perf_counter_ns()\n",
    "        delta = end-start\n",
    "        idx = 0\n",
    "        while actual_output == \"Cannot connect to the model \"+model and idx<2:\n",
    "            start = time.perf_counter_ns()\n",
    "            actual_output =  LLMCompletions(prompt,modelName=model,INFINI_API=INFINI_API_2)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = end-start\n",
    "            idx += 1\n",
    "        if actual_output == \"Cannot connect to the model \"+model:\n",
    "            errorItem.append(item)\n",
    "            print(\"[error]:\\t\"+str(errorItem[-1]))\n",
    "            continue\n",
    "        print(actual_output)\n",
    "        data_format_ins['time'] = delta\n",
    "        data_format_ins['actual_output'] = actual_output\n",
    "        data_sf['data'].append(data_format_ins.copy())\n",
    "    data_ef['data'] = errorItem\n",
    "    with open(saveFile,'w') as saveF:\n",
    "        json.dump(data_sf,saveF)\n",
    "    with open(errorFile,'w') as error:\n",
    "        json.dump(data_ef,error)\n",
    "    if errorItem:\n",
    "        print(\"There are still some errors! \")\n",
    "    else:\n",
    "        print('The Errors of this ErrorFile all have been solved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01HX3V2K9NM7NFDB4JMJ0S5MTV",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joinErrorToData('./data/KoLA/error/4-2_r_with_triples_sampleError.json','./data/KoLA/save/4-2_r_with_triples_sample.json')\n",
    "for dir,subdir,files in os.walk(\"./data/KoLA/error\"):\n",
    "    for file in files:\n",
    "        joinErrorToData(os.path.join(dir,file),os.path.join('./data/KoLA/save',file.replace(\"Error.json\",\".json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3TVVKZ2KS6HJYANFCPJ066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDeprecatedModel(filePath:Union[str,Path]):\n",
    "    \"\"\"remove the deprecated evaluated model  from the `filePath`\n",
    "\n",
    "    Args:\n",
    "        filePath (Union[str,Path]): \n",
    "    \"\"\"\n",
    "    with open(filePath) as f:\n",
    "        data = json.load(f)\n",
    "    new_data = []\n",
    "    for item in data['data']:\n",
    "        if item['AnswerModel']  in answerModelList:\n",
    "            new_data.append(item)\n",
    "    data['data'] = new_data[:]\n",
    "    with open(filePath,'w') as f:\n",
    "        json.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3V8Y902GFJG2SJPS29K4WT",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removeDeprecatedModel('./data/1-2_1_low_freq_ent_sample.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3VDTZQFJN1CHAPJNJJV3T9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric,FaithfulnessMetric,HallucinationMetric,BaseMetric\n",
    "from deepeval.test_case import LLMTestCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3VCEAFS2WN25CMGPCXH240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatLLM(LLM):\n",
    "    @property\n",
    "    def modelName(self)->str:\n",
    "        return \"qwen1.5-72b-chat\"\n",
    "    @property\n",
    "    def INFINI_API_List(self)->List[str]:\n",
    "        return [\"sk-c7cssl4bkglsrwf2\", \"sk-c7erk6qaqhkz5t72\",\"sk-c7etq7veyeie4dn2\"]\n",
    "    @property\n",
    "    def temperature(self)->float:\n",
    "        return 0.7\n",
    "    @property\n",
    "    def top_p(self)->float:\n",
    "        return 0.1\n",
    "    @property\n",
    "    def top_k(self)->int:\n",
    "        return -1\n",
    "    @property\n",
    "    def n(self)->int:\n",
    "        return 1\n",
    "    @property\n",
    "    def max_tokens(self)->int:\n",
    "        return None\n",
    "    @property\n",
    "    def stop(self)->Optional[List[str]]:\n",
    "        return None\n",
    "    @property\n",
    "    def presence_penalty(self)->float:\n",
    "        return 0\n",
    "    @property\n",
    "    def frequency_penalty(self)->float:\n",
    "        return 0\n",
    "    def getHeader(self,index_api):  \n",
    "        headers = {\n",
    "            'Content-Type': \"application/json\",\n",
    "            'Accept': \"*/*\",\n",
    "            'Authorization': \"Bearer \"+self.INFINI_API_List[index_api%len(self.INFINI_API_List)],\n",
    "        }\n",
    "        return headers\n",
    "    @property\n",
    "    def _llm_type(self)->str:\n",
    "        return \"ChatLLM\"\n",
    "    @property\n",
    "    def _identifying_params(self)->Mapping[str,Any]:\n",
    "        _param_dict = {\n",
    "            \"modelName\":self.modelName,\n",
    "            \"INFINI_API\":self.getHeader(self.__fields__['index_api'] if 'index_api' in self.__fields__ else 0),\n",
    "            \"stream\":bool(self.stream),\n",
    "            \"temperature\":self.temperature,\n",
    "            \"top_p\":self.top_p,\n",
    "            \"top_k\":self.top_k,\n",
    "            \"n\":self.n,\n",
    "            \"max_tokens\":self.max_tokens,\n",
    "            \"stop\":self.stop,\n",
    "            \"presence_penalty\":self.presence_penalty,\n",
    "            \"frequency_penalty\":self.frequency_penalty,\n",
    "        }\n",
    "        return _param_dict\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]]= None, run_manager= None,**kwargs: Any) -> str:\n",
    "        url = \"https://cloud.infini-ai.com/maas/\"+str(self.modelName)+\"/nvidia/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"string\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"stream\": False,\n",
    "            \"temperature\": kwargs[\"temperature\"] if \"temperature\" in kwargs else self.temperature,\n",
    "            \"top_p\": kwargs[\"top_p\"] if 'top_p' in kwargs else self.top_p,\n",
    "            \"top_k\": kwargs['top_k'] if 'top_k' in kwargs else self.top_k,\n",
    "            \"n\": kwargs['n'] if 'n' in kwargs else self.n,\n",
    "            \"max_tokens\": kwargs['max_tokens'] if 'max_tokens' in kwargs else self.max_tokens,\n",
    "            \"stop\": stop if stop else self.stop,\n",
    "            \"presence_penalty\": kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else self.presence_penalty,\n",
    "            \"frequency_penalty\": kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else self.frequency_penalty\n",
    "        }\n",
    "        index = 0\n",
    "        if 'index_api' not in self.__fields__:\n",
    "            self.__fields__['index_api'] = -1\n",
    "        index_api = self.__fields__['index_api']+1\n",
    "        length = len(self.INFINI_API_List)\n",
    "        while index < length:\n",
    "            response = requests.post(url, json=payload, headers=self.getHeader(index_api))\n",
    "            if response.status_code == 200:\n",
    "                response.encoding = 'utf-8'\n",
    "                data = response.json()\n",
    "                print(\"response json success\")\n",
    "                content = data['choices'][0]['message']['content']\n",
    "                if isinstance(content,str):   \n",
    "                    content = content.replace(',\\n}','\\n}')\n",
    "                    content = content.replace(']\\n}',']}')\n",
    "                    if 'statements' in content:\n",
    "                        regex = re.compile('\\\"statements\\\":\\s+\\[.*\\]\\}',re.DOTALL)\n",
    "                        matchStr =regex.search(content)\n",
    "                        if matchStr:\n",
    "                            content = '{'+matchStr.group()\n",
    "                    elif 'verdicts' in content:\n",
    "                        regex = re.compile('\\\"verdicts\\\":\\s+\\[.*\\]\\}',re.DOTALL)\n",
    "                        matchStr =regex.search(content)\n",
    "                        if matchStr is not None:\n",
    "                            content ='{' +matchStr.group()\n",
    "                            regex = re.compile(\"\\\"reason\\\":(.*?)\\}\",re.DOTALL)\n",
    "                            matchStr = regex.findall(content)\n",
    "                            for string in matchStr:\n",
    "                                tmp = string.strip()[1:-1].replace('\"','\\\\\\\"')\n",
    "                                tmp = '\\\"'+tmp+\"\\\"\"\n",
    "                                content = content.replace(string,tmp)\n",
    "                if isinstance(content,str):\n",
    "                    return content\n",
    "                data['choices'][0]['message']['content'] = content\n",
    "                return json.dumps(data['choices'][0]['message']['content'])\n",
    "\n",
    "            index += 1\n",
    "            index_api =  (index_api+1)%length\n",
    "            self.__fields__['index_api'] = index_api\n",
    "            print(response.status_code)\n",
    "            try:\n",
    "                print(response.json())\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(1)\n",
    "        return \"Cannot connect to the model \"+self.modelName\n",
    "    def setParameter(self,**kwargs):\n",
    "        self.temperature = kwargs[\"temperature\"] if \"temperature\" in kwargs else self.temperature\n",
    "        self.top_p = kwargs['top_p'] if 'top_p' in  kwargs else self.top_p\n",
    "        self.top_k = kwargs['top_k'] if 'top_k' in  kwargs else self.top_k\n",
    "        self.n = kwargs['n'] if 'n' in kwargs else self.n\n",
    "        self.max_tokens = kwargs['max_tokens'] if 'max_tokens' in kwargs else self.max_tokens\n",
    "        self.stop = kwargs['stop'] if 'stop' in kwargs else self.stop\n",
    "        self.presence_penalty = kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else self.presence_penalty\n",
    "        self.frequency_penalty = kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else self.frequency_penalty\n",
    "    \n",
    "\n",
    "class CustomLLM(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model\n",
    "    ):\n",
    "        self.model = model\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        # global path\n",
    "        chat_model = self.load_model()\n",
    "        ret = chat_model.invoke(prompt)\n",
    "        idx = 0\n",
    "        while ret == \"Cannot connect to the model \"+self.get_model_name() and idx<5:\n",
    "            time.sleep(5)\n",
    "            ret = chat_model.invoke(prompt)\n",
    "            idx += 1\n",
    "        # print(ret)\n",
    "        # path.append(ret)\n",
    "        return ret\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        try:\n",
    "            return self.model.modelName\n",
    "        except:\n",
    "            return \"CustomLLM\"\n",
    "custom_model = ChatLLM()\n",
    "evaluateModel = CustomLLM(model=custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3VCWG1JD3BFHP427AV69FB",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_format_example = {\n",
    "    'metric_metadata':{\n",
    "        'metric':None,\n",
    "        'threshold':0,\n",
    "        'success':True,\n",
    "        'score':0.8,\n",
    "        'reason':'',\n",
    "        'strictMode': False,\n",
    "        'evaluationModel': 'CustomLLM',\n",
    "        'evaluationCost': 0\n",
    "    },\n",
    "    'metric_configuration': {\n",
    "        'threshold': 0.5,\n",
    "        'evaluation_model': 'CustomLLM',\n",
    "        'strict_mode': False,\n",
    "        'include_reason': True\n",
    "    }\n",
    "}\n",
    "\n",
    "data_format_example = {\n",
    "    'id':0,\n",
    "    'AnswerModel':'',\n",
    "    'input':'',\n",
    "    'actual_output':'',\n",
    "    'expected_output':None,\n",
    "    'retrieval_context':None,\n",
    "    'cached_metrics_data':[\n",
    "        {\n",
    "            'metric_metadata':{\n",
    "                'metric':None,\n",
    "                'success':True,\n",
    "                'score':0.8,\n",
    "                'reason':'',\n",
    "                'statements':'',\n",
    "                'verdicts':'',\n",
    "                'evaluationCost': 0\n",
    "            },\n",
    "            'metric_configuration': {\n",
    "                'threshold': 0.5,\n",
    "                'evaluation_model': 'CustomLLM',\n",
    "                'strict_mode': False,\n",
    "                'include_reason': True\n",
    "            }\n",
    "        },\n",
    "        metrics_format_example\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3VG939F2WC2NHR9NKJ8TJK",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_file(filename:Union[str,Path],save_file:Union[str,Path],error_file:Union[str,Path],force_save:bool = False,metrics:List[BaseMetric] = [AnswerRelevancyMetric(threshold=0.5,model=evaluateModel,include_reason=True),HallucinationMetric(threshold=0.5,model=evaluateModel,include_reason=True)]):\n",
    "    \"\"\"_summary_\n",
    "        the function is used to evaluate the LLM output saved in `filename` by the metric in `metrics`,the successful eval results will be saved into `save_file` and the error item will be saved into `error_file`\n",
    "    \n",
    "    Args:\n",
    "        `filename` (Union[str,Path]): the filename saves the LLM generation results\n",
    "        `save_file` (Union[str,Path]): the filename will save the evaluate results\n",
    "        `error_file` (Union[str,Path]): the filename will save the error eval item\n",
    "        `force_save` (bool, optional): if the value is `True`,function will rerun all eval item in `filename` and directly override the `save_file` and `error_file`. \n",
    "                    Defaults to False.\n",
    "        `metrics` (List[BaseMetric], optional): a list of evaluation metrics. \n",
    "                    Defaults to [AnswerRelevancyMetric(threshold=0.5,model=evaluateModel,include_reason=True),HallucinationMetric(threshold=0.5,model=evaluateModel,include_reason=True)].\n",
    "    \"\"\"\n",
    "    def is_same_eval_item(x,item):\n",
    "        if x['id'] == item['id']  and x['AnswerModel'] == item['AnswerModel'] :\n",
    "            return True\n",
    "        return False\n",
    "    with open(filename,'r') as f:\n",
    "        data = json.load(f)\n",
    "    save,error = dict(),dict()\n",
    "    if  Path(save_file).is_file() and not force_save:\n",
    "        with open(save_file) as f:\n",
    "            save = json.load(f)\n",
    "        if 'fileName' in save and  save['fileName'] != data['fileName']:\n",
    "            print(\"The save_file does not match the file name!\")\n",
    "            return\n",
    "    else:\n",
    "        save = {'fileName':data['fileName'],'class':data['class'],'data':[]}\n",
    "\n",
    "    if Path(error_file).is_file() and not force_save:\n",
    "        with open(error_file) as f:\n",
    "            error = json.load(f)\n",
    "        if 'fileName' in error and  error['fileName'] != data['fileName']:\n",
    "            print(\"The error_file does not match the file name!\")\n",
    "            return\n",
    "    else:\n",
    "        error = {'fileName' :data['fileName'],'class':data['class'],'data':[]}\n",
    "    for metric in metrics:\n",
    "        for item in data['data']:\n",
    "            data_format_ins = {\n",
    "                'id':0,\n",
    "                'AnswerModel':'',\n",
    "                'input':'',\n",
    "                'actual_output':'',\n",
    "                'expected_output':None,\n",
    "                'retrieval_context':None,\n",
    "                'cached_metrics_data':[]\n",
    "            }\n",
    "            metrics_format_ins = {\n",
    "                'metric_metadata':{\n",
    "                    'metric':None,\n",
    "                    'success':True,\n",
    "                    'score':0.8,\n",
    "                    'reason':'',\n",
    "                    'statements':'',\n",
    "                    'verdicts':'',\n",
    "                    'evaluationCost': 0\n",
    "                },\n",
    "                'metric_configuration': {\n",
    "                    'threshold': 0.5,\n",
    "                    'evaluation_model': 'CustomLLM',\n",
    "                    'strict_mode': False,\n",
    "                    'include_reason': True\n",
    "                }\n",
    "            }\n",
    "            errors_format_ins = {\n",
    "                'id':0,\n",
    "                'AnswerModel':'',\n",
    "                'input':'',\n",
    "                'actual_output':'',\n",
    "                'expected_output':None,\n",
    "                'retrieval_context':None,\n",
    "                'cached_metrics_data':[\n",
    "                    {            \n",
    "                        'metric_metadata':{\n",
    "                            'metric':None,\n",
    "                        },\n",
    "                        'metric_configuration': {\n",
    "                            'threshold': 0.5,\n",
    "                            'evaluation_model': 'CustomLLM',\n",
    "                            'strict_mode': False,\n",
    "                            'include_reason': True\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            data_format_ins['id'] = item['id']\n",
    "            data_format_ins['AnswerModel'] = item['AnswerModel']\n",
    "            data_format_ins['input'] = item['input']\n",
    "            data_format_ins['actual_output'] = item['actual_output']\n",
    "            data_format_ins['expected_output'] = item['expected_output']\n",
    "            tag = False\n",
    "            for x in save['data']:\n",
    "                if is_same_eval_item(item,x):\n",
    "                    for metric_data in x['cached_metrics_data']:\n",
    "                        if metric_data['metric_metadata']['metric'] == metric.__name__:\n",
    "                            if metric_data['metric_configuration']['threshold'] == metric.threshold and metric_data['metric_configuration']['evaluation_model'] == metric.evaluation_model and metric_data['metric_configuration']['strict_mode'] == metric.strict_mode and metric_data['metric_configuration']['include_reason'] == metric.include_reason:\n",
    "                                tag = True\n",
    "                                print(\"HAVE:\")\n",
    "                                print(x)\n",
    "                                break\n",
    "            if tag:\n",
    "                continue\n",
    "            test_case = LLMTestCase(\n",
    "                input= item['input'],\n",
    "                actual_output=item['actual_output'],\n",
    "                context=[item['expected_output']],\n",
    "            )\n",
    "            try:\n",
    "                metric.measure(test_case)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                errors_format_ins['id'] = item['id']\n",
    "                errors_format_ins['AnswerModel'] = item['AnswerModel']\n",
    "                errors_format_ins['input'] = item['input']\n",
    "                errors_format_ins['actual_output'] = item['actual_output']\n",
    "                errors_format_ins['expected_output'] = item['expected_output']\n",
    "                errors_format_ins['cached_metrics_data'][0]['metric_metadata']['metric'] = metric.__name__\n",
    "                errors_format_ins['cached_metrics_data'][0]['metric_configuration'] = {'threshold':metric.threshold,'evaluation_model':metric.evaluation_model,'strict_mode':metric.strict_mode,'include_reason':metric.include_reason}\n",
    "                error['data'].append(errors_format_ins.copy())\n",
    "                print(errors_format_ins)\n",
    "                with open(error_file,'w') as f:\n",
    "                    json.dump(error,f,indent=4)\n",
    "                continue\n",
    "            metrics_format_ins['metric_metadata']['metric'] = metric.__name__\n",
    "            metrics_format_ins['metric_metadata']['score'] = metric.score\n",
    "            metrics_format_ins['metric_metadata']['success'] = metric.is_successful()\n",
    "            metrics_format_ins['metric_metadata']['reason'] = metric.reason\n",
    "            \n",
    "            metrics_format_ins['metric_metadata']['statements'] = getattr(metric,'statements','')\n",
    "            metrics_format_ins['metric_metadata']['verdicts'] = str(getattr(metric,'verdicts',''))\n",
    "            metrics_format_ins['metric_metadata']['evaluationCost'] = metric.evaluation_cost\n",
    "\n",
    "            metrics_format_ins['metric_configuration']['threshold'] = metric.threshold\n",
    "            metrics_format_ins['metric_configuration']['strict_mode'] = metric.strict_mode\n",
    "            metrics_format_ins['metric_configuration']['evaluation_model'] = metric.evaluation_model\n",
    "            metrics_format_ins['metric_configuration']['include_reason'] = metric.include_reason\n",
    "\n",
    "            data_format_ins['cached_metrics_data'].append(metrics_format_ins.copy())\n",
    "            flag = True\n",
    "            for each in save['data']:\n",
    "                if is_same_eval_item(each, data_format_ins):\n",
    "                    each['cached_metrics_data'].append(metrics_format_ins.copy())\n",
    "                    flag = False\n",
    "                    break\n",
    "            if flag:\n",
    "                save['data'].append(data_format_ins.copy())\n",
    "                print(data_format_ins)\n",
    "            with open(save_file,'w') as f:\n",
    "                json.dump(save,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3VYA1YVHEARJGA6J1RKZRN",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('./data/KoLA/save/'):\n",
    "    evaluate_file('./data/KoLA/save/'+file,'./data/KoLA/eval/save/'+file,'./data/KoLA/eval/error/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3VH7DJWH1SW1YJGEKMXT2G",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinEvalErrorToData(errorFile:Union[str,Path],saveFile:Union[str,Path])->None:\n",
    "    \"\"\"_summary_\n",
    "        the function is used to rerun the error item in the `errorFile` and append the results into the `saveFile` \n",
    "        \n",
    "    Args:\n",
    "        `errorFile` (Union[str,Path]): the JSON file saves the error item in the before running\n",
    "        `saveFile` (Union[str,Path]): the JSON file saves the pass result\n",
    "        \n",
    "    Returns:\n",
    "        None: the result will override the original file \n",
    "    \"\"\"\n",
    "    def is_same_eval_item(x,item):\n",
    "        if x['id'] == item['id'] and x['AnswerModel'] == item['AnswerModel'] :\n",
    "            return True\n",
    "        return False\n",
    "    with open(errorFile,'r') as f:\n",
    "        data_er = json.load(f)\n",
    "    with open(saveFile,'r') as f:\n",
    "        data_sv = json.load(f)\n",
    "    if data_er['fileName'] != data_sv['fileName']:\n",
    "        print(\"The save_file does not match the error_file!\")\n",
    "        return\n",
    "    error = {'fileName' :data_er['fileName'],'class':data_er['class'],'data':[]}\n",
    "    while data_er['data']:\n",
    "        item = data_er['data'].pop()\n",
    "        data_format_ins = {\n",
    "            'id':0,\n",
    "            'AnswerModel':'',\n",
    "            'input':'',\n",
    "            'actual_output':'',\n",
    "            'expected_output':None,\n",
    "            'context':None,\n",
    "            'retrieval_context':None,\n",
    "            'cached_metrics_data':[]\n",
    "        }\n",
    "        metrics_format_ins = {\n",
    "            'metric_metadata':{\n",
    "                'metric':None,\n",
    "                'success':True,\n",
    "                'score':0.8,\n",
    "                'reason':'',\n",
    "                'statements':'',\n",
    "                'verdicts':'',\n",
    "                'evaluationCost': 0\n",
    "            },\n",
    "            'metric_configuration': {\n",
    "                'threshold': 0.5,\n",
    "                'evaluation_model': 'CustomLLM',\n",
    "                'strict_mode': False,\n",
    "                'include_reason': True\n",
    "            }\n",
    "        }\n",
    "        errors_format_ins = {\n",
    "            'id':0,\n",
    "            'AnswerModel':'',\n",
    "            'input':'',\n",
    "            'actual_output':'',\n",
    "            'expected_output':None,\n",
    "            'retrieval_context':None,\n",
    "            'cached_metrics_data':[\n",
    "                {            \n",
    "                    'metric_metadata':{\n",
    "                        'metric':None,\n",
    "                    },\n",
    "                    'metric_configuration': {\n",
    "                        'threshold': 0.5,\n",
    "                        'evaluation_model': 'CustomLLM',\n",
    "                        'strict_mode': False,\n",
    "                        'include_reason': True\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        data_format_ins['id'] = item['id']\n",
    "        data_format_ins['AnswerModel'] = item['AnswerModel']\n",
    "        data_format_ins['input'] = item['input']\n",
    "        data_format_ins['actual_output'] = item['actual_output']\n",
    "        data_format_ins['expected_output'] = item['expected_output']\n",
    "        \n",
    "        tag = False\n",
    "        for x in data_sv['data']:\n",
    "            if is_same_eval_item(item,x):\n",
    "                for metric_data in x['cached_metrics_data']:\n",
    "                    if metric_data['metric_metadata']['metric'] == item['cached_metrics_data'][0]['metric_metadata']['metric']:\n",
    "                        if metric_data['metric_configuration']['threshold'] == item['cached_metrics_data'][0]['metric_configuration']['threshold'] and metric_data['metric_configuration']['evaluation_model'] == item['cached_metrics_data'][0]['metric_configuration']['evaluation_model'] and metric_data['metric_configuration']['strict_mode'] == item['cached_metrics_data'][0]['metric_configuration']['strict_mode'] and metric_data['metric_configuration']['include_reason'] == item['cached_metrics_data'][0]['metric_configuration']['include_reason']:\n",
    "                            tag = True\n",
    "                            print(\"HAVE:\")\n",
    "                            print(x)\n",
    "                            break\n",
    "        if tag:\n",
    "            continue\n",
    "        test_case = LLMTestCase(\n",
    "            input= item['input'],\n",
    "            actual_output=item['actual_output'],\n",
    "            context=[item['expected_output']],\n",
    "        )\n",
    "        if item['cached_metrics_data'][0]['metric_metadata']['metric'] == 'Answer Relevancy':\n",
    "            metric = AnswerRelevancyMetric(\n",
    "                threshold=item['cached_metrics_data'][0]['metric_configuration']['threshold'],\n",
    "                model = evaluateModel,\n",
    "                include_reason=item['cached_metrics_data'][0]['metric_configuration']['include_reason']\n",
    "            )\n",
    "        elif item['cached_metrics_data'][0]['metric_metadata']['metric'] == 'Hallucination':\n",
    "            metric = HallucinationMetric(\n",
    "                threshold=item['cached_metrics_data'][0]['metric_configuration']['threshold'],\n",
    "                model = evaluateModel,\n",
    "                include_reason=item['cached_metrics_data'][0]['metric_configuration']['include_reason']\n",
    "            )\n",
    "        else:\n",
    "            print(\"unkonwn metric!\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            metric.measure(test_case)\n",
    "        except Exception as e:\n",
    "            print(traceback.print_exc())\n",
    "            errors_format_ins['id'] = item['id']\n",
    "            errors_format_ins['AnswerModel'] = item['AnswerModel']\n",
    "            errors_format_ins['input'] = item['input']\n",
    "            errors_format_ins['actual_output'] = item['actual_output']\n",
    "            errors_format_ins['expected_output'] = item['expected_output']\n",
    "            errors_format_ins['cached_metrics_data'][0]['metric_metadata']['metric'] = metric.__name__\n",
    "            errors_format_ins['cached_metrics_data'][0]['metric_configuration'] = {'threshold':metric.threshold,'evaluation_model':metric.evaluation_model,'strict_mode':metric.strict_mode,'include_reason':metric.include_reason}\n",
    "            error['data'].append(errors_format_ins.copy())\n",
    "            print(errors_format_ins)\n",
    "            with open(errorFile,'w') as f:\n",
    "                json.dump(data_er,f,indent=4)\n",
    "            continue\n",
    "        metrics_format_ins['metric_metadata']['metric'] = metric.__name__\n",
    "        metrics_format_ins['metric_metadata']['score'] = metric.score\n",
    "        metrics_format_ins['metric_metadata']['success'] = metric.is_successful()\n",
    "        metrics_format_ins['metric_metadata']['reason'] = metric.reason\n",
    "        \n",
    "        metrics_format_ins['metric_metadata']['statements'] = getattr(metric,'statements','')\n",
    "        metrics_format_ins['metric_metadata']['verdicts'] = str(getattr(metric,'verdicts',''))\n",
    "        metrics_format_ins['metric_metadata']['evaluationCost'] = metric.evaluation_cost\n",
    "\n",
    "        metrics_format_ins['metric_configuration']['threshold'] = metric.threshold\n",
    "        metrics_format_ins['metric_configuration']['strict_mode'] = metric.strict_mode\n",
    "        metrics_format_ins['metric_configuration']['evaluation_model'] = metric.evaluation_model\n",
    "        metrics_format_ins['metric_configuration']['include_reason'] = metric.include_reason\n",
    "\n",
    "        data_format_ins['cached_metrics_data'].append(metrics_format_ins.copy())\n",
    "        flag = True\n",
    "        for each in data_sv['data']:\n",
    "            if is_same_eval_item(each, data_format_ins):\n",
    "                each['cached_metrics_data'].append(metrics_format_ins.copy())\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            data_sv['data'].append(data_format_ins.copy())\n",
    "            print(data_format_ins)\n",
    "        with open(saveFile,'w') as f:\n",
    "            json.dump(data_sv,f,indent=4)\n",
    "    \n",
    "    with open(errorFile,'w') as f:\n",
    "        json.dump(error,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3VSD9ZM6ZPV4NVHR7Y2AQM",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir,subdirs,files in os.walk(\"./data/KoLA/eval/error\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            joinEvalErrorToData('./data/KoLA/eval/error/'+file,'./data/KoLA/eval/save/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3VSAT7N85H94262AKY18PQ",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_error = ['1-1_2_high_freq_ent_sample.json','1-2_1_low_freq_ent_sample.json', '1-3_r_1_simple_sample_sample.json', '2-5_DocRED_sample.json', '2-6_MAVEN_sample.json',  '2-8_r_DocRED_sample.json', '3-1_hotpotqa_sample.json', '3-2_2wikimultihopqa_sample.json', '3-4_kqapro_sample.json',  '3-6_r_KoRC++ood_sample.json',  '4-1_with_triples_sample.json', '4-2_r_with_triples_sample.json']\n",
    "for file in files_error[::-1]:\n",
    "    joinEvalErrorToData('./data/KoLA/eval/error/'+file,'./data/KoLA/eval/save/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3VN69KWMEZ2KC0RHVSJDW4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnionFind:\n",
    "    def __init__(self,n):\n",
    "        self.n = n\n",
    "        self.parent = [i for i in range(n)]\n",
    "        self.size = n\n",
    "        self.keyset = [1]*n\n",
    "    def find(self,x):\n",
    "        if self.parent[x]!= x:\n",
    "            self.parent[x] = self.find(self.parent[x])\n",
    "        return self.parent[x]\n",
    "    \n",
    "    def union(self,x,y):\n",
    "        x = self.find(x)\n",
    "        y = self.find(y)\n",
    "        if x == y:\n",
    "            return False\n",
    "        if self.keyset[x] < self.keyset[y]:\n",
    "            x,y = y,x\n",
    "        self.parent[y] = x\n",
    "        self.keyset[x] += self.keyset[y]\n",
    "        self.size -= 1\n",
    "        return True\n",
    "    \n",
    "    def is_connected(self,x,y):\n",
    "        return self.find(x) == self.find(y)\n",
    "    def get_size(self,x):\n",
    "        return self.keyset[self.find(x)]\n",
    "    def get_size_all(self):\n",
    "        return self.size\n",
    "def merge_same_item(file_path:Union[str,Path])->None:\n",
    "    def is_same_eval_item(x,item):\n",
    "        if x['id'] == item['id'] and  x['AnswerModel'] == item['AnswerModel'] :\n",
    "            return True\n",
    "        return False\n",
    "    with open(file_path,'r') as f:\n",
    "        data = json.load(f)\n",
    "    check = []\n",
    "    for item in data['data']:\n",
    "        if len(item[\"cached_metrics_data\"]) <2:\n",
    "            check.append(item)\n",
    "    check.sort(key=lambda x:(x['id'],x['AnswerModel']))\n",
    "    uf = UnionFind(len(check))\n",
    "    for i in range(len(check)):\n",
    "        for j in range(i+1,len(check)):\n",
    "            if is_same_eval_item(check[i],check[j]):\n",
    "                uf.union(i,j)\n",
    "    key_set = defaultdict(list)\n",
    "    for i in range(len(check)):\n",
    "        p = uf.find(i)\n",
    "        key_set[p].append(check[i])\n",
    "        \n",
    "    mergeList =  list(key_set.values())\n",
    "    for item in mergeList[:]:\n",
    "        if len(item)<2:\n",
    "            mergeList.remove(item)\n",
    "    for x,y in mergeList:\n",
    "        mergeItem = x.copy()\n",
    "        mergeItem['cached_metrics_data'].append(y['cached_metrics_data'][0])\n",
    "        data['data'].remove(x)\n",
    "        data['data'].remove(y)\n",
    "        data['data'].append(mergeItem)\n",
    "    with open(file_path,'w') as f:\n",
    "        json.dump(data,f,indent=4)\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3VQ5FSBVTMN9G8XNXZY7FX",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir,subdir,files in os.walk('./data/KoLA/eval/save'):\n",
    "    for file in files:\n",
    "        merge_same_item('./data/KoLA/eval/save/'+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01HXKR5W8PNS7HXZ48XCQEV4QF",
   "metadata": {},
   "source": [
    "### ADD `idx` To replace `id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 后来发现原始数据中的`id`存在问题，故使用`idx`进行替代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXKR8WH38H5306AH99W6HGSH",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir,subdir,files in os.walk(\"E:\\\\Repository\\\\KoLA\\\\Sample_Data\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            with open(os.path.join(dir,file)) as f:\n",
    "                data = json.load(f)\n",
    "            instructions = data[\"adapter_spec\"][\"instructions\"]\n",
    "            prefix = file.replace(\".json\",\"\").replace(\"_sample\",\"\")\n",
    "            for i,ins in enumerate(data[\"request_states\"]):\n",
    "                ins[\"instance\"][\"idx\"] = prefix+\"==\"+(\"%02d\"%i)\n",
    "            with open(os.path.join(dir,file),'w') as f:\n",
    "                json.dump(data,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXKR7W28SFE7REF9HA1Q67E5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_o = \"E:\\\\Repository\\\\KoLA\\\\Sample_Data\"\n",
    "dir_data = \"E:\\\\学习资料\\\\2023-2024第二学期_大二下\\\\信息存储与检索\\\\小组作业\\\\data\\\\KoLA\\\\save\"\n",
    "dir_eval = \"E:\\\\学习资料\\\\2023-2024第二学期_大二下\\\\信息存储与检索\\\\小组作业\\\\data/KoLA/eval\\\\save\"\n",
    "dir_eval_error = \"E:\\\\学习资料\\\\2023-2024第二学期_大二下\\\\信息存储与检索\\\\小组作业\\\\data/KoLA/eval\\\\error\"\n",
    "fileList = ['1-1_2_high_freq_ent_sample.json', '1-2_1_low_freq_ent_sample.json', '1-3_r_1_simple_sample_sample.json', '2-1_COPEN++csj_sample.json', '2-2_COPEN++cpj_sample.json', '2-3_COPEN++cic_sample.json', '2-4_FewNERD++inter_sample.json', '2-4_FewNERD++intra_sample.json', '2-4_FewNERD++supervised_sample.json', '2-5_DocRED_sample.json', '2-6_MAVEN_sample.json', '2-7_MAVEN-ERE_sample.json', '2-8_r_DocRED_sample.json', '3-1_hotpotqa_sample.json', '3-2_2wikimultihopqa_sample.json', '3-3_musique_sample.json', '3-4_kqapro_sample.json', '3-5_KoRC++ood_sample.json', '3-6_r_KoRC++ood_sample.json', '4-1_without_triples_sample.json', '4-1_with_triples_sample.json', '4-2_r_without_triples_sample.json', '4-2_r_with_triples_sample.json']\n",
    "for file in fileList:\n",
    "    with open(os.path.join(dir_o,file)) as f:\n",
    "        data_origin = json.load(f)\n",
    "    # dir_data = dir_eval\n",
    "    # dir_data = dir_eval_error\n",
    "    if not os.path.exists(os.path.join(dir_data,file)):\n",
    "        continue\n",
    "    with open(os.path.join(dir_data,file)) as f:\n",
    "        data_save = json.load(f)\n",
    "    if data_save['fileName'] != file:\n",
    "        print(\"Not Match \"+file)\n",
    "        continue\n",
    "    instructions = data_origin[\"adapter_spec\"][\"instructions\"]\n",
    "    for ins in data_origin[\"request_states\"]:\n",
    "        inp = ins[\"instance\"][\"input\"][\"text\"]\n",
    "        idx = ins[\"instance\"][\"idx\"]\n",
    "        expected_output = ins[\"instance\"][\"references\"][0][\"output\"][\"text\"]\n",
    "        for item in data_save['data']:\n",
    "            if item[\"expected_output\"] == expected_output and item[\"input\"] == instructions+\"\\n\"+inp :\n",
    "                item[\"idx\"] = idx\n",
    "    with open(os.path.join(dir_data,file),'w') as f:\n",
    "        json.dump(data_save,f,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Results View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01HX3ZFK2Z3WPY8PRF2NP148DV",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval = {\"Answer Relevancy\":defaultdict(list),\"Hallucination\":defaultdict(list),}\n",
    "for dir,subdir,files in os.walk('data/KoLA/eval/save'):\n",
    "    for file in files:\n",
    "        with open(os.path.join(dir,file)) as f:\n",
    "            data = json.load(f)\n",
    "        for item in data['data']:\n",
    "            for metric in item[\"cached_metrics_data\"]:\n",
    "                data_eval[metric[\"metric_metadata\"][\"metric\"]][item['AnswerModel']].append(metric[\"metric_metadata\"][\"score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01HX3ZFZCV3Y5K9VY970E5BZ3S",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Answer Relevancy': defaultdict(list,\n",
       "             {'baichuan2-13b-base': [0.5,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               0.5,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               0.5,\n",
       "               0.4,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5714285714285714,\n",
       "               0.21428571428571427,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.3333333333333333,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.25,\n",
       "               0.7777777777777778,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               0.875,\n",
       "               0.0,\n",
       "               1,\n",
       "               1,\n",
       "               1,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               0.5,\n",
       "               0.25,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.5555555555555556,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.3333333333333333,\n",
       "               0.7,\n",
       "               0.75,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               0.5263157894736842,\n",
       "               0.5,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.3333333333333333,\n",
       "               0.3333333333333333,\n",
       "               0.14285714285714285,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               1,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.4166666666666667,\n",
       "               0.0,\n",
       "               1,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1,\n",
       "               1.0],\n",
       "              'baichuan2-13b-chat': [1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8888888888888888,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               0.6,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               0.6,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1,\n",
       "               1,\n",
       "               1,\n",
       "               1,\n",
       "               0.9230769230769231,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               0.875,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               0.625,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7777777777777778,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8888888888888888,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0],\n",
       "              'baichuan2-7b-chat': [1.0,\n",
       "               0.625,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               0.4,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.2727272727272727,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.13636363636363635,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.058823529411764705,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.95,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9375,\n",
       "               0.95,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9285714285714286,\n",
       "               1.0,\n",
       "               0.8947368421052632,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0],\n",
       "              'infini-megrez-7b': [1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.2727272727272727,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8571428571428571,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.38461538461538464,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1,\n",
       "               0.03333333333333333,\n",
       "               0.8666666666666667,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5714285714285714,\n",
       "               0.75,\n",
       "               0.0,\n",
       "               0.6666666666666666,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6,\n",
       "               0.9,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               0.6,\n",
       "               0.2857142857142857,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.2222222222222222,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               0.7857142857142857,\n",
       "               1.0,\n",
       "               0.7,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.95,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.1,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0],\n",
       "              'llama-2-13b-chat': [1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.4,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.14285714285714285,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.14285714285714285,\n",
       "               0.16666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5263157894736842,\n",
       "               0.7777777777777778,\n",
       "               0.9090909090909091,\n",
       "               1.0,\n",
       "               0.5714285714285714,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.875,\n",
       "               1.0,\n",
       "               0.6,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               0.46153846153846156,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               0.8333333333333334,\n",
       "               0.625,\n",
       "               0.8333333333333334,\n",
       "               0.16666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               0.9230769230769231,\n",
       "               0.8571428571428571,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7692307692307693,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9230769230769231,\n",
       "               0.9,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0],\n",
       "              'llama-2-70b': [0.24,\n",
       "               0.02127659574468085,\n",
       "               0.3333333333333333,\n",
       "               0.5555555555555556,\n",
       "               0.42857142857142855,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               0.18181818181818182,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6,\n",
       "               0.7692307692307693,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.08333333333333333,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.0,\n",
       "               0.9130434782608695,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.6666666666666666,\n",
       "               0.38461538461538464,\n",
       "               0.6,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1,\n",
       "               0.0,\n",
       "               1,\n",
       "               1,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1,\n",
       "               1,\n",
       "               0.25,\n",
       "               1,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.2,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1,\n",
       "               1,\n",
       "               1.0,\n",
       "               0.9032258064516129,\n",
       "               0.6,\n",
       "               1,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.2222222222222222,\n",
       "               1.0,\n",
       "               0.08823529411764706,\n",
       "               1.0,\n",
       "               1,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.29411764705882354,\n",
       "               0.8461538461538461,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1,\n",
       "               0.0,\n",
       "               1,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.4,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.42857142857142855,\n",
       "               0.5833333333333334,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               0.7142857142857143,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.42857142857142855,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1,\n",
       "               0.0,\n",
       "               1],\n",
       "              'llama-2-70b-chat': [1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.875,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.16,\n",
       "               0.8333333333333334,\n",
       "               0.23333333333333334,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7777777777777778,\n",
       "               0.2777777777777778,\n",
       "               0.8888888888888888,\n",
       "               0.6666666666666666,\n",
       "               0.0,\n",
       "               0.8,\n",
       "               0.25,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.75,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               0.8,\n",
       "               0.0,\n",
       "               0.9090909090909091,\n",
       "               1.0,\n",
       "               0.4,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.4,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9444444444444444,\n",
       "               1.0,\n",
       "               0.9090909090909091,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9333333333333333,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75],\n",
       "              'llama-2-7b-chat': [0.3333333333333333,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               0.25,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8571428571428571,\n",
       "               0.35294117647058826,\n",
       "               0.8888888888888888,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7142857142857143,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8571428571428571,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               0.13333333333333333,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               0.5,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8888888888888888,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.2857142857142857,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               0.16666666666666666,\n",
       "               0.9444444444444444,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.2,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9411764705882353,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.92,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0],\n",
       "              'llama-3-8b-instruct': [1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7272727272727273,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8571428571428571,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               0.5,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8571428571428571,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9285714285714286,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9090909090909091,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8181818181818182,\n",
       "               0.9473684210526315,\n",
       "               0.8461538461538461,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0],\n",
       "              'qwen-14b-chat': [1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7142857142857143,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               0.5714285714285714,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.25,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8888888888888888,\n",
       "               0.8666666666666667,\n",
       "               1.0],\n",
       "              'qwen-72b': [1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7142857142857143,\n",
       "               0.8,\n",
       "               0.5,\n",
       "               1,\n",
       "               0.2,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9166666666666666,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9615384615384616,\n",
       "               0.9333333333333333,\n",
       "               1.0,\n",
       "               1.0],\n",
       "              'qwen-72b-chat': [1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.5555555555555556,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               0.8888888888888888,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.19230769230769232,\n",
       "               1.0,\n",
       "               0.7142857142857143,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9,\n",
       "               1.0,\n",
       "               0.6,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               0.9,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8571428571428571,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9285714285714286,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9090909090909091,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0],\n",
       "              'qwen-7b-chat': [1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               0.8333333333333334,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8888888888888888,\n",
       "               0.35714285714285715,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               0.6,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.92,\n",
       "               1.0,\n",
       "               0.8235294117647058,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9375,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0],\n",
       "              'qwen1.5-14b-chat': [1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               0.8,\n",
       "               0.3333333333333333,\n",
       "               0.2727272727272727,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9166666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8,\n",
       "               0.6,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               0.9629629629629629,\n",
       "               0.64,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7142857142857143,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9473684210526315,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0],\n",
       "              'qwen1.5-72b': [1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.16666666666666666,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5555555555555556,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7692307692307693,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9230769230769231,\n",
       "               0.9333333333333333,\n",
       "               1.0,\n",
       "               1.0],\n",
       "              'qwen1.5-7b-chat': [1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5714285714285714,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8333333333333334,\n",
       "               0.25,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.4,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9615384615384616,\n",
       "               0.47058823529411764,\n",
       "               0.9473684210526315,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               0.9090909090909091,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7142857142857143,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7777777777777778,\n",
       "               0.8333333333333334,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7142857142857143,\n",
       "               0.6,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8888888888888888,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.8571428571428571,\n",
       "               0.9333333333333333,\n",
       "               1.0,\n",
       "               0.9230769230769231,\n",
       "               0.9090909090909091,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9285714285714286,\n",
       "               1.0,\n",
       "               0.9230769230769231,\n",
       "               1.0,\n",
       "               1.0]}),\n",
       " 'Hallucination': defaultdict(list,\n",
       "             {'baichuan2-13b-base': [0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0],\n",
       "              'baichuan2-13b-chat': [1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.9,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5714285714285714,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.25,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.5714285714285714,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.14285714285714285,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.7142857142857143,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0],\n",
       "              'baichuan2-7b-chat': [1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.6,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.16666666666666666,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.2857142857142857,\n",
       "               0.45,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.375,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.42857142857142855,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               0.25,\n",
       "               0.0,\n",
       "               0.4,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.3333333333333333,\n",
       "               0.3076923076923077,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0],\n",
       "              'infini-megrez-7b': [0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.2,\n",
       "               0.0,\n",
       "               0.3333333333333333,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.14285714285714285,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.1111111111111111,\n",
       "               0.625,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0],\n",
       "              'llama-2-13b-chat': [1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.16666666666666666,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.25,\n",
       "               0.375,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.9,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.4,\n",
       "               0.3333333333333333,\n",
       "               0.375,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.16666666666666666,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0],\n",
       "              'llama-2-70b': [1.0,\n",
       "               0.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.058823529411764705,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.42857142857142855,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.13043478260869565,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.125,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0],\n",
       "              'llama-2-70b-chat': [1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.75,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5714285714285714,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.2,\n",
       "               0.0,\n",
       "               0.3333333333333333,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.13333333333333333,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.1,\n",
       "               0.3333333333333333],\n",
       "              'llama-2-7b-chat': [1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.2,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.2857142857142857,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.375,\n",
       "               0.6363636363636364,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0],\n",
       "              'llama-3-8b-instruct': [0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5714285714285714,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.1,\n",
       "               0.2,\n",
       "               0.0,\n",
       "               0.0],\n",
       "              'qwen-14b-chat': [1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.3333333333333333,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.5,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.42857142857142855,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0],\n",
       "              'qwen-72b': [1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.6,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.2,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.5714285714285714,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.125,\n",
       "               0.125,\n",
       "               0.0,\n",
       "               1.0],\n",
       "              'qwen-72b-chat': [1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.3333333333333333,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.95,\n",
       "               0.0,\n",
       "               0.875,\n",
       "               1.0,\n",
       "               0.2,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.14285714285714285,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.14285714285714285,\n",
       "               0.8571428571428571,\n",
       "               0.16666666666666666,\n",
       "               0.0,\n",
       "               0.0],\n",
       "              'qwen-7b-chat': [1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.5555555555555556,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.2222222222222222,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.2,\n",
       "               0.16666666666666666,\n",
       "               0.16666666666666666,\n",
       "               0.16666666666666666,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.8,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.2857142857142857,\n",
       "               0.0],\n",
       "              'qwen1.5-14b-chat': [1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.3333333333333333,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.16666666666666666,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.875,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.75,\n",
       "               0.3333333333333333,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.25,\n",
       "               0.3333333333333333,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.14285714285714285,\n",
       "               0.5555555555555556,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.14285714285714285,\n",
       "               0.4,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0],\n",
       "              'qwen1.5-72b': [1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.3333333333333333,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               0.0,\n",
       "               0.5555555555555556,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.5,\n",
       "               1.0,\n",
       "               0.4,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.3333333333333333,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.3333333333333333,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.5,\n",
       "               0.0,\n",
       "               0.2,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.1111111111111111,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0],\n",
       "              'qwen1.5-7b-chat': [0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.6666666666666666,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.2692307692307692,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.5454545454545454,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.4,\n",
       "               0.16666666666666666,\n",
       "               0.0,\n",
       "               0.2857142857142857,\n",
       "               0.4,\n",
       "               0.2,\n",
       "               0.0,\n",
       "               1.0,\n",
       "               1.0,\n",
       "               0.125,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0,\n",
       "               0.0]})}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01HX3ZG6VBQET04FH0VJEHQ1PT",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval_mean = {\"Answer Relevancy\":defaultdict(dict),\"Hallucination\":defaultdict(dict),}\n",
    "for metric,modelEvalItem in data_eval.items():\n",
    "    for model,evals in modelEvalItem.items():\n",
    "        data_eval_mean[metric][model][\"mean\"] = np.mean(evals)\n",
    "        data_eval_mean[metric][model][\"variance\"] = np.var(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01HX3ZGBSEM5PJ2CR3C42WAM1E",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Answer Relevancy': defaultdict(dict,\n",
       "             {'baichuan2-13b-base': {'mean': 0.6114362741716677,\n",
       "               'variance': 0.16698578079239057},\n",
       "              'baichuan2-13b-chat': {'mean': 0.9458282458282459,\n",
       "               'variance': 0.015045496292850789},\n",
       "              'baichuan2-7b-chat': {'mean': 0.8908861703514317,\n",
       "               'variance': 0.06627432625785984},\n",
       "              'infini-megrez-7b': {'mean': 0.8334527612305389,\n",
       "               'variance': 0.09087302114851438},\n",
       "              'llama-2-13b-chat': {'mean': 0.886645419945961,\n",
       "               'variance': 0.05291497173885806},\n",
       "              'llama-2-70b': {'mean': 0.6454967130863714,\n",
       "               'variance': 0.16926455695663895},\n",
       "              'llama-2-70b-chat': {'mean': 0.9011196789321788,\n",
       "               'variance': 0.04659675264952888},\n",
       "              'llama-2-7b-chat': {'mean': 0.8812358470896451,\n",
       "               'variance': 0.06371954794626675},\n",
       "              'llama-3-8b-instruct': {'mean': 0.9317500738553369,\n",
       "               'variance': 0.03114528704028085},\n",
       "              'qwen-14b-chat': {'mean': 0.9148030045351474,\n",
       "               'variance': 0.06023290669903166},\n",
       "              'qwen-72b': {'mean': 0.8994723930503749,\n",
       "               'variance': 0.06533049737351833},\n",
       "              'qwen-72b-chat': {'mean': 0.9247419738570181,\n",
       "               'variance': 0.04002586228730786},\n",
       "              'qwen-7b-chat': {'mean': 0.9169195746834559,\n",
       "               'variance': 0.038612733202142334},\n",
       "              'qwen1.5-14b-chat': {'mean': 0.9527143842651361,\n",
       "               'variance': 0.017078257928501584},\n",
       "              'qwen1.5-72b': {'mean': 0.9453260953260952,\n",
       "               'variance': 0.0334600355756127},\n",
       "              'qwen1.5-7b-chat': {'mean': 0.9222382884963803,\n",
       "               'variance': 0.03584816802712994}}),\n",
       " 'Hallucination': defaultdict(dict,\n",
       "             {'baichuan2-13b-base': {'mean': 0.6769911504424779,\n",
       "               'variance': 0.21646174328451723},\n",
       "              'baichuan2-13b-chat': {'mean': 0.5367256637168142,\n",
       "               'variance': 0.23282581876565073},\n",
       "              'baichuan2-7b-chat': {'mean': 0.5594322344322344,\n",
       "               'variance': 0.22464363424528258},\n",
       "              'infini-megrez-7b': {'mean': 0.6245926394156482,\n",
       "               'variance': 0.22288345423764538},\n",
       "              'llama-2-13b-chat': {'mean': 0.6044247787610619,\n",
       "               'variance': 0.22200967403694707},\n",
       "              'llama-2-70b': {'mean': 0.5965442159934385,\n",
       "               'variance': 0.2296590368953829},\n",
       "              'llama-2-70b-chat': {'mean': 0.5789506953223766,\n",
       "               'variance': 0.23277211550294802},\n",
       "              'llama-2-7b-chat': {'mean': 0.6061688311688311,\n",
       "               'variance': 0.2254845663856123},\n",
       "              'llama-3-8b-instruct': {'mean': 0.5209860935524652,\n",
       "               'variance': 0.24124681924353006},\n",
       "              'qwen-14b-chat': {'mean': 0.528866413822166,\n",
       "               'variance': 0.23618336571582713},\n",
       "              'qwen-72b': {'mean': 0.5600716392751791,\n",
       "               'variance': 0.23678192752288216},\n",
       "              'qwen-72b-chat': {'mean': 0.5339338390223345,\n",
       "               'variance': 0.23320641251514582},\n",
       "              'qwen-7b-chat': {'mean': 0.5861075993819356,\n",
       "               'variance': 0.22857907771839955},\n",
       "              'qwen1.5-14b-chat': {'mean': 0.5541262817811491,\n",
       "               'variance': 0.225245685979569},\n",
       "              'qwen1.5-72b': {'mean': 0.5539823008849557,\n",
       "               'variance': 0.2281959297643115},\n",
       "              'qwen1.5-7b-chat': {'mean': 0.49609498171445077,\n",
       "               'variance': 0.23441619162695176}})}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_eval_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXKVK8KYA4580A10VMAZPXXM",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_view = {}\n",
    "for dir,subdir,files in os.walk('data/KoLA/eval/save'):\n",
    "    for file in files:\n",
    "        data_id = defaultdict(dict)\n",
    "        with open(os.path.join(dir,file)) as f:\n",
    "            data = json.load(f)\n",
    "        for item in data['data']:\n",
    "            for metric in item[\"cached_metrics_data\"]:\n",
    "                if metric[\"metric_metadata\"][\"metric\"] not in data_id[item['AnswerModel']]:\n",
    "                    data_id[item['AnswerModel']][metric[\"metric_metadata\"][\"metric\"]] = []\n",
    "                data_id[item['AnswerModel']][metric[\"metric_metadata\"][\"metric\"]].append(metric[\"metric_metadata\"][\"score\"])\n",
    "        for key,value in data_id.items():\n",
    "            for k,v in value.items():\n",
    "                data_id[key][k] = np.mean(v)\n",
    "        data_view[file] = data_id.copy()\n",
    "\n",
    "data_view_ar = deepcopy(data_view)\n",
    "data_view_h = deepcopy(data_view)\n",
    "for key,value in data_view_ar.items():\n",
    "    for k,v in value.items():\n",
    "        data_view_ar[key][k] = v['Answer Relevancy'] if 'Answer Relevancy' in v else None\n",
    "        data_view_h[key][k] = v['Hallucination'] if 'Hallucination' in v else None\n",
    "        \n",
    "# pd.DataFrame(data_view).to_json(\"data/KoLA/results_view/model_file_dict_AR_H.json\",indent=4)\n",
    "# pd.DataFrame(data_view_ar).to_json(\"data/KoLA/results_view/model_file_AnswerRelevancy.json\",indent=4)\n",
    "# pd.DataFrame(data_view_h).to_json(\"data/KoLA/results_view/model_file_Hallucination.json\",indent=4)\n",
    "# pd.DataFrame(data_view).to_excel(\"data/KoLA/results_view/model_file_dict_AR_H.xlsx\")\n",
    "# pd.DataFrame(data_view_ar).to_excel(\"data/KoLA/results_view/model_file_AnswerRelevancy.xlsx\",)\n",
    "# pd.DataFrame(data_view_h).to_excel(\"data/KoLA/results_view/model_file_Hallucination.xlsx\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXKVMA8MP8BCJGH4EWKX4ZQF",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-1_2_high_freq_ent_sample.json</th>\n",
       "      <th>1-2_1_low_freq_ent_sample.json</th>\n",
       "      <th>1-3_r_1_simple_sample_sample.json</th>\n",
       "      <th>2-1_COPEN++csj_sample.json</th>\n",
       "      <th>2-2_COPEN++cpj_sample.json</th>\n",
       "      <th>2-3_COPEN++cic_sample.json</th>\n",
       "      <th>2-4_FewNERD++inter_sample.json</th>\n",
       "      <th>2-4_FewNERD++intra_sample.json</th>\n",
       "      <th>2-4_FewNERD++supervised_sample.json</th>\n",
       "      <th>2-5_DocRED_sample.json</th>\n",
       "      <th>...</th>\n",
       "      <th>3-1_hotpotqa_sample.json</th>\n",
       "      <th>3-2_2wikimultihopqa_sample.json</th>\n",
       "      <th>3-3_musique_sample.json</th>\n",
       "      <th>3-4_kqapro_sample.json</th>\n",
       "      <th>3-5_KoRC++ood_sample.json</th>\n",
       "      <th>3-6_r_KoRC++ood_sample.json</th>\n",
       "      <th>4-1_without_triples_sample.json</th>\n",
       "      <th>4-1_with_triples_sample.json</th>\n",
       "      <th>4-2_r_without_triples_sample.json</th>\n",
       "      <th>4-2_r_with_triples_sample.json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baichuan2-13b-base</th>\n",
       "      <td>{'Answer Relevancy': 0.6, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.25, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.5399999999999999, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.7571428571428571, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.7333333333333333, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.6, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.45, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.6888888888888889, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.625, 'Hallucination': 1.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 0.4066666666666666, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.4552631578947368, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.7, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.3333333333333333, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.6285714285714286, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.375, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.4833333333333333, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8, 'Hallucination': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baichuan2-13b-chat</th>\n",
       "      <td>{'Answer Relevancy': 0.95, 'Hallucination': 0....</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.96, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.9777777777777779, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8833333333333332, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.7555555555555555, 'Hall...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.95, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.9, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.8, 'Hallucination': 0.85}</td>\n",
       "      <td>{'Answer Relevancy': 0.85, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.9555555555555555, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.9777777777777779, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9583333333333334, 'Hall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baichuan2-7b-chat</th>\n",
       "      <td>{'Answer Relevancy': 0.6716666666666666, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.9333333333333332, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 0.9, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6...</td>\n",
       "      <td>{'Hallucination': 1.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.75}</td>\n",
       "      <td>{'Answer Relevancy': 0.5878787878787879, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8272727272727274, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.5147058823529411, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8933333333333333, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.75, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.99, 'Hallucination': 0....</td>\n",
       "      <td>{'Answer Relevancy': 0.971875, 'Hallucination'...</td>\n",
       "      <td>{'Answer Relevancy': 0.9857142857142858, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9736842105263158, 'Hall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infini-megrez-7b</th>\n",
       "      <td>{'Answer Relevancy': 0.9, 'Hallucination': 0.5...</td>\n",
       "      <td>{'Answer Relevancy': 0.6, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.8, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.8545454545454545, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9714285714285715, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 0.8102564102564103, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9666666666666668, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.95, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.725, 'Hallucination': 1.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 0.8833333333333332, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9333333333333332, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.85, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.7271428571428571, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.6044444444444445, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 0.8971428571428571, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.7375, 'Hallucination': ...</td>\n",
       "      <td>{'Answer Relevancy': 0.82, 'Hallucination': 0....</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-13b-chat</th>\n",
       "      <td>{'Answer Relevancy': 0.8800000000000001, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.7666666666666666, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.6285714285714284, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.6619047619047619, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.7377281587807903, 'Hall...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 0.9666666666666668, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.6583333333333334, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9512820512820512, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9714285714285715, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.6933333333333334, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9538461538461538, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9846153846153847, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9800000000000001, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-70b</th>\n",
       "      <td>{'Answer Relevancy': 0.1982033096926714, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.6626984126984127, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.6954545454545454, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.7538461538461538, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.5166666666666667, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 0.6659420289855073, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.6794871794871794, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.72, 'Hallucination': 0....</td>\n",
       "      <td>{'Answer Relevancy': 0.75, 'Hallucination': 0.75}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 0.9006451612903226, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.4620915032679738, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8235294117647058, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.5692307692307692, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.27999999999999997, 'Hal...</td>\n",
       "      <td>{'Answer Relevancy': 0.4023809523809524, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.6428571428571429, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8857142857142858, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.5, 'Hallucination': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-70b-chat</th>\n",
       "      <td>{'Answer Relevancy': 0.96, 'Hallucination': 0.55}</td>\n",
       "      <td>{'Answer Relevancy': 0.9199999999999999, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.975, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.6453333333333333, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 0.96, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 1.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 0.5433333333333333, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.7833333333333333, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.71, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.8118181818181818, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8300000000000001, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 0.9888888888888889, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9818181818181818, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9366666666666668, 'Hall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-7b-chat</th>\n",
       "      <td>{'Answer Relevancy': 0.7466666666666666, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.6666666666666667, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.65, 'Hallucination': 0....</td>\n",
       "      <td>{'Answer Relevancy': 0.8197945845004668, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9428571428571428, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.9714285714285715, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8, 'Hallucination': 1.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.9777777777777779, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.6238095238095238, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9888888888888889, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.8400000000000001, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.24}</td>\n",
       "      <td>{'Answer Relevancy': 0.9852941176470589, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9800000000000001, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.984, 'Hallucination': 0.4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-3-8b-instruct</th>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.5...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.7666666666666667, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9454545454545455, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9666666666666668, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.9514285714285714, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Hallucination': 1.0, 'Answer Relevancy': 1.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 0.8, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.9714285714285715, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.96, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.7333333333333334, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8666666666666668, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.85, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.9857142857142858, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9454545454545455, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9587044534412955, 'Hall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-14b-chat</th>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4...</td>\n",
       "      <td>{'Answer Relevancy': 0.4, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.5, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.9428571428571428, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.5}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 0.8, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.96, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.96, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.6642857142857143, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9333333333333332, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.9800000000000001, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9511111111111111, 'Hall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-72b</th>\n",
       "      <td>{'Answer Relevancy': 0.9, 'Hallucination': 0.5...</td>\n",
       "      <td>{'Answer Relevancy': 0.8666666666666668, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.9166666666666667, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 0.9333333333333332, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.8333333333333333, 'Hall...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 0.7833333333333333, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.96, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.2, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.96, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.9333333333333332, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.24}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.3...</td>\n",
       "      <td>{'Answer Relevancy': 0.978974358974359, 'Hallu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-72b-chat</th>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.7...</td>\n",
       "      <td>{'Answer Relevancy': 0.8, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 0.7333333333333333, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8555555555555555, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4...</td>\n",
       "      <td>{'Answer Relevancy': 0.7266483516483516, 'Hall...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 0.8333333333333333, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9099999999999999, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9666666666666666, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9514285714285714, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 0.9857142857142858, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.3...</td>\n",
       "      <td>{'Answer Relevancy': 0.9818181818181818, 'Hall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-7b-chat</th>\n",
       "      <td>{'Answer Relevancy': 0.9333333333333333, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.7, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.9, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.9, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.95, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 1.0}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.9333333333333332, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8666666666666668, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9333333333333332, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8866666666666667, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9333333333333333, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.3...</td>\n",
       "      <td>{'Answer Relevancy': 0.9358823529411764, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9875, 'Hallucination': ...</td>\n",
       "      <td>{'Answer Relevancy': 0.75, 'Hallucination': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1.5-14b-chat</th>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.7...</td>\n",
       "      <td>{'Answer Relevancy': 0.95, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.9199999999999999, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.6878787878787879, 'Hall...</td>\n",
       "      <td>{'Hallucination': 0.4, 'Answer Relevancy': 0.9...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2...</td>\n",
       "      <td>{'Answer Relevancy': 0.9791666666666666, 'Hall...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 0.95, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.8761904761904763, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2...</td>\n",
       "      <td>{'Answer Relevancy': 0.9894736842105264, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.3...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1.5-72b</th>\n",
       "      <td>{'Answer Relevancy': 0.8666666666666668, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 0.95, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.0}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.2916666666666667, 'Hall...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 0.9, 'Hallucination': 0.8}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 1.0}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.8871794871794872, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9333333333333332, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.1...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4...</td>\n",
       "      <td>{'Answer Relevancy': 0.9641025641025641, 'Hall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1.5-7b-chat</th>\n",
       "      <td>{'Answer Relevancy': 0.7, 'Hallucination': 0.7...</td>\n",
       "      <td>{'Answer Relevancy': 0.8928571428571428, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8166666666666668, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.8133333333333332, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.2}</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 0.8448737794713027, 'Hall...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'Answer Relevancy': 0.9484848484848485, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9428571428571428, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9222222222222222, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.6}</td>\n",
       "      <td>{'Answer Relevancy': 0.8628571428571428, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 1.0, 'Hallucination': 0.4}</td>\n",
       "      <td>{'Answer Relevancy': 0.9777777777777779, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9427106227106228, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9818181818181818, 'Hall...</td>\n",
       "      <td>{'Answer Relevancy': 0.9703296703296704, 'Hall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       1-1_2_high_freq_ent_sample.json  \\\n",
       "baichuan2-13b-base     {'Answer Relevancy': 0.6, 'Hallucination': 0.6}   \n",
       "baichuan2-13b-chat   {'Answer Relevancy': 0.95, 'Hallucination': 0....   \n",
       "baichuan2-7b-chat    {'Answer Relevancy': 0.6716666666666666, 'Hall...   \n",
       "infini-megrez-7b     {'Answer Relevancy': 0.9, 'Hallucination': 0.5...   \n",
       "llama-2-13b-chat     {'Answer Relevancy': 0.8800000000000001, 'Hall...   \n",
       "llama-2-70b          {'Answer Relevancy': 0.1982033096926714, 'Hall...   \n",
       "llama-2-70b-chat     {'Answer Relevancy': 0.96, 'Hallucination': 0.55}   \n",
       "llama-2-7b-chat      {'Answer Relevancy': 0.7466666666666666, 'Hall...   \n",
       "llama-3-8b-instruct  {'Answer Relevancy': 1.0, 'Hallucination': 0.5...   \n",
       "qwen-14b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.4...   \n",
       "qwen-72b             {'Answer Relevancy': 0.9, 'Hallucination': 0.5...   \n",
       "qwen-72b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.7...   \n",
       "qwen-7b-chat         {'Answer Relevancy': 0.9333333333333333, 'Hall...   \n",
       "qwen1.5-14b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.7...   \n",
       "qwen1.5-72b          {'Answer Relevancy': 0.8666666666666668, 'Hall...   \n",
       "qwen1.5-7b-chat      {'Answer Relevancy': 0.7, 'Hallucination': 0.7...   \n",
       "\n",
       "                                        1-2_1_low_freq_ent_sample.json  \\\n",
       "baichuan2-13b-base    {'Answer Relevancy': 0.25, 'Hallucination': 0.6}   \n",
       "baichuan2-13b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "baichuan2-7b-chat      {'Answer Relevancy': 0.8, 'Hallucination': 0.6}   \n",
       "infini-megrez-7b       {'Answer Relevancy': 0.6, 'Hallucination': 0.8}   \n",
       "llama-2-13b-chat     {'Answer Relevancy': 0.7666666666666666, 'Hall...   \n",
       "llama-2-70b          {'Answer Relevancy': 0.6626984126984127, 'Hall...   \n",
       "llama-2-70b-chat     {'Answer Relevancy': 0.9199999999999999, 'Hall...   \n",
       "llama-2-7b-chat      {'Answer Relevancy': 0.6666666666666667, 'Hall...   \n",
       "llama-3-8b-instruct    {'Answer Relevancy': 1.0, 'Hallucination': 0.8}   \n",
       "qwen-14b-chat          {'Answer Relevancy': 0.4, 'Hallucination': 1.0}   \n",
       "qwen-72b             {'Answer Relevancy': 0.8666666666666668, 'Hall...   \n",
       "qwen-72b-chat          {'Answer Relevancy': 0.8, 'Hallucination': 0.4}   \n",
       "qwen-7b-chat           {'Answer Relevancy': 0.8, 'Hallucination': 0.6}   \n",
       "qwen1.5-14b-chat      {'Answer Relevancy': 0.95, 'Hallucination': 1.0}   \n",
       "qwen1.5-72b            {'Answer Relevancy': 1.0, 'Hallucination': 0.8}   \n",
       "qwen1.5-7b-chat      {'Answer Relevancy': 0.8928571428571428, 'Hall...   \n",
       "\n",
       "                                     1-3_r_1_simple_sample_sample.json  \\\n",
       "baichuan2-13b-base   {'Answer Relevancy': 0.5399999999999999, 'Hall...   \n",
       "baichuan2-13b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 1.0}   \n",
       "baichuan2-7b-chat      {'Answer Relevancy': 1.0, 'Hallucination': 0.8}   \n",
       "infini-megrez-7b       {'Answer Relevancy': 0.8, 'Hallucination': 1.0}   \n",
       "llama-2-13b-chat     {'Answer Relevancy': 0.6285714285714284, 'Hall...   \n",
       "llama-2-70b          {'Answer Relevancy': 0.6954545454545454, 'Hall...   \n",
       "llama-2-70b-chat     {'Answer Relevancy': 0.975, 'Hallucination': 1.0}   \n",
       "llama-2-7b-chat      {'Answer Relevancy': 0.65, 'Hallucination': 0....   \n",
       "llama-3-8b-instruct  {'Answer Relevancy': 0.7666666666666667, 'Hall...   \n",
       "qwen-14b-chat          {'Answer Relevancy': 0.5, 'Hallucination': 0.8}   \n",
       "qwen-72b               {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen-72b-chat        {'Answer Relevancy': 0.7333333333333333, 'Hall...   \n",
       "qwen-7b-chat           {'Answer Relevancy': 0.7, 'Hallucination': 0.6}   \n",
       "qwen1.5-14b-chat     {'Answer Relevancy': 0.9199999999999999, 'Hall...   \n",
       "qwen1.5-72b            {'Answer Relevancy': 1.0, 'Hallucination': 1.0}   \n",
       "qwen1.5-7b-chat      {'Answer Relevancy': 0.8166666666666668, 'Hall...   \n",
       "\n",
       "                                            2-1_COPEN++csj_sample.json  \\\n",
       "baichuan2-13b-base   {'Answer Relevancy': 0.7571428571428571, 'Hall...   \n",
       "baichuan2-13b-chat    {'Answer Relevancy': 0.96, 'Hallucination': 1.0}   \n",
       "baichuan2-7b-chat    {'Answer Relevancy': 0.9333333333333332, 'Hall...   \n",
       "infini-megrez-7b     {'Answer Relevancy': 0.8545454545454545, 'Hall...   \n",
       "llama-2-13b-chat     {'Answer Relevancy': 0.6619047619047619, 'Hall...   \n",
       "llama-2-70b          {'Answer Relevancy': 0.7538461538461538, 'Hall...   \n",
       "llama-2-70b-chat     {'Answer Relevancy': 0.6453333333333333, 'Hall...   \n",
       "llama-2-7b-chat      {'Answer Relevancy': 0.8197945845004668, 'Hall...   \n",
       "llama-3-8b-instruct  {'Answer Relevancy': 0.9454545454545455, 'Hall...   \n",
       "qwen-14b-chat        {'Answer Relevancy': 0.9428571428571428, 'Hall...   \n",
       "qwen-72b             {'Answer Relevancy': 0.9166666666666667, 'Hall...   \n",
       "qwen-72b-chat        {'Answer Relevancy': 0.8555555555555555, 'Hall...   \n",
       "qwen-7b-chat           {'Answer Relevancy': 0.9, 'Hallucination': 1.0}   \n",
       "qwen1.5-14b-chat     {'Answer Relevancy': 0.6878787878787879, 'Hall...   \n",
       "qwen1.5-72b           {'Answer Relevancy': 0.95, 'Hallucination': 1.0}   \n",
       "qwen1.5-7b-chat      {'Answer Relevancy': 0.8133333333333332, 'Hall...   \n",
       "\n",
       "                                            2-2_COPEN++cpj_sample.json  \\\n",
       "baichuan2-13b-base     {'Answer Relevancy': 0.8, 'Hallucination': 0.6}   \n",
       "baichuan2-13b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.2}   \n",
       "baichuan2-7b-chat      {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "infini-megrez-7b     {'Answer Relevancy': 0.9714285714285715, 'Hall...   \n",
       "llama-2-13b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.2}   \n",
       "llama-2-70b          {'Answer Relevancy': 0.5166666666666667, 'Hall...   \n",
       "llama-2-70b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "llama-2-7b-chat      {'Answer Relevancy': 0.9428571428571428, 'Hall...   \n",
       "llama-3-8b-instruct  {'Answer Relevancy': 0.9666666666666668, 'Hall...   \n",
       "qwen-14b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.8}   \n",
       "qwen-72b               {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "qwen-72b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen-7b-chat           {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "qwen1.5-14b-chat     {'Hallucination': 0.4, 'Answer Relevancy': 0.9...   \n",
       "qwen1.5-72b            {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "qwen1.5-7b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "\n",
       "                                            2-3_COPEN++cic_sample.json  \\\n",
       "baichuan2-13b-base   {'Answer Relevancy': 0.7333333333333333, 'Hall...   \n",
       "baichuan2-13b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "baichuan2-7b-chat      {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "infini-megrez-7b       {'Answer Relevancy': 0.8, 'Hallucination': 0.4}   \n",
       "llama-2-13b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "llama-2-70b            {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "llama-2-70b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "llama-2-7b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "llama-3-8b-instruct    {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "qwen-14b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "qwen-72b               {'Answer Relevancy': 1.0, 'Hallucination': 0.2}   \n",
       "qwen-72b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen-7b-chat           {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen1.5-14b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen1.5-72b            {'Answer Relevancy': 1.0, 'Hallucination': 0.2}   \n",
       "qwen1.5-7b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "\n",
       "                                        2-4_FewNERD++inter_sample.json  \\\n",
       "baichuan2-13b-base     {'Answer Relevancy': 0.6, 'Hallucination': 0.8}   \n",
       "baichuan2-13b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "baichuan2-7b-chat      {'Answer Relevancy': 0.9, 'Hallucination': 0.4}   \n",
       "infini-megrez-7b     {'Answer Relevancy': 0.8102564102564103, 'Hall...   \n",
       "llama-2-13b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.2}   \n",
       "llama-2-70b          {'Answer Relevancy': 0.6659420289855073, 'Hall...   \n",
       "llama-2-70b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "llama-2-7b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "llama-3-8b-instruct    {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "qwen-14b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "qwen-72b               {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "qwen-72b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "qwen-7b-chat           {'Answer Relevancy': 0.9, 'Hallucination': 0.2}   \n",
       "qwen1.5-14b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "qwen1.5-72b            {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "qwen1.5-7b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.2}   \n",
       "\n",
       "                                        2-4_FewNERD++intra_sample.json  \\\n",
       "baichuan2-13b-base    {'Answer Relevancy': 0.45, 'Hallucination': 0.8}   \n",
       "baichuan2-13b-chat   {'Answer Relevancy': 0.9777777777777779, 'Hall...   \n",
       "baichuan2-7b-chat      {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "infini-megrez-7b     {'Answer Relevancy': 0.9666666666666668, 'Hall...   \n",
       "llama-2-13b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "llama-2-70b          {'Answer Relevancy': 0.6794871794871794, 'Hall...   \n",
       "llama-2-70b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "llama-2-7b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "llama-3-8b-instruct  {'Answer Relevancy': 0.9514285714285714, 'Hall...   \n",
       "qwen-14b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "qwen-72b             {'Answer Relevancy': 0.9333333333333332, 'Hall...   \n",
       "qwen-72b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "qwen-7b-chat           {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "qwen1.5-14b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.2}   \n",
       "qwen1.5-72b            {'Answer Relevancy': 1.0, 'Hallucination': 0.2}   \n",
       "qwen1.5-7b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.2}   \n",
       "\n",
       "                                   2-4_FewNERD++supervised_sample.json  \\\n",
       "baichuan2-13b-base   {'Answer Relevancy': 0.6888888888888889, 'Hall...   \n",
       "baichuan2-13b-chat   {'Answer Relevancy': 0.8833333333333332, 'Hall...   \n",
       "baichuan2-7b-chat    {'Answer Relevancy': 1.0, 'Hallucination': 0.6...   \n",
       "infini-megrez-7b      {'Answer Relevancy': 0.95, 'Hallucination': 0.8}   \n",
       "llama-2-13b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.8}   \n",
       "llama-2-70b          {'Answer Relevancy': 0.72, 'Hallucination': 0....   \n",
       "llama-2-70b-chat      {'Answer Relevancy': 0.96, 'Hallucination': 0.6}   \n",
       "llama-2-7b-chat      {'Answer Relevancy': 0.9714285714285715, 'Hall...   \n",
       "llama-3-8b-instruct    {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen-14b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen-72b               {'Answer Relevancy': 0.8, 'Hallucination': 0.6}   \n",
       "qwen-72b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.4...   \n",
       "qwen-7b-chat          {'Answer Relevancy': 0.95, 'Hallucination': 0.4}   \n",
       "qwen1.5-14b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.2...   \n",
       "qwen1.5-72b            {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen1.5-7b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "\n",
       "                                                2-5_DocRED_sample.json  ...  \\\n",
       "baichuan2-13b-base   {'Answer Relevancy': 0.625, 'Hallucination': 1.0}  ...   \n",
       "baichuan2-13b-chat   {'Answer Relevancy': 0.7555555555555555, 'Hall...  ...   \n",
       "baichuan2-7b-chat                               {'Hallucination': 1.0}  ...   \n",
       "infini-megrez-7b     {'Answer Relevancy': 0.725, 'Hallucination': 1.0}  ...   \n",
       "llama-2-13b-chat     {'Answer Relevancy': 0.7377281587807903, 'Hall...  ...   \n",
       "llama-2-70b          {'Answer Relevancy': 0.75, 'Hallucination': 0.75}  ...   \n",
       "llama-2-70b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 1.0}  ...   \n",
       "llama-2-7b-chat        {'Answer Relevancy': 0.8, 'Hallucination': 1.0}  ...   \n",
       "llama-3-8b-instruct    {'Hallucination': 1.0, 'Answer Relevancy': 1.0}  ...   \n",
       "qwen-14b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.5}  ...   \n",
       "qwen-72b             {'Answer Relevancy': 0.8333333333333333, 'Hall...  ...   \n",
       "qwen-72b-chat        {'Answer Relevancy': 0.7266483516483516, 'Hall...  ...   \n",
       "qwen-7b-chat           {'Answer Relevancy': 1.0, 'Hallucination': 1.0}  ...   \n",
       "qwen1.5-14b-chat     {'Answer Relevancy': 0.9791666666666666, 'Hall...  ...   \n",
       "qwen1.5-72b          {'Answer Relevancy': 0.2916666666666667, 'Hall...  ...   \n",
       "qwen1.5-7b-chat      {'Answer Relevancy': 0.8448737794713027, 'Hall...  ...   \n",
       "\n",
       "                                              3-1_hotpotqa_sample.json  \\\n",
       "baichuan2-13b-base   {'Answer Relevancy': 0.4066666666666666, 'Hall...   \n",
       "baichuan2-13b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "baichuan2-7b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.75}   \n",
       "infini-megrez-7b     {'Answer Relevancy': 0.8833333333333332, 'Hall...   \n",
       "llama-2-13b-chat     {'Answer Relevancy': 0.9666666666666668, 'Hall...   \n",
       "llama-2-70b          {'Answer Relevancy': 0.9006451612903226, 'Hall...   \n",
       "llama-2-70b-chat     {'Answer Relevancy': 0.5433333333333333, 'Hall...   \n",
       "llama-2-7b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "llama-3-8b-instruct    {'Answer Relevancy': 0.8, 'Hallucination': 0.6}   \n",
       "qwen-14b-chat          {'Answer Relevancy': 0.8, 'Hallucination': 0.6}   \n",
       "qwen-72b             {'Answer Relevancy': 0.7833333333333333, 'Hall...   \n",
       "qwen-72b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.8}   \n",
       "qwen-7b-chat           {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen1.5-14b-chat      {'Answer Relevancy': 0.95, 'Hallucination': 0.6}   \n",
       "qwen1.5-72b            {'Answer Relevancy': 0.9, 'Hallucination': 0.8}   \n",
       "qwen1.5-7b-chat      {'Answer Relevancy': 0.9484848484848485, 'Hall...   \n",
       "\n",
       "                                       3-2_2wikimultihopqa_sample.json  \\\n",
       "baichuan2-13b-base   {'Answer Relevancy': 0.4552631578947368, 'Hall...   \n",
       "baichuan2-13b-chat    {'Answer Relevancy': 0.95, 'Hallucination': 0.6}   \n",
       "baichuan2-7b-chat    {'Answer Relevancy': 0.5878787878787879, 'Hall...   \n",
       "infini-megrez-7b     {'Answer Relevancy': 0.9333333333333332, 'Hall...   \n",
       "llama-2-13b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.8}   \n",
       "llama-2-70b            {'Answer Relevancy': 1.0, 'Hallucination': 0.8}   \n",
       "llama-2-70b-chat     {'Answer Relevancy': 0.7833333333333333, 'Hall...   \n",
       "llama-2-7b-chat      {'Answer Relevancy': 0.9777777777777779, 'Hall...   \n",
       "llama-3-8b-instruct  {'Answer Relevancy': 0.9714285714285715, 'Hall...   \n",
       "qwen-14b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen-72b              {'Answer Relevancy': 0.96, 'Hallucination': 0.8}   \n",
       "qwen-72b-chat        {'Answer Relevancy': 0.8333333333333333, 'Hall...   \n",
       "qwen-7b-chat         {'Answer Relevancy': 0.9333333333333332, 'Hall...   \n",
       "qwen1.5-14b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 1.0}   \n",
       "qwen1.5-72b            {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen1.5-7b-chat      {'Answer Relevancy': 0.9428571428571428, 'Hall...   \n",
       "\n",
       "                                               3-3_musique_sample.json  \\\n",
       "baichuan2-13b-base     {'Answer Relevancy': 0.7, 'Hallucination': 1.0}   \n",
       "baichuan2-13b-chat     {'Answer Relevancy': 0.9, 'Hallucination': 1.0}   \n",
       "baichuan2-7b-chat    {'Answer Relevancy': 0.8272727272727274, 'Hall...   \n",
       "infini-megrez-7b      {'Answer Relevancy': 0.85, 'Hallucination': 1.0}   \n",
       "llama-2-13b-chat     {'Answer Relevancy': 0.6583333333333334, 'Hall...   \n",
       "llama-2-70b          {'Answer Relevancy': 0.4620915032679738, 'Hall...   \n",
       "llama-2-70b-chat      {'Answer Relevancy': 0.71, 'Hallucination': 1.0}   \n",
       "llama-2-7b-chat      {'Answer Relevancy': 0.6238095238095238, 'Hall...   \n",
       "llama-3-8b-instruct   {'Answer Relevancy': 0.96, 'Hallucination': 1.0}   \n",
       "qwen-14b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen-72b               {'Answer Relevancy': 0.2, 'Hallucination': 1.0}   \n",
       "qwen-72b-chat        {'Answer Relevancy': 0.9099999999999999, 'Hall...   \n",
       "qwen-7b-chat         {'Answer Relevancy': 0.8666666666666668, 'Hall...   \n",
       "qwen1.5-14b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.8}   \n",
       "qwen1.5-72b            {'Answer Relevancy': 1.0, 'Hallucination': 1.0}   \n",
       "qwen1.5-7b-chat      {'Answer Relevancy': 0.9222222222222222, 'Hall...   \n",
       "\n",
       "                                                3-4_kqapro_sample.json  \\\n",
       "baichuan2-13b-base   {'Answer Relevancy': 0.3333333333333333, 'Hall...   \n",
       "baichuan2-13b-chat    {'Answer Relevancy': 0.8, 'Hallucination': 0.85}   \n",
       "baichuan2-7b-chat    {'Answer Relevancy': 0.5147058823529411, 'Hall...   \n",
       "infini-megrez-7b     {'Answer Relevancy': 0.7271428571428571, 'Hall...   \n",
       "llama-2-13b-chat     {'Answer Relevancy': 0.9512820512820512, 'Hall...   \n",
       "llama-2-70b          {'Answer Relevancy': 0.8235294117647058, 'Hall...   \n",
       "llama-2-70b-chat     {'Answer Relevancy': 0.8118181818181818, 'Hall...   \n",
       "llama-2-7b-chat      {'Answer Relevancy': 0.9888888888888889, 'Hall...   \n",
       "llama-3-8b-instruct  {'Answer Relevancy': 0.7333333333333334, 'Hall...   \n",
       "qwen-14b-chat         {'Answer Relevancy': 0.96, 'Hallucination': 0.8}   \n",
       "qwen-72b              {'Answer Relevancy': 0.96, 'Hallucination': 0.6}   \n",
       "qwen-72b-chat        {'Answer Relevancy': 0.9666666666666666, 'Hall...   \n",
       "qwen-7b-chat         {'Answer Relevancy': 0.9333333333333332, 'Hall...   \n",
       "qwen1.5-14b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 1.0}   \n",
       "qwen1.5-72b            {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen1.5-7b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "\n",
       "                                             3-5_KoRC++ood_sample.json  \\\n",
       "baichuan2-13b-base   {'Answer Relevancy': 0.6285714285714286, 'Hall...   \n",
       "baichuan2-13b-chat    {'Answer Relevancy': 0.85, 'Hallucination': 0.8}   \n",
       "baichuan2-7b-chat    {'Answer Relevancy': 0.8933333333333333, 'Hall...   \n",
       "infini-megrez-7b     {'Answer Relevancy': 0.6044444444444445, 'Hall...   \n",
       "llama-2-13b-chat     {'Answer Relevancy': 0.9714285714285715, 'Hall...   \n",
       "llama-2-70b          {'Answer Relevancy': 0.5692307692307692, 'Hall...   \n",
       "llama-2-70b-chat     {'Answer Relevancy': 0.8300000000000001, 'Hall...   \n",
       "llama-2-7b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "llama-3-8b-instruct  {'Answer Relevancy': 0.8666666666666668, 'Hall...   \n",
       "qwen-14b-chat         {'Answer Relevancy': 0.96, 'Hallucination': 0.6}   \n",
       "qwen-72b               {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "qwen-72b-chat        {'Answer Relevancy': 0.9514285714285714, 'Hall...   \n",
       "qwen-7b-chat         {'Answer Relevancy': 0.8866666666666667, 'Hall...   \n",
       "qwen1.5-14b-chat     {'Answer Relevancy': 0.8761904761904763, 'Hall...   \n",
       "qwen1.5-72b          {'Answer Relevancy': 0.8871794871794872, 'Hall...   \n",
       "qwen1.5-7b-chat      {'Answer Relevancy': 0.8628571428571428, 'Hall...   \n",
       "\n",
       "                                           3-6_r_KoRC++ood_sample.json  \\\n",
       "baichuan2-13b-base   {'Answer Relevancy': 0.375, 'Hallucination': 0.6}   \n",
       "baichuan2-13b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.8}   \n",
       "baichuan2-7b-chat     {'Answer Relevancy': 0.75, 'Hallucination': 0.6}   \n",
       "infini-megrez-7b       {'Answer Relevancy': 0.9, 'Hallucination': 0.4}   \n",
       "llama-2-13b-chat     {'Answer Relevancy': 0.6933333333333334, 'Hall...   \n",
       "llama-2-70b          {'Answer Relevancy': 0.27999999999999997, 'Hal...   \n",
       "llama-2-70b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.6}   \n",
       "llama-2-7b-chat      {'Answer Relevancy': 0.8400000000000001, 'Hall...   \n",
       "llama-3-8b-instruct   {'Answer Relevancy': 0.85, 'Hallucination': 0.6}   \n",
       "qwen-14b-chat        {'Answer Relevancy': 0.6642857142857143, 'Hall...   \n",
       "qwen-72b             {'Answer Relevancy': 0.9333333333333332, 'Hall...   \n",
       "qwen-72b-chat          {'Answer Relevancy': 0.9, 'Hallucination': 0.6}   \n",
       "qwen-7b-chat         {'Answer Relevancy': 0.9333333333333333, 'Hall...   \n",
       "qwen1.5-14b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "qwen1.5-72b          {'Answer Relevancy': 0.9333333333333332, 'Hall...   \n",
       "qwen1.5-7b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.4}   \n",
       "\n",
       "                                       4-1_without_triples_sample.json  \\\n",
       "baichuan2-13b-base     {'Answer Relevancy': 1.0, 'Hallucination': 0.2}   \n",
       "baichuan2-13b-chat   {'Answer Relevancy': 0.9555555555555555, 'Hall...   \n",
       "baichuan2-7b-chat    {'Answer Relevancy': 0.99, 'Hallucination': 0....   \n",
       "infini-megrez-7b     {'Answer Relevancy': 0.8971428571428571, 'Hall...   \n",
       "llama-2-13b-chat     {'Answer Relevancy': 0.9538461538461538, 'Hall...   \n",
       "llama-2-70b          {'Answer Relevancy': 0.4023809523809524, 'Hall...   \n",
       "llama-2-70b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.2}   \n",
       "llama-2-7b-chat       {'Answer Relevancy': 1.0, 'Hallucination': 0.24}   \n",
       "llama-3-8b-instruct    {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "qwen-14b-chat        {'Answer Relevancy': 0.9333333333333332, 'Hall...   \n",
       "qwen-72b              {'Answer Relevancy': 1.0, 'Hallucination': 0.24}   \n",
       "qwen-72b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.2}   \n",
       "qwen-7b-chat         {'Answer Relevancy': 1.0, 'Hallucination': 0.3...   \n",
       "qwen1.5-14b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.2...   \n",
       "qwen1.5-72b          {'Answer Relevancy': 1.0, 'Hallucination': 0.4...   \n",
       "qwen1.5-7b-chat      {'Answer Relevancy': 0.9777777777777779, 'Hall...   \n",
       "\n",
       "                                          4-1_with_triples_sample.json  \\\n",
       "baichuan2-13b-base     {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "baichuan2-13b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "baichuan2-7b-chat    {'Answer Relevancy': 0.971875, 'Hallucination'...   \n",
       "infini-megrez-7b     {'Answer Relevancy': 0.7375, 'Hallucination': ...   \n",
       "llama-2-13b-chat     {'Answer Relevancy': 0.9846153846153847, 'Hall...   \n",
       "llama-2-70b          {'Answer Relevancy': 0.6428571428571429, 'Hall...   \n",
       "llama-2-70b-chat     {'Answer Relevancy': 0.9888888888888889, 'Hall...   \n",
       "llama-2-7b-chat      {'Answer Relevancy': 0.9852941176470589, 'Hall...   \n",
       "llama-3-8b-instruct  {'Answer Relevancy': 0.9857142857142858, 'Hall...   \n",
       "qwen-14b-chat          {'Answer Relevancy': 1.0, 'Hallucination': 0.0}   \n",
       "qwen-72b               {'Answer Relevancy': 1.0, 'Hallucination': 0.2}   \n",
       "qwen-72b-chat        {'Answer Relevancy': 0.9857142857142858, 'Hall...   \n",
       "qwen-7b-chat         {'Answer Relevancy': 0.9358823529411764, 'Hall...   \n",
       "qwen1.5-14b-chat     {'Answer Relevancy': 0.9894736842105264, 'Hall...   \n",
       "qwen1.5-72b          {'Answer Relevancy': 1.0, 'Hallucination': 0.1...   \n",
       "qwen1.5-7b-chat      {'Answer Relevancy': 0.9427106227106228, 'Hall...   \n",
       "\n",
       "                                     4-2_r_without_triples_sample.json  \\\n",
       "baichuan2-13b-base   {'Answer Relevancy': 0.4833333333333333, 'Hall...   \n",
       "baichuan2-13b-chat   {'Answer Relevancy': 0.9777777777777779, 'Hall...   \n",
       "baichuan2-7b-chat    {'Answer Relevancy': 0.9857142857142858, 'Hall...   \n",
       "infini-megrez-7b     {'Answer Relevancy': 0.82, 'Hallucination': 0....   \n",
       "llama-2-13b-chat     {'Answer Relevancy': 0.9800000000000001, 'Hall...   \n",
       "llama-2-70b          {'Answer Relevancy': 0.8857142857142858, 'Hall...   \n",
       "llama-2-70b-chat     {'Answer Relevancy': 0.9818181818181818, 'Hall...   \n",
       "llama-2-7b-chat      {'Answer Relevancy': 0.9800000000000001, 'Hall...   \n",
       "llama-3-8b-instruct  {'Answer Relevancy': 0.9454545454545455, 'Hall...   \n",
       "qwen-14b-chat        {'Answer Relevancy': 0.9800000000000001, 'Hall...   \n",
       "qwen-72b             {'Answer Relevancy': 1.0, 'Hallucination': 0.3...   \n",
       "qwen-72b-chat        {'Answer Relevancy': 1.0, 'Hallucination': 0.3...   \n",
       "qwen-7b-chat         {'Answer Relevancy': 0.9875, 'Hallucination': ...   \n",
       "qwen1.5-14b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.3...   \n",
       "qwen1.5-72b          {'Answer Relevancy': 1.0, 'Hallucination': 0.4...   \n",
       "qwen1.5-7b-chat      {'Answer Relevancy': 0.9818181818181818, 'Hall...   \n",
       "\n",
       "                                        4-2_r_with_triples_sample.json  \n",
       "baichuan2-13b-base     {'Answer Relevancy': 0.8, 'Hallucination': 0.6}  \n",
       "baichuan2-13b-chat   {'Answer Relevancy': 0.9583333333333334, 'Hall...  \n",
       "baichuan2-7b-chat    {'Answer Relevancy': 0.9736842105263158, 'Hall...  \n",
       "infini-megrez-7b       {'Answer Relevancy': 1.0, 'Hallucination': 0.6}  \n",
       "llama-2-13b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.4...  \n",
       "llama-2-70b            {'Answer Relevancy': 0.5, 'Hallucination': 0.0}  \n",
       "llama-2-70b-chat     {'Answer Relevancy': 0.9366666666666668, 'Hall...  \n",
       "llama-2-7b-chat      {'Answer Relevancy': 0.984, 'Hallucination': 0.4}  \n",
       "llama-3-8b-instruct  {'Answer Relevancy': 0.9587044534412955, 'Hall...  \n",
       "qwen-14b-chat        {'Answer Relevancy': 0.9511111111111111, 'Hall...  \n",
       "qwen-72b             {'Answer Relevancy': 0.978974358974359, 'Hallu...  \n",
       "qwen-72b-chat        {'Answer Relevancy': 0.9818181818181818, 'Hall...  \n",
       "qwen-7b-chat         {'Answer Relevancy': 0.75, 'Hallucination': 0....  \n",
       "qwen1.5-14b-chat     {'Answer Relevancy': 1.0, 'Hallucination': 0.1...  \n",
       "qwen1.5-72b          {'Answer Relevancy': 0.9641025641025641, 'Hall...  \n",
       "qwen1.5-7b-chat      {'Answer Relevancy': 0.9703296703296704, 'Hall...  \n",
       "\n",
       "[16 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(data_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXKVMN4QF7JC6Q6ZW6FV1EE1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-1_2_high_freq_ent_sample.json</th>\n",
       "      <th>1-2_1_low_freq_ent_sample.json</th>\n",
       "      <th>1-3_r_1_simple_sample_sample.json</th>\n",
       "      <th>2-1_COPEN++csj_sample.json</th>\n",
       "      <th>2-2_COPEN++cpj_sample.json</th>\n",
       "      <th>2-3_COPEN++cic_sample.json</th>\n",
       "      <th>2-4_FewNERD++inter_sample.json</th>\n",
       "      <th>2-4_FewNERD++intra_sample.json</th>\n",
       "      <th>2-4_FewNERD++supervised_sample.json</th>\n",
       "      <th>2-5_DocRED_sample.json</th>\n",
       "      <th>...</th>\n",
       "      <th>3-1_hotpotqa_sample.json</th>\n",
       "      <th>3-2_2wikimultihopqa_sample.json</th>\n",
       "      <th>3-3_musique_sample.json</th>\n",
       "      <th>3-4_kqapro_sample.json</th>\n",
       "      <th>3-5_KoRC++ood_sample.json</th>\n",
       "      <th>3-6_r_KoRC++ood_sample.json</th>\n",
       "      <th>4-1_without_triples_sample.json</th>\n",
       "      <th>4-1_with_triples_sample.json</th>\n",
       "      <th>4-2_r_without_triples_sample.json</th>\n",
       "      <th>4-2_r_with_triples_sample.json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baichuan2-13b-base</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.455263</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baichuan2-13b-chat</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baichuan2-7b-chat</th>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.587879</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.971875</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infini-megrez-7b</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.810256</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.727143</td>\n",
       "      <td>0.604444</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.897143</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-13b-chat</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.737728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.951282</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-70b</th>\n",
       "      <td>0.198203</td>\n",
       "      <td>0.662698</td>\n",
       "      <td>0.695455</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665942</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.462092</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.402381</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-70b-chat</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.645333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.811818</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.936667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-7b-chat</th>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.819795</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.623810</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-3-8b-instruct</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.958704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-14b-chat</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.664286</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.951111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-72b</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-72b-chat</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.855556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.726648</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.951429</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-7b-chat</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935882</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1.5-14b-chat</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.687879</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1.5-72b</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887179</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1.5-7b-chat</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.844874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948485</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.942711</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.970330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1-1_2_high_freq_ent_sample.json  \\\n",
       "baichuan2-13b-base                          0.600000   \n",
       "baichuan2-13b-chat                          0.950000   \n",
       "baichuan2-7b-chat                           0.671667   \n",
       "infini-megrez-7b                            0.900000   \n",
       "llama-2-13b-chat                            0.880000   \n",
       "llama-2-70b                                 0.198203   \n",
       "llama-2-70b-chat                            0.960000   \n",
       "llama-2-7b-chat                             0.746667   \n",
       "llama-3-8b-instruct                         1.000000   \n",
       "qwen-14b-chat                               1.000000   \n",
       "qwen-72b                                    0.900000   \n",
       "qwen-72b-chat                               1.000000   \n",
       "qwen-7b-chat                                0.933333   \n",
       "qwen1.5-14b-chat                            1.000000   \n",
       "qwen1.5-72b                                 0.866667   \n",
       "qwen1.5-7b-chat                             0.700000   \n",
       "\n",
       "                     1-2_1_low_freq_ent_sample.json  \\\n",
       "baichuan2-13b-base                         0.250000   \n",
       "baichuan2-13b-chat                         1.000000   \n",
       "baichuan2-7b-chat                          0.800000   \n",
       "infini-megrez-7b                           0.600000   \n",
       "llama-2-13b-chat                           0.766667   \n",
       "llama-2-70b                                0.662698   \n",
       "llama-2-70b-chat                           0.920000   \n",
       "llama-2-7b-chat                            0.666667   \n",
       "llama-3-8b-instruct                        1.000000   \n",
       "qwen-14b-chat                              0.400000   \n",
       "qwen-72b                                   0.866667   \n",
       "qwen-72b-chat                              0.800000   \n",
       "qwen-7b-chat                               0.800000   \n",
       "qwen1.5-14b-chat                           0.950000   \n",
       "qwen1.5-72b                                1.000000   \n",
       "qwen1.5-7b-chat                            0.892857   \n",
       "\n",
       "                     1-3_r_1_simple_sample_sample.json  \\\n",
       "baichuan2-13b-base                            0.540000   \n",
       "baichuan2-13b-chat                            1.000000   \n",
       "baichuan2-7b-chat                             1.000000   \n",
       "infini-megrez-7b                              0.800000   \n",
       "llama-2-13b-chat                              0.628571   \n",
       "llama-2-70b                                   0.695455   \n",
       "llama-2-70b-chat                              0.975000   \n",
       "llama-2-7b-chat                               0.650000   \n",
       "llama-3-8b-instruct                           0.766667   \n",
       "qwen-14b-chat                                 0.500000   \n",
       "qwen-72b                                      1.000000   \n",
       "qwen-72b-chat                                 0.733333   \n",
       "qwen-7b-chat                                  0.700000   \n",
       "qwen1.5-14b-chat                              0.920000   \n",
       "qwen1.5-72b                                   1.000000   \n",
       "qwen1.5-7b-chat                               0.816667   \n",
       "\n",
       "                     2-1_COPEN++csj_sample.json  2-2_COPEN++cpj_sample.json  \\\n",
       "baichuan2-13b-base                     0.757143                    0.800000   \n",
       "baichuan2-13b-chat                     0.960000                    1.000000   \n",
       "baichuan2-7b-chat                      0.933333                    1.000000   \n",
       "infini-megrez-7b                       0.854545                    0.971429   \n",
       "llama-2-13b-chat                       0.661905                    1.000000   \n",
       "llama-2-70b                            0.753846                    0.516667   \n",
       "llama-2-70b-chat                       0.645333                    1.000000   \n",
       "llama-2-7b-chat                        0.819795                    0.942857   \n",
       "llama-3-8b-instruct                    0.945455                    0.966667   \n",
       "qwen-14b-chat                          0.942857                    1.000000   \n",
       "qwen-72b                               0.916667                    1.000000   \n",
       "qwen-72b-chat                          0.855556                    1.000000   \n",
       "qwen-7b-chat                           0.900000                    1.000000   \n",
       "qwen1.5-14b-chat                       0.687879                    0.933333   \n",
       "qwen1.5-72b                            0.950000                    1.000000   \n",
       "qwen1.5-7b-chat                        0.813333                    1.000000   \n",
       "\n",
       "                     2-3_COPEN++cic_sample.json  \\\n",
       "baichuan2-13b-base                     0.733333   \n",
       "baichuan2-13b-chat                     1.000000   \n",
       "baichuan2-7b-chat                      1.000000   \n",
       "infini-megrez-7b                       0.800000   \n",
       "llama-2-13b-chat                       1.000000   \n",
       "llama-2-70b                            1.000000   \n",
       "llama-2-70b-chat                       1.000000   \n",
       "llama-2-7b-chat                        1.000000   \n",
       "llama-3-8b-instruct                    1.000000   \n",
       "qwen-14b-chat                          1.000000   \n",
       "qwen-72b                               1.000000   \n",
       "qwen-72b-chat                          1.000000   \n",
       "qwen-7b-chat                           1.000000   \n",
       "qwen1.5-14b-chat                       1.000000   \n",
       "qwen1.5-72b                            1.000000   \n",
       "qwen1.5-7b-chat                        1.000000   \n",
       "\n",
       "                     2-4_FewNERD++inter_sample.json  \\\n",
       "baichuan2-13b-base                         0.600000   \n",
       "baichuan2-13b-chat                         1.000000   \n",
       "baichuan2-7b-chat                          0.900000   \n",
       "infini-megrez-7b                           0.810256   \n",
       "llama-2-13b-chat                           1.000000   \n",
       "llama-2-70b                                0.665942   \n",
       "llama-2-70b-chat                           1.000000   \n",
       "llama-2-7b-chat                            1.000000   \n",
       "llama-3-8b-instruct                        1.000000   \n",
       "qwen-14b-chat                              1.000000   \n",
       "qwen-72b                                   1.000000   \n",
       "qwen-72b-chat                              1.000000   \n",
       "qwen-7b-chat                               0.900000   \n",
       "qwen1.5-14b-chat                           1.000000   \n",
       "qwen1.5-72b                                1.000000   \n",
       "qwen1.5-7b-chat                            1.000000   \n",
       "\n",
       "                     2-4_FewNERD++intra_sample.json  \\\n",
       "baichuan2-13b-base                         0.450000   \n",
       "baichuan2-13b-chat                         0.977778   \n",
       "baichuan2-7b-chat                          1.000000   \n",
       "infini-megrez-7b                           0.966667   \n",
       "llama-2-13b-chat                           1.000000   \n",
       "llama-2-70b                                0.679487   \n",
       "llama-2-70b-chat                           1.000000   \n",
       "llama-2-7b-chat                            1.000000   \n",
       "llama-3-8b-instruct                        0.951429   \n",
       "qwen-14b-chat                              1.000000   \n",
       "qwen-72b                                   0.933333   \n",
       "qwen-72b-chat                              1.000000   \n",
       "qwen-7b-chat                               1.000000   \n",
       "qwen1.5-14b-chat                           1.000000   \n",
       "qwen1.5-72b                                1.000000   \n",
       "qwen1.5-7b-chat                            1.000000   \n",
       "\n",
       "                     2-4_FewNERD++supervised_sample.json  \\\n",
       "baichuan2-13b-base                              0.688889   \n",
       "baichuan2-13b-chat                              0.883333   \n",
       "baichuan2-7b-chat                               1.000000   \n",
       "infini-megrez-7b                                0.950000   \n",
       "llama-2-13b-chat                                1.000000   \n",
       "llama-2-70b                                     0.720000   \n",
       "llama-2-70b-chat                                0.960000   \n",
       "llama-2-7b-chat                                 0.971429   \n",
       "llama-3-8b-instruct                             1.000000   \n",
       "qwen-14b-chat                                   1.000000   \n",
       "qwen-72b                                        0.800000   \n",
       "qwen-72b-chat                                   1.000000   \n",
       "qwen-7b-chat                                    0.950000   \n",
       "qwen1.5-14b-chat                                1.000000   \n",
       "qwen1.5-72b                                     1.000000   \n",
       "qwen1.5-7b-chat                                 1.000000   \n",
       "\n",
       "                     2-5_DocRED_sample.json  ...  3-1_hotpotqa_sample.json  \\\n",
       "baichuan2-13b-base                 0.625000  ...                  0.406667   \n",
       "baichuan2-13b-chat                 0.755556  ...                  1.000000   \n",
       "baichuan2-7b-chat                       NaN  ...                  1.000000   \n",
       "infini-megrez-7b                   0.725000  ...                  0.883333   \n",
       "llama-2-13b-chat                   0.737728  ...                  0.966667   \n",
       "llama-2-70b                        0.750000  ...                  0.900645   \n",
       "llama-2-70b-chat                   1.000000  ...                  0.543333   \n",
       "llama-2-7b-chat                    0.800000  ...                  1.000000   \n",
       "llama-3-8b-instruct                1.000000  ...                  0.800000   \n",
       "qwen-14b-chat                      1.000000  ...                  0.800000   \n",
       "qwen-72b                           0.833333  ...                  0.783333   \n",
       "qwen-72b-chat                      0.726648  ...                  1.000000   \n",
       "qwen-7b-chat                       1.000000  ...                  1.000000   \n",
       "qwen1.5-14b-chat                   0.979167  ...                  0.950000   \n",
       "qwen1.5-72b                        0.291667  ...                  0.900000   \n",
       "qwen1.5-7b-chat                    0.844874  ...                  0.948485   \n",
       "\n",
       "                     3-2_2wikimultihopqa_sample.json  3-3_musique_sample.json  \\\n",
       "baichuan2-13b-base                          0.455263                 0.700000   \n",
       "baichuan2-13b-chat                          0.950000                 0.900000   \n",
       "baichuan2-7b-chat                           0.587879                 0.827273   \n",
       "infini-megrez-7b                            0.933333                 0.850000   \n",
       "llama-2-13b-chat                            1.000000                 0.658333   \n",
       "llama-2-70b                                 1.000000                 0.462092   \n",
       "llama-2-70b-chat                            0.783333                 0.710000   \n",
       "llama-2-7b-chat                             0.977778                 0.623810   \n",
       "llama-3-8b-instruct                         0.971429                 0.960000   \n",
       "qwen-14b-chat                               1.000000                 1.000000   \n",
       "qwen-72b                                    0.960000                 0.200000   \n",
       "qwen-72b-chat                               0.833333                 0.910000   \n",
       "qwen-7b-chat                                0.933333                 0.866667   \n",
       "qwen1.5-14b-chat                            1.000000                 1.000000   \n",
       "qwen1.5-72b                                 1.000000                 1.000000   \n",
       "qwen1.5-7b-chat                             0.942857                 0.922222   \n",
       "\n",
       "                     3-4_kqapro_sample.json  3-5_KoRC++ood_sample.json  \\\n",
       "baichuan2-13b-base                 0.333333                   0.628571   \n",
       "baichuan2-13b-chat                 0.800000                   0.850000   \n",
       "baichuan2-7b-chat                  0.514706                   0.893333   \n",
       "infini-megrez-7b                   0.727143                   0.604444   \n",
       "llama-2-13b-chat                   0.951282                   0.971429   \n",
       "llama-2-70b                        0.823529                   0.569231   \n",
       "llama-2-70b-chat                   0.811818                   0.830000   \n",
       "llama-2-7b-chat                    0.988889                   1.000000   \n",
       "llama-3-8b-instruct                0.733333                   0.866667   \n",
       "qwen-14b-chat                      0.960000                   0.960000   \n",
       "qwen-72b                           0.960000                   1.000000   \n",
       "qwen-72b-chat                      0.966667                   0.951429   \n",
       "qwen-7b-chat                       0.933333                   0.886667   \n",
       "qwen1.5-14b-chat                   1.000000                   0.876190   \n",
       "qwen1.5-72b                        1.000000                   0.887179   \n",
       "qwen1.5-7b-chat                    1.000000                   0.862857   \n",
       "\n",
       "                     3-6_r_KoRC++ood_sample.json  \\\n",
       "baichuan2-13b-base                      0.375000   \n",
       "baichuan2-13b-chat                      1.000000   \n",
       "baichuan2-7b-chat                       0.750000   \n",
       "infini-megrez-7b                        0.900000   \n",
       "llama-2-13b-chat                        0.693333   \n",
       "llama-2-70b                             0.280000   \n",
       "llama-2-70b-chat                        1.000000   \n",
       "llama-2-7b-chat                         0.840000   \n",
       "llama-3-8b-instruct                     0.850000   \n",
       "qwen-14b-chat                           0.664286   \n",
       "qwen-72b                                0.933333   \n",
       "qwen-72b-chat                           0.900000   \n",
       "qwen-7b-chat                            0.933333   \n",
       "qwen1.5-14b-chat                        1.000000   \n",
       "qwen1.5-72b                             0.933333   \n",
       "qwen1.5-7b-chat                         1.000000   \n",
       "\n",
       "                     4-1_without_triples_sample.json  \\\n",
       "baichuan2-13b-base                          1.000000   \n",
       "baichuan2-13b-chat                          0.955556   \n",
       "baichuan2-7b-chat                           0.990000   \n",
       "infini-megrez-7b                            0.897143   \n",
       "llama-2-13b-chat                            0.953846   \n",
       "llama-2-70b                                 0.402381   \n",
       "llama-2-70b-chat                            1.000000   \n",
       "llama-2-7b-chat                             1.000000   \n",
       "llama-3-8b-instruct                         1.000000   \n",
       "qwen-14b-chat                               0.933333   \n",
       "qwen-72b                                    1.000000   \n",
       "qwen-72b-chat                               1.000000   \n",
       "qwen-7b-chat                                1.000000   \n",
       "qwen1.5-14b-chat                            1.000000   \n",
       "qwen1.5-72b                                 1.000000   \n",
       "qwen1.5-7b-chat                             0.977778   \n",
       "\n",
       "                     4-1_with_triples_sample.json  \\\n",
       "baichuan2-13b-base                       1.000000   \n",
       "baichuan2-13b-chat                       1.000000   \n",
       "baichuan2-7b-chat                        0.971875   \n",
       "infini-megrez-7b                         0.737500   \n",
       "llama-2-13b-chat                         0.984615   \n",
       "llama-2-70b                              0.642857   \n",
       "llama-2-70b-chat                         0.988889   \n",
       "llama-2-7b-chat                          0.985294   \n",
       "llama-3-8b-instruct                      0.985714   \n",
       "qwen-14b-chat                            1.000000   \n",
       "qwen-72b                                 1.000000   \n",
       "qwen-72b-chat                            0.985714   \n",
       "qwen-7b-chat                             0.935882   \n",
       "qwen1.5-14b-chat                         0.989474   \n",
       "qwen1.5-72b                              1.000000   \n",
       "qwen1.5-7b-chat                          0.942711   \n",
       "\n",
       "                     4-2_r_without_triples_sample.json  \\\n",
       "baichuan2-13b-base                            0.483333   \n",
       "baichuan2-13b-chat                            0.977778   \n",
       "baichuan2-7b-chat                             0.985714   \n",
       "infini-megrez-7b                              0.820000   \n",
       "llama-2-13b-chat                              0.980000   \n",
       "llama-2-70b                                   0.885714   \n",
       "llama-2-70b-chat                              0.981818   \n",
       "llama-2-7b-chat                               0.980000   \n",
       "llama-3-8b-instruct                           0.945455   \n",
       "qwen-14b-chat                                 0.980000   \n",
       "qwen-72b                                      1.000000   \n",
       "qwen-72b-chat                                 1.000000   \n",
       "qwen-7b-chat                                  0.987500   \n",
       "qwen1.5-14b-chat                              1.000000   \n",
       "qwen1.5-72b                                   1.000000   \n",
       "qwen1.5-7b-chat                               0.981818   \n",
       "\n",
       "                     4-2_r_with_triples_sample.json  \n",
       "baichuan2-13b-base                         0.800000  \n",
       "baichuan2-13b-chat                         0.958333  \n",
       "baichuan2-7b-chat                          0.973684  \n",
       "infini-megrez-7b                           1.000000  \n",
       "llama-2-13b-chat                           1.000000  \n",
       "llama-2-70b                                0.500000  \n",
       "llama-2-70b-chat                           0.936667  \n",
       "llama-2-7b-chat                            0.984000  \n",
       "llama-3-8b-instruct                        0.958704  \n",
       "qwen-14b-chat                              0.951111  \n",
       "qwen-72b                                   0.978974  \n",
       "qwen-72b-chat                              0.981818  \n",
       "qwen-7b-chat                               0.750000  \n",
       "qwen1.5-14b-chat                           1.000000  \n",
       "qwen1.5-72b                                0.964103  \n",
       "qwen1.5-7b-chat                            0.970330  \n",
       "\n",
       "[16 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(data_view_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HXKVN28D5VC5G3EB7SHKDGNP",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-1_2_high_freq_ent_sample.json</th>\n",
       "      <th>1-2_1_low_freq_ent_sample.json</th>\n",
       "      <th>1-3_r_1_simple_sample_sample.json</th>\n",
       "      <th>2-1_COPEN++csj_sample.json</th>\n",
       "      <th>2-2_COPEN++cpj_sample.json</th>\n",
       "      <th>2-3_COPEN++cic_sample.json</th>\n",
       "      <th>2-4_FewNERD++inter_sample.json</th>\n",
       "      <th>2-4_FewNERD++intra_sample.json</th>\n",
       "      <th>2-4_FewNERD++supervised_sample.json</th>\n",
       "      <th>2-5_DocRED_sample.json</th>\n",
       "      <th>...</th>\n",
       "      <th>3-1_hotpotqa_sample.json</th>\n",
       "      <th>3-2_2wikimultihopqa_sample.json</th>\n",
       "      <th>3-3_musique_sample.json</th>\n",
       "      <th>3-4_kqapro_sample.json</th>\n",
       "      <th>3-5_KoRC++ood_sample.json</th>\n",
       "      <th>3-6_r_KoRC++ood_sample.json</th>\n",
       "      <th>4-1_without_triples_sample.json</th>\n",
       "      <th>4-1_with_triples_sample.json</th>\n",
       "      <th>4-2_r_without_triples_sample.json</th>\n",
       "      <th>4-2_r_with_triples_sample.json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baichuan2-13b-base</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baichuan2-13b-chat</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baichuan2-7b-chat</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.128205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infini-megrez-7b</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-13b-chat</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-70b</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.511765</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-70b-chat</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.113333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-7b-chat</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.402273</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-3-8b-instruct</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-14b-chat</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-72b</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-72b-chat</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-7b-chat</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.317778</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.257143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1.5-14b-chat</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.339683</td>\n",
       "      <td>0.108571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1.5-72b</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1.5-7b-chat</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.817308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.170476</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1-1_2_high_freq_ent_sample.json  \\\n",
       "baichuan2-13b-base                          0.600000   \n",
       "baichuan2-13b-chat                          0.666667   \n",
       "baichuan2-7b-chat                           0.720000   \n",
       "infini-megrez-7b                            0.533333   \n",
       "llama-2-13b-chat                            0.733333   \n",
       "llama-2-70b                                 0.533333   \n",
       "llama-2-70b-chat                            0.550000   \n",
       "llama-2-7b-chat                             0.666667   \n",
       "llama-3-8b-instruct                         0.533333   \n",
       "qwen-14b-chat                               0.466667   \n",
       "qwen-72b                                    0.533333   \n",
       "qwen-72b-chat                               0.733333   \n",
       "qwen-7b-chat                                0.733333   \n",
       "qwen1.5-14b-chat                            0.733333   \n",
       "qwen1.5-72b                                 0.466667   \n",
       "qwen1.5-7b-chat                             0.733333   \n",
       "\n",
       "                     1-2_1_low_freq_ent_sample.json  \\\n",
       "baichuan2-13b-base                              0.6   \n",
       "baichuan2-13b-chat                              0.6   \n",
       "baichuan2-7b-chat                               0.6   \n",
       "infini-megrez-7b                                0.8   \n",
       "llama-2-13b-chat                                0.6   \n",
       "llama-2-70b                                     0.8   \n",
       "llama-2-70b-chat                                0.4   \n",
       "llama-2-7b-chat                                 0.4   \n",
       "llama-3-8b-instruct                             0.8   \n",
       "qwen-14b-chat                                   1.0   \n",
       "qwen-72b                                        0.6   \n",
       "qwen-72b-chat                                   0.4   \n",
       "qwen-7b-chat                                    0.6   \n",
       "qwen1.5-14b-chat                                1.0   \n",
       "qwen1.5-72b                                     0.8   \n",
       "qwen1.5-7b-chat                                 0.6   \n",
       "\n",
       "                     1-3_r_1_simple_sample_sample.json  \\\n",
       "baichuan2-13b-base                            1.000000   \n",
       "baichuan2-13b-chat                            1.000000   \n",
       "baichuan2-7b-chat                             0.800000   \n",
       "infini-megrez-7b                              1.000000   \n",
       "llama-2-13b-chat                              0.633333   \n",
       "llama-2-70b                                   1.000000   \n",
       "llama-2-70b-chat                              1.000000   \n",
       "llama-2-7b-chat                               0.666667   \n",
       "llama-3-8b-instruct                           0.600000   \n",
       "qwen-14b-chat                                 0.800000   \n",
       "qwen-72b                                      0.600000   \n",
       "qwen-72b-chat                                 0.800000   \n",
       "qwen-7b-chat                                  0.600000   \n",
       "qwen1.5-14b-chat                              0.800000   \n",
       "qwen1.5-72b                                   1.000000   \n",
       "qwen1.5-7b-chat                               0.800000   \n",
       "\n",
       "                     2-1_COPEN++csj_sample.json  2-2_COPEN++cpj_sample.json  \\\n",
       "baichuan2-13b-base                          0.6                         0.6   \n",
       "baichuan2-13b-chat                          1.0                         0.2   \n",
       "baichuan2-7b-chat                           1.0                         0.4   \n",
       "infini-megrez-7b                            0.8                         0.6   \n",
       "llama-2-13b-chat                            0.6                         0.2   \n",
       "llama-2-70b                                 1.0                         0.7   \n",
       "llama-2-70b-chat                            1.0                         0.4   \n",
       "llama-2-7b-chat                             1.0                         0.2   \n",
       "llama-3-8b-instruct                         1.0                         0.6   \n",
       "qwen-14b-chat                               0.8                         0.8   \n",
       "qwen-72b                                    0.8                         0.4   \n",
       "qwen-72b-chat                               1.0                         0.6   \n",
       "qwen-7b-chat                                1.0                         0.4   \n",
       "qwen1.5-14b-chat                            1.0                         0.4   \n",
       "qwen1.5-72b                                 1.0                         0.4   \n",
       "qwen1.5-7b-chat                             0.8                         0.4   \n",
       "\n",
       "                     2-3_COPEN++cic_sample.json  \\\n",
       "baichuan2-13b-base                          0.6   \n",
       "baichuan2-13b-chat                          0.6   \n",
       "baichuan2-7b-chat                           0.4   \n",
       "infini-megrez-7b                            0.4   \n",
       "llama-2-13b-chat                            0.4   \n",
       "llama-2-70b                                 0.4   \n",
       "llama-2-70b-chat                            0.4   \n",
       "llama-2-7b-chat                             0.4   \n",
       "llama-3-8b-instruct                         0.4   \n",
       "qwen-14b-chat                               0.4   \n",
       "qwen-72b                                    0.2   \n",
       "qwen-72b-chat                               0.6   \n",
       "qwen-7b-chat                                0.6   \n",
       "qwen1.5-14b-chat                            0.6   \n",
       "qwen1.5-72b                                 0.2   \n",
       "qwen1.5-7b-chat                             0.4   \n",
       "\n",
       "                     2-4_FewNERD++inter_sample.json  \\\n",
       "baichuan2-13b-base                              0.8   \n",
       "baichuan2-13b-chat                              0.0   \n",
       "baichuan2-7b-chat                               0.4   \n",
       "infini-megrez-7b                                0.2   \n",
       "llama-2-13b-chat                                0.2   \n",
       "llama-2-70b                                     0.8   \n",
       "llama-2-70b-chat                                0.0   \n",
       "llama-2-7b-chat                                 0.6   \n",
       "llama-3-8b-instruct                             0.0   \n",
       "qwen-14b-chat                                   0.0   \n",
       "qwen-72b                                        0.4   \n",
       "qwen-72b-chat                                   0.0   \n",
       "qwen-7b-chat                                    0.2   \n",
       "qwen1.5-14b-chat                                0.0   \n",
       "qwen1.5-72b                                     0.0   \n",
       "qwen1.5-7b-chat                                 0.2   \n",
       "\n",
       "                     2-4_FewNERD++intra_sample.json  \\\n",
       "baichuan2-13b-base                              0.8   \n",
       "baichuan2-13b-chat                              0.0   \n",
       "baichuan2-7b-chat                               0.0   \n",
       "infini-megrez-7b                                0.8   \n",
       "llama-2-13b-chat                                0.4   \n",
       "llama-2-70b                                     0.6   \n",
       "llama-2-70b-chat                                0.4   \n",
       "llama-2-7b-chat                                 0.6   \n",
       "llama-3-8b-instruct                             0.4   \n",
       "qwen-14b-chat                                   0.0   \n",
       "qwen-72b                                        0.2   \n",
       "qwen-72b-chat                                   0.0   \n",
       "qwen-7b-chat                                    0.0   \n",
       "qwen1.5-14b-chat                                0.2   \n",
       "qwen1.5-72b                                     0.2   \n",
       "qwen1.5-7b-chat                                 0.2   \n",
       "\n",
       "                     2-4_FewNERD++supervised_sample.json  \\\n",
       "baichuan2-13b-base                              0.800000   \n",
       "baichuan2-13b-chat                              0.400000   \n",
       "baichuan2-7b-chat                               0.633333   \n",
       "infini-megrez-7b                                0.800000   \n",
       "llama-2-13b-chat                                0.800000   \n",
       "llama-2-70b                                     0.511765   \n",
       "llama-2-70b-chat                                0.600000   \n",
       "llama-2-7b-chat                                 0.466667   \n",
       "llama-3-8b-instruct                             0.600000   \n",
       "qwen-14b-chat                                   0.600000   \n",
       "qwen-72b                                        0.600000   \n",
       "qwen-72b-chat                                   0.466667   \n",
       "qwen-7b-chat                                    0.400000   \n",
       "qwen1.5-14b-chat                                0.266667   \n",
       "qwen1.5-72b                                     0.600000   \n",
       "qwen1.5-7b-chat                                 0.400000   \n",
       "\n",
       "                     2-5_DocRED_sample.json  ...  3-1_hotpotqa_sample.json  \\\n",
       "baichuan2-13b-base                 1.000000  ...                  0.600000   \n",
       "baichuan2-13b-chat                 0.975000  ...                  0.600000   \n",
       "baichuan2-7b-chat                  1.000000  ...                  0.750000   \n",
       "infini-megrez-7b                   1.000000  ...                  0.600000   \n",
       "llama-2-13b-chat                   1.000000  ...                  0.800000   \n",
       "llama-2-70b                        0.750000  ...                  0.426087   \n",
       "llama-2-70b-chat                   1.000000  ...                  1.000000   \n",
       "llama-2-7b-chat                    1.000000  ...                  0.600000   \n",
       "llama-3-8b-instruct                1.000000  ...                  0.600000   \n",
       "qwen-14b-chat                      0.500000  ...                  0.600000   \n",
       "qwen-72b                           1.000000  ...                  0.800000   \n",
       "qwen-72b-chat                      0.706250  ...                  0.800000   \n",
       "qwen-7b-chat                       1.000000  ...                  0.600000   \n",
       "qwen1.5-14b-chat                   0.916667  ...                  0.600000   \n",
       "qwen1.5-72b                        1.000000  ...                  0.800000   \n",
       "qwen1.5-7b-chat                    0.817308  ...                  0.400000   \n",
       "\n",
       "                     3-2_2wikimultihopqa_sample.json  3-3_musique_sample.json  \\\n",
       "baichuan2-13b-base                             1.000                      1.0   \n",
       "baichuan2-13b-chat                             0.600                      1.0   \n",
       "baichuan2-7b-chat                              0.875                      1.0   \n",
       "infini-megrez-7b                               0.700                      1.0   \n",
       "llama-2-13b-chat                               0.800                      1.0   \n",
       "llama-2-70b                                    0.800                      0.8   \n",
       "llama-2-70b-chat                               0.800                      1.0   \n",
       "llama-2-7b-chat                                0.600                      1.0   \n",
       "llama-3-8b-instruct                            0.600                      1.0   \n",
       "qwen-14b-chat                                  0.600                      0.6   \n",
       "qwen-72b                                       0.800                      1.0   \n",
       "qwen-72b-chat                                  0.800                      1.0   \n",
       "qwen-7b-chat                                   0.400                      1.0   \n",
       "qwen1.5-14b-chat                               1.000                      0.8   \n",
       "qwen1.5-72b                                    0.600                      1.0   \n",
       "qwen1.5-7b-chat                                0.600                      0.8   \n",
       "\n",
       "                     3-4_kqapro_sample.json  3-5_KoRC++ood_sample.json  \\\n",
       "baichuan2-13b-base                     1.00                        1.0   \n",
       "baichuan2-13b-chat                     0.85                        0.8   \n",
       "baichuan2-7b-chat                      1.00                        0.8   \n",
       "infini-megrez-7b                       1.00                        0.6   \n",
       "llama-2-13b-chat                       0.80                        0.6   \n",
       "llama-2-70b                            1.00                        0.8   \n",
       "llama-2-70b-chat                       1.00                        0.8   \n",
       "llama-2-7b-chat                        0.80                        0.6   \n",
       "llama-3-8b-instruct                    0.60                        0.6   \n",
       "qwen-14b-chat                          0.80                        0.6   \n",
       "qwen-72b                               0.60                        0.6   \n",
       "qwen-72b-chat                          0.60                        0.6   \n",
       "qwen-7b-chat                           1.00                        1.0   \n",
       "qwen1.5-14b-chat                       1.00                        0.8   \n",
       "qwen1.5-72b                            0.60                        0.6   \n",
       "qwen1.5-7b-chat                        0.60                        0.6   \n",
       "\n",
       "                     3-6_r_KoRC++ood_sample.json  \\\n",
       "baichuan2-13b-base                           0.6   \n",
       "baichuan2-13b-chat                           0.8   \n",
       "baichuan2-7b-chat                            0.6   \n",
       "infini-megrez-7b                             0.4   \n",
       "llama-2-13b-chat                             0.8   \n",
       "llama-2-70b                                  0.6   \n",
       "llama-2-70b-chat                             0.6   \n",
       "llama-2-7b-chat                              0.6   \n",
       "llama-3-8b-instruct                          0.6   \n",
       "qwen-14b-chat                                1.0   \n",
       "qwen-72b                                     1.0   \n",
       "qwen-72b-chat                                0.6   \n",
       "qwen-7b-chat                                 1.0   \n",
       "qwen1.5-14b-chat                             0.4   \n",
       "qwen1.5-72b                                  0.8   \n",
       "qwen1.5-7b-chat                              0.4   \n",
       "\n",
       "                     4-1_without_triples_sample.json  \\\n",
       "baichuan2-13b-base                          0.200000   \n",
       "baichuan2-13b-chat                          0.114286   \n",
       "baichuan2-7b-chat                           0.085714   \n",
       "infini-megrez-7b                            0.228571   \n",
       "llama-2-13b-chat                            0.533333   \n",
       "llama-2-70b                                 0.400000   \n",
       "llama-2-70b-chat                            0.200000   \n",
       "llama-2-7b-chat                             0.240000   \n",
       "llama-3-8b-instruct                         0.000000   \n",
       "qwen-14b-chat                               0.100000   \n",
       "qwen-72b                                    0.240000   \n",
       "qwen-72b-chat                               0.200000   \n",
       "qwen-7b-chat                                0.311111   \n",
       "qwen1.5-14b-chat                            0.216667   \n",
       "qwen1.5-72b                                 0.466667   \n",
       "qwen1.5-7b-chat                             0.109091   \n",
       "\n",
       "                     4-1_with_triples_sample.json  \\\n",
       "baichuan2-13b-base                       0.000000   \n",
       "baichuan2-13b-chat                       0.000000   \n",
       "baichuan2-7b-chat                        0.150000   \n",
       "infini-megrez-7b                         0.022222   \n",
       "llama-2-13b-chat                         0.080000   \n",
       "llama-2-70b                              0.225000   \n",
       "llama-2-70b-chat                         0.040000   \n",
       "llama-2-7b-chat                          0.057143   \n",
       "llama-3-8b-instruct                      0.000000   \n",
       "qwen-14b-chat                            0.000000   \n",
       "qwen-72b                                 0.200000   \n",
       "qwen-72b-chat                            0.000000   \n",
       "qwen-7b-chat                             0.317778   \n",
       "qwen1.5-14b-chat                         0.116667   \n",
       "qwen1.5-72b                              0.166667   \n",
       "qwen1.5-7b-chat                          0.170476   \n",
       "\n",
       "                     4-2_r_without_triples_sample.json  \\\n",
       "baichuan2-13b-base                            0.500000   \n",
       "baichuan2-13b-chat                            0.428571   \n",
       "baichuan2-7b-chat                             0.080000   \n",
       "infini-megrez-7b                              0.325000   \n",
       "llama-2-13b-chat                              0.541667   \n",
       "llama-2-70b                                   0.800000   \n",
       "llama-2-70b-chat                              0.066667   \n",
       "llama-2-7b-chat                               0.402273   \n",
       "llama-3-8b-instruct                           0.200000   \n",
       "qwen-14b-chat                                 0.485714   \n",
       "qwen-72b                                      0.314286   \n",
       "qwen-72b-chat                                 0.328571   \n",
       "qwen-7b-chat                                  0.226667   \n",
       "qwen1.5-14b-chat                              0.339683   \n",
       "qwen1.5-72b                                   0.440000   \n",
       "qwen1.5-7b-chat                               0.520000   \n",
       "\n",
       "                     4-2_r_with_triples_sample.json  \n",
       "baichuan2-13b-base                         0.600000  \n",
       "baichuan2-13b-chat                         0.142857  \n",
       "baichuan2-7b-chat                          0.128205  \n",
       "infini-megrez-7b                           0.600000  \n",
       "llama-2-13b-chat                           0.433333  \n",
       "llama-2-70b                                0.000000  \n",
       "llama-2-70b-chat                           0.113333  \n",
       "llama-2-7b-chat                            0.400000  \n",
       "llama-3-8b-instruct                        0.060000  \n",
       "qwen-14b-chat                              0.300000  \n",
       "qwen-72b                                   0.250000  \n",
       "qwen-72b-chat                              0.233333  \n",
       "qwen-7b-chat                               0.257143  \n",
       "qwen1.5-14b-chat                           0.108571  \n",
       "qwen1.5-72b                                0.022222  \n",
       "qwen1.5-7b-chat                            0.025000  \n",
       "\n",
       "[16 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(data_view_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATH DATA PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX4025VX12NBKZ1JA9217W99",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = {'fileName':\"math401.json\",'data':[]}\n",
    "with open('E:/Repository/math401-llm-main/math401.json') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        text = data['query']\n",
    "        if '**' in text:\n",
    "            text = text.replace('**','^')\n",
    "        item = {'input':text,'expected_output':data['response']}\n",
    "        question['data'].append(item.copy())\n",
    "with open('./data/math401/math401.json','w') as file:\n",
    "    json.dump(question,file,indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Math Evaluation Samples Drawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01HX40JAXPSCH3655C8NS17BQ8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/math401/math401.json') as f:\n",
    "    data = json.load(f)\n",
    "data_new  = {\"fileName\":\"math50.json\",'data':[]}\n",
    "data_new['data'].append(data['data'][0])\n",
    "data_new['data'].append(data['data'][1])\n",
    "for i,item in enumerate(data['data'][2:]):\n",
    "    if i % 8 == 0:\n",
    "        data_new['data'].append(item)\n",
    "with open('./data/math401/math50.json','w') as f:\n",
    "    json.dump(data_new,f,indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mannual processing\n",
    "1. delete:\n",
    "    delete the following item from math50.json\n",
    "    <table>\n",
    "    <tr><td>\n",
    "        {\n",
    "            \"input\": \"2+4=\",\n",
    "            \"expected_output\": \"6\"\n",
    "        }\n",
    "    </td></tr>\n",
    "    <tr><td>\n",
    "        {\n",
    "            \"input\": \"0*2=\",\n",
    "            \"expected_output\": \"0.0000\"\n",
    "        }\n",
    "    </td></tr>\n",
    "    <tr><td>\n",
    "        {\n",
    "            \"input\": \"6^2=\",\n",
    "            \"expected_output\": \"36\"\n",
    "        }\n",
    "    </td></tr>\n",
    "    </table>\n",
    "2. replace: \n",
    "    do the following replacing actions in math50.json\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td>old</td>\n",
    "            <td>new</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                {\n",
    "                    \"input\": \"log 10(63)=\",\n",
    "                    \"expected_output\": \"1.7993\"\n",
    "                }\n",
    "            </td>\n",
    "            <td>\n",
    "                {\n",
    "                    \"input\": \"log 2(71)=\",\n",
    "                    \"expected_output\": \"6.1497\"\n",
    "                }\n",
    "            </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "3. insert: \n",
    "    do the following inserting actions in math50.json\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td>insertItem</td>\n",
    "            <td>after</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                {\n",
    "                    \"input\": \"tan(-0.17\\u03c0)=\",\n",
    "                    \"expected_output\": \"-0.5774\"\n",
    "                }\n",
    "            </td>\n",
    "            <td>\n",
    "                {\n",
    "                    \"input\": \"cos(-300\\u00b0)=\",\n",
    "                    \"expected_output\": \"0.5000\"\n",
    "                }\n",
    "            </td>\n",
    "        </tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH6ZHTNEPNWJX8WCSQPB",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/math401/math50.json') as f:\n",
    "    data = json.load(f)\n",
    "data_new  = {'fileName': data['fileName'],'data':[]}\n",
    "for item in data['data']:\n",
    "    data_format = {'id':item['id'],'input':item['input'],'expected_output':item['expected_output']}\n",
    "    data_new['data'].append(data_format.copy())\n",
    "with open('./data/math401/math50.json','w') as f:\n",
    "    json.dump(data_new,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH6ZKZG59EH5VYKYTD96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/math401/math50.json','r') as f:\n",
    "    data_eval  = json.load(f)\n",
    "data_eval['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Model Reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH6ZSE8SZ6GN979AD82S",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LLM_Reply_MATH(filepath,savePath,errorPath):\n",
    "    with open(filepath) as f:\n",
    "        data = json.load(f)\n",
    "    questionList = data['data']\n",
    "    instructions = 'Only return the correct answer of the question.\\n'\n",
    "    for model in answerModelList:\n",
    "        error = {'fileName':model.title()+'.json','model':model,'data':[]}\n",
    "        save = {'fileName':model.title()+'.json','model':model,'data':[]}\n",
    "        for index,item in enumerate(questionList):\n",
    "            data_format_ins = {\n",
    "                'id':0,\n",
    "                'AnswerModel':'',\n",
    "                'input':'',\n",
    "                'actual_output':'',\n",
    "                'expected_output':None,\n",
    "                'is_correct':-1,\n",
    "                'time':-1\n",
    "            }\n",
    "            if 'id' in item:\n",
    "                data_format_ins['id'] = item['id']\n",
    "            else:\n",
    "                data_format_ins['id'] = model+'-%04d'% index\n",
    "            prompt = instructions+item['input']\n",
    "            data_format_ins['input'] = prompt\n",
    "            print(prompt)\n",
    "            data_format_ins['expected_output'] = item['expected_output']\n",
    "            data_format_ins['AnswerModel'] = model\n",
    "            print(model)\n",
    "            start = time.perf_counter_ns()\n",
    "            actual_output =  LLMCompletions(prompt,modelName=model,top_p=0)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = end-start\n",
    "            idx = 0\n",
    "            while actual_output == \"Cannot connect to the model \"+model and idx<2:\n",
    "                start = time.perf_counter_ns()\n",
    "                actual_output =  LLMCompletions(prompt,modelName=model,top_p=0)\n",
    "                end = time.perf_counter_ns()\n",
    "                delta = end-start\n",
    "                idx += 1\n",
    "            if actual_output == \"Cannot connect to the model \"+model:\n",
    "                error['data'].append({'id':data_format_ins['id'],\"AnswerModel\":model,\"input\":prompt,\"expected_output\":data_format_ins['expected_output']})\n",
    "                continue\n",
    "            print(idx,delta//1000_000,actual_output,sep='\\t')\n",
    "            data_format_ins['actual_output'] = actual_output\n",
    "            data_format_ins['time'] = delta\n",
    "            save['data'].append(data_format_ins.copy())\n",
    "            print('*'*70)\n",
    "        errorItemFinal = []\n",
    "        while error['data']:\n",
    "            item = error['data'].pop()\n",
    "            data_format_ins['id'] = item['id']\n",
    "            model = item['AnswerModel']\n",
    "            data_format_ins['AnswerModel'] = model\n",
    "            prompt = item['input']\n",
    "            data_format_ins['input'] = prompt\n",
    "            data_format_ins['expected_output'] = item['expected_output']\n",
    "            start = time.perf_counter_ns()\n",
    "            actual_output =  LLMCompletions(prompt,modelName=model,top_p=0)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = end-start\n",
    "            idx = 0\n",
    "            while actual_output == \"Cannot connect to the model \"+model and idx<2:\n",
    "                print('\\t'+str(idx)+'\\ttest')\n",
    "                start = time.perf_counter_ns()\n",
    "                actual_output =  LLMCompletions(prompt,modelName=model,top_p=0)\n",
    "                end = time.perf_counter_ns()\n",
    "                delta = end-start\n",
    "                idx += 1\n",
    "            if actual_output == \"Cannot connect to the model \"+model:\n",
    "                errorItemFinal.append(item)\n",
    "                print(\"[error]:\\t\"+str(errorItemFinal[-1]))\n",
    "                continue\n",
    "            print(idx,delta,actual_output,sep='\\t')\n",
    "            data_format_ins['actual_output'] = actual_output\n",
    "            data_format_ins['time'] = delta\n",
    "            save['data'].append(data_format_ins.copy())\n",
    "        with open(os.path.join(savePath,model+'.json'),'w',encoding='utf-8') as out:\n",
    "            json.dump(save,out,indent=4)\n",
    "        if errorItemFinal:\n",
    "            for i in errorItemFinal:\n",
    "                error['data'].append(i)\n",
    "            with open(os.path.join(errorPath,model+'.json'),'w',encoding='utf-8') as out:\n",
    "                json.dump(error,out,indent=4)\n",
    "        print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH6Z2KY0MJ1QW9XHRHZE",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_LLM_Reply_MATH('./data/math401/math50.json','./data/math401/save','./data/math401/error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Reply Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH6ZVPSCC97BCK0RJAB8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_result(filePath:Union[str,Path])->None:\n",
    "    \"\"\"\n",
    "    _summary_\n",
    "        the function is used to sort the results saved in the JSON `filepath` by `id` field\n",
    "        \n",
    "    Args:\n",
    "        `filePath` (Union[str,Path]): the JSON file path\n",
    "\n",
    "    Returns:\n",
    "        None: the result will override the original `filePath` \n",
    "    \"\"\"\n",
    "    with open(filePath,'r') as f:\n",
    "        data = json.load(f)\n",
    "    data['data'].sort(key = lambda x:x['id'])\n",
    "    with open(filePath,'w') as f:\n",
    "        json.dump(data,f,indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH6Z5QSBKK5S6XPWDAW5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addField(file:Union[str,Path],field:str,default:Any)->None:\n",
    "    \"\"\"\n",
    "    _summary_\n",
    "        the function is used to add a field into the `.json` `file`\n",
    "\n",
    "    Args:\n",
    "        `file` (Union[str,Path]): the filename ,the file should be JSON file\n",
    "        `field` (str): the field name\n",
    "        `default` (Any): the default value of the added field,the value will add or subtract a Random from -500_000_000 to 500_000_000 if the field is `time`\n",
    "        \n",
    "    Returns:\n",
    "        None: the result will override the original `file` \n",
    "    \"\"\"\n",
    "    with open(file,'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data['data']:\n",
    "        if field not in item:\n",
    "            item[field] = default\n",
    "            if field == 'time':\n",
    "                item[field] += random.randint(-500_000_000,500_000_000)\n",
    "    with open(file,'w') as f:\n",
    "        json.dump(data,f,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH6ZJC7571YKEH2ZZ02A",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir,subdir ,files in os.walk('./data/math401/save'):\n",
    "    for file in files:\n",
    "        addField(os.path.join(dir,file),'extract_answer',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH6ZV2C8F6WEYD75STG4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumberAnswer(text:str)->Union[float,None]:\n",
    "    \"\"\"_summary_\n",
    "        the function is used to extract the number from the text\n",
    "\n",
    "    Args:\n",
    "        `text` (str): the text contains the number\n",
    "        \n",
    "    Returns:\n",
    "        Union[float,None]: the number in the `text`, or None if the `text` does not contain the number\n",
    "    \"\"\"\n",
    "    text = text.split('=')\n",
    "    if text:\n",
    "        text = text[-1]\n",
    "        regex = re.compile('([+-]?\\d+[,0-9]*[.]?[0-9]*)')\n",
    "        ret = regex.findall(text)\n",
    "        if ret:\n",
    "            return eval(ret[-1].replace(',',''))\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH6ZV7NK8J3AGQK40QSS",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAnswer(file:Union[str,Path]):\n",
    "    \"\"\"\n",
    "    _summary_:\n",
    "        the function is used to process the answer that the LLM returned , namely extracting the number from the `actual_output` and save as `extract_answer`, and transform `expected_output` from str to number[int,float] \n",
    "\n",
    "    Args:\n",
    "        `file` (Union[str,Path]): the filename of the file saving the answer created by the LLM\n",
    "        \n",
    "    Returns:\n",
    "        None : the result will be written into the original `file`\n",
    "    \"\"\"\n",
    "    with open(file,'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data['data']:\n",
    "        if item['is_correct'] == -1:\n",
    "            item['extract_answer'] = getNumberAnswer(item['actual_output'])\n",
    "            item['expected_output'] = eval(item['expected_output'])\n",
    "            if item['extract_answer'] is None :\n",
    "                item['is_correct'] = 0\n",
    "            else:\n",
    "                item['is_correct'] =1 if abs(item['expected_output']-item['extract_answer']) < 1e-3 else 0\n",
    "    with open(file,'w') as f:\n",
    "        json.dump(data,f,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH6ZMNKJE6P13CECEMMZ",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir,subdir ,files in os.walk('./data/math401/save'):\n",
    "    for file in files:\n",
    "        processAnswer(os.path.join(dir,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH6ZKDBFZGB1B4NM237B",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir,subdir ,files in os.walk('./data/math401/save'):\n",
    "    for file in files:\n",
    "        with open(os.path.join(dir,file),'r') as f:\n",
    "            data = json.load(f)\n",
    "        for item in data['data']:\n",
    "\n",
    "            if item['is_correct']:\n",
    "                item['is_correct'] = 1\n",
    "            else:\n",
    "                item['is_correct'] = 0\n",
    "        with open(os.path.join(dir,file),'w') as f:\n",
    "            json.dump(data,f,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH6ZRF5AX3C8TJW3M7AB",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_accuracy(file:Union[str,Path],return_tuple:bool = False)->Union[float,tuple[str,float]]:\n",
    "    \"\"\"_summary_\n",
    "        the function calculates the accuracy of the model answers on the `math50` dataset saved in `file`\n",
    "\n",
    "    Args:\n",
    "        `file` (Union[str,Path]): the path to the JSON `file` containing a model answer results\n",
    "        `return_tuple` (bool, optional): if the value is True,the function will return a tuple (modelName,accuracy),else only return accuracy `[0,1]`. \n",
    "                    Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Union[float,tuple[str,float]]: if return_tuple is True,return a tuple containing both modelName and accuracy in format `(modelName:str,accuracy:float)`,else only return the accuracy in [0,1]\n",
    "    \"\"\"\n",
    "    with open(file,'r') as f:\n",
    "        data = json.load(f)\n",
    "    correct = 0\n",
    "    for item in data['data']:\n",
    "        correct += item['is_correct']\n",
    "    accuracy =  correct/len(data['data'])\n",
    "    if return_tuple:\n",
    "        return (data['model'],accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def calculate_nan_ratio(file:Union[str,Path],return_tuple:bool = False)->Union[float,tuple[str,float]]:\n",
    "    \"\"\"_summary_\n",
    "        the function calculates the no number ratio of the LLM answers on the `math50` dataset saved in `file`\n",
    "\n",
    "    Args:\n",
    "        `file` (Union[str,Path]): the path to the JSON `file` containing a model answer results\n",
    "        `return_tuple` (bool, optional): if the value is True,the function will return a tuple (modelName,nan_ratio),else only return nan_ratio `[0,1]`. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Union[float,tuple[str,float]]: if return_tuple is True,return a tuple containing both modelName and nan_ratio in format `(modelName:str,nan_ratio:float)`,else only return the nan_ratio in [0,1]\n",
    "    \"\"\"\n",
    "    with open(file,'r') as f:\n",
    "        data = json.load(f)\n",
    "    nan = 0\n",
    "    for item in data['data']:\n",
    "        if item['extract_answer'] is None:\n",
    "            nan += 1\n",
    "    nan_ratio = nan/len(data['data'])\n",
    "    if return_tuple:\n",
    "        return (data['model'],nan_ratio)\n",
    "    return nan_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH6Z5XMDR08ZFVQGKCDD",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RE(y_true:Union[int,float],y_pred:Union[int,float])->float:\n",
    "    return min(10,abs(y_true-y_pred)/max(abs(y_true),1))\n",
    "def calculate_RE(file:Union[str,Path],return_tuple:bool = False)->Union[List[float],tuple[str,List[float]]]:\n",
    "    \n",
    "    with open(file,'r') as f:\n",
    "        data = json.load(f)\n",
    "    RE_list = []\n",
    "    for item in data['data']:\n",
    "        ret = 0\n",
    "        y_true = item['expected_output']\n",
    "        y_pred = item['extract_answer']\n",
    "        if y_pred is None:\n",
    "            ret = 10\n",
    "        else:\n",
    "            ret = RE(y_true,y_pred)\n",
    "        RE_list.append(ret)\n",
    "    if return_tuple:\n",
    "        return (data['model'],RE_list)\n",
    "    return RE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH70QVBQPEMYZ76CQVRG",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = {'eval':'math','eval_dataset':'math50.json','data':[]}\n",
    "for dir,subdir ,files in os.walk('./data/math401/save'):\n",
    "    for file in files:\n",
    "        tmp = calculate_accuracy(os.path.join(dir,file),return_tuple=True)\n",
    "        nan_ratio = calculate_nan_ratio(os.path.join(dir,file))\n",
    "        RE_List = calculate_RE(os.path.join(dir,file))\n",
    "        data_list['data'].append({'model':tmp[0],'Accuracy':tmp[1],'Nan_Ratio':nan_ratio,'RE_List':RE_List[:]})\n",
    "with open('./data/math401/math50_eval_result.json','w') as f:\n",
    "    json.dump(data_list,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3ZCH70JN8GP6CXB3YT5PF6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for dir,subdir ,files in os.walk('./data/math401/save'):\n",
    "    for file in files:\n",
    "        tmp = calculate_accuracy(os.path.join(dir,file),return_tuple=True)\n",
    "        nan_ratio = calculate_nan_ratio(os.path.join(dir,file))\n",
    "        RE_List = calculate_RE(os.path.join(dir,file))\n",
    "        data[tmp[0]] = {'Accuracy':tmp[1],'Nan_Ratio':nan_ratio,'RE_List':RE_List[:]}\n",
    "df = pd.DataFrame(data).T.sort_index()\n",
    "df.to_json('./data/math401/math50_eval_result_df.json',indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Evaluation Task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3WB3EXZV4FD0TR4HP1ZQEX",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_timeout import *\n",
    "from evalplus.data import write_jsonl,get_human_eval_plus\n",
    "from evalplus.sanitize import main as sanitize_main\n",
    "from evalplus.syncheck import  main as syntax_check_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3WB3EX0HWYKP35M5Q9V5YT",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMCompletion:\n",
    "    def __init__(self,index=0):\n",
    "        self.index = index\n",
    "    def GEN_SOLUTION(self,prompt,modelName:str = \"infini-megrez-7b\",INFINI_API_List = [\"sk-c7cssl4bkglsrwf2\", \"sk-c7erk6qaqhkz5t72\",\"sk-c7etq7veyeie4dn2\"],returnContent:bool = True,**kwargs):\n",
    "        url = \"https://cloud.infini-ai.com/maas/\"+modelName+\"/nvidia/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": modelName,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"stream\": False,\n",
    "            \"temperature\": kwargs[\"temperature\"] if \"temperature\" in kwargs else 0.7,\n",
    "            \"top_p\": kwargs[\"top_p\"] if 'top_p' in kwargs else 1,\n",
    "            \"top_k\": kwargs['top_k'] if 'top_k' in kwargs else -1,\n",
    "            \"n\": kwargs['n'] if 'n' in kwargs else 1,\n",
    "            \"max_tokens\": kwargs['max_tokens'] if 'max_tokens' in kwargs else None,\n",
    "            \"stop\": kwargs['stop'] if 'stop' in kwargs else None,\n",
    "            \"presence_penalty\": kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else 0,\n",
    "            \"frequency_penalty\": kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else 0\n",
    "        }\n",
    "        idx = 0\n",
    "        while idx < len(INFINI_API_List):\n",
    "            headers = {\n",
    "                    'Content-Type': \"application/json\",\n",
    "                    'Accept': \"*/*\",\n",
    "                    'Authorization': \"Bearer \"+INFINI_API_List[self.index%len(INFINI_API_List)],\n",
    "            } \n",
    "            # print(payload)\n",
    "            # print(headers)\n",
    "            response = requests.post(url, json=payload, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                response.encoding = 'utf-8'\n",
    "                data = response.json()\n",
    "                content = data['choices'][0]['message']['content']\n",
    "                print(content)\n",
    "                # if isinstance(content,str):\n",
    "                #     content = content.replace(',\\n}','\\n}')\n",
    "                #     content = content.replace(']\\n}',']}')\n",
    "                #     content = content.replace('\\\\','\\\\\\\\')\n",
    "                if returnContent:\n",
    "                    return content\n",
    "                try:\n",
    "                    content = json.loads(content)\n",
    "                except:\n",
    "                    pass\n",
    "                data['choices'][0]['message']['content'] = content\n",
    "                if isinstance(content,str):\n",
    "                    return content\n",
    "                \n",
    "                return json.dumps(data['choices'][0]['message']['content'])\n",
    "            else:\n",
    "                print(response.status_code)\n",
    "                try:\n",
    "                    print(response.json())\n",
    "                except:\n",
    "                    pass\n",
    "            self.index = (self.index + 1) % len(INFINI_API_List)\n",
    "            idx += 1\n",
    "        print((\"=\"*35)+'Error:\\t'+prompt+('='*35))\n",
    "        return \"Cannot connect to the model \"+modelName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3WB3EXCBF17PJM4VKFQH70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_human_eval_plus()\n",
    "dataset_copy  = dataset.copy()\n",
    "for i,key in enumerate(dataset.keys()):\n",
    "    if i % 6 != 0:\n",
    "        del dataset_copy[key]\n",
    "with open('./data/codeEval/data.json','w') as f:\n",
    "    json.dump(dataset_copy,f,ensure_ascii=False,indent=4)\n",
    "with open('./data/codeEval/data.jsonl','w') as fw:\n",
    "    for item in dataset_copy.keys():\n",
    "        fw.write(json.dumps(dataset_copy[item])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3WB3EXBF2YEW1QDA8TQT9Q",
   "metadata": {},
   "outputs": [],
   "source": [
    "answerModelList = [    \n",
    "    'baichuan2-7b-chat',\n",
    "    'baichuan2-13b-chat',\n",
    "    'baichuan2-13b-base',\n",
    "    'qwen-7b-chat',\n",
    "    'qwen-14b-chat',\n",
    "    'qwen-72b-chat',\n",
    "    'qwen-72b',\n",
    "    'qwen1.5-7b-chat',\n",
    "    'qwen1.5-14b-chat',\n",
    "    'qwen1.5-72b',\n",
    "    #'llama-2-70b-chat',#deprecated,can not connect to the model\n",
    "    'llama-2-70b',\n",
    "    'llama-2-7b-chat',\n",
    "    'llama-2-13b-chat',\n",
    "    'infini-megrez-7b',  \n",
    "]\n",
    "productor = LLMCompletion()\n",
    "with open('./data/codeEval/data.json','r') as f:\n",
    "    dataset = json.load(f)\n",
    "for modelName in answerModelList:\n",
    "    samples = [dict(task_id=task_id, solution=productor.GEN_SOLUTION(problem[\"prompt\"],modelName=modelName)) for task_id, problem in dataset.items()]\n",
    "    write_jsonl('./data/codeEval/code_raw/'+modelName+\".jsonl\", samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Sanitize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01HX3WB3EX8V815J6TF6SBJCMS",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baichuan2-13b-base.jsonl', 'baichuan2-13b-chat.jsonl', 'baichuan2-7b-chat.jsonl', 'infini-megrez-7b.jsonl', 'llama-2-13b-chat.jsonl', 'llama-2-70b-chat.jsonl', 'llama-2-70b.jsonl', 'llama-2-7b-chat.jsonl', 'qwen-14b-chat.jsonl', 'qwen-72b-chat.jsonl', 'qwen-72b.jsonl', 'qwen-7b-chat.jsonl', 'qwen1.5-14b-chat.jsonl', 'qwen1.5-72b.jsonl', 'qwen1.5-7b-chat.jsonl']\n"
     ]
    }
   ],
   "source": [
    "for dir,subdir,files in os.walk('./data/codeEval/code_raw'):\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3WB3EX31E55E1H0A9DTSFA",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_code = ['baichuan2-13b-base.jsonl', 'baichuan2-13b-chat.jsonl', 'baichuan2-7b-chat.jsonl', 'infini-megrez-7b.jsonl',  'llama-2-13b-chat.jsonl', 'llama-2-70b-chat.jsonl', 'llama-2-70b.jsonl', 'llama-2-7b-chat.jsonl', 'qwen-14b-chat.jsonl', 'qwen-72b-chat.jsonl','qwen-72b.jsonl', 'qwen-7b-chat.jsonl', 'qwen1.5-14b-chat.jsonl', 'qwen1.5-72b.jsonl', 'qwen1.5-7b-chat.jsonl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3XSGT462SWQZGZR49206E5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUMANEVAL_OVERRIDE_PATH\"] = './data/codeEval/data.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3X89MPVMDBSTMHTCMJKM3R",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir,subdir,files in os.walk('./data/codeEval/code_raw'):\n",
    "    for file in files:\n",
    "        sanitize_main(dir+'/'+file,\"humaneval\")\n",
    "        shutil.move(os.path.join(dir,file.replace(\".jsonl\",\"-sanitized.jsonl\")),os.path.join(Path(dir).parent/'code_sanitize',file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3XKZPQ0BXHA4RST6D6VQTM",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir,subdir,files in os.walk('./data/codeEval/code_sanitize'):\n",
    "    for file in files:\n",
    "        syntax_check_main(dir+'/'+file,'humaneval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3YA1NQY78HKVBAXMF4JRPS",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/codeEval/data.json','r') as f:\n",
    "    dataset = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01HXKS9VFQ3KN29T3STA99Y0A9",
   "metadata": {},
   "source": [
    "#### Manual Sanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3YAKGH1MKKQH58T8ZBVGVG",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"HumanEval/156\"]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3WB3EXG98TE4PE4DHFS658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = 'qwen1.5-7b-chat.jsonl'\n",
    "# data = []\n",
    "# with open('./data/codeEval/code_raw/'+file_name, 'r') as f:\n",
    "#     for line in f.readlines():\n",
    "#         data.append(json.loads(line))\n",
    "# data_sanitize = []\n",
    "# with open('./data/codeEval/code_sanitize/'+file_name,'r') as f:\n",
    "#     for line in f.readlines():\n",
    "#         data_sanitize.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3WB3EY82V5WTC0BYRV5G47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 27\n",
    "# print(data[i]['task_id'])\n",
    "# print(data[i]['solution'])\n",
    "# print('='*70)\n",
    "# print(data_sanitize[i]['task_id'])\n",
    "# print(data_sanitize[i]['solution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3YCE7W33ZAYD872NG6JDW0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(data_sanitize)):\n",
    "#     print(data_sanitize[i]['solution'])\n",
    "#     print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Execute And Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3YM3K9KGDT3X29176Z0T05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(code:str,inputs:List,entry_point:str,record_time=True,timeout:float = 10)->List:\n",
    "    env = {}\n",
    "    n = len(inputs)\n",
    "    local = {}\n",
    "    try:\n",
    "        exec(code,None,local)\n",
    "        if len(local) != 1:\n",
    "            exec(code,env)\n",
    "        else:\n",
    "            env = local\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        if record_time:\n",
    "            return ([\"SyntaxError\"]*n,[(1<<31)-1]*n)\n",
    "        return [\"SyntaxError\"]*n\n",
    "    if entry_point in env:\n",
    "        fn = env[entry_point]\n",
    "    else:\n",
    "        if record_time:\n",
    "            return ([\"NotImplemented\"]*n,[(1<<31)-1]*n)\n",
    "        return [\"NotImplemented\"]*n\n",
    "    @func_set_timeout(timeout)\n",
    "    def get(inp,record_time:bool=True):\n",
    "        try:\n",
    "            start = time.perf_counter_ns()\n",
    "            ret = fn(*inp) #if fn.__code__.co_argcount > 1 else fn(inp)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = (end-start)//1000_000\n",
    "        except Exception as e:\n",
    "            print(e,fn)\n",
    "            ret = \"SyntaxError\"\n",
    "            delta = (1<<31)-1\n",
    "        if isinstance(ret,NotImplementedError) or str(ret) == str(NotImplemented):\n",
    "            ret = \"NotImplemented\"\n",
    "        if record_time:\n",
    "            return (ret,delta)\n",
    "        return ret\n",
    "        \n",
    "    ret = []\n",
    "    rtime = []\n",
    "    for inp in inputs:\n",
    "        try:\n",
    "            res,delta = get(inp)\n",
    "            ret.append(res)\n",
    "            rtime.append(delta)\n",
    "        except FunctionTimedOut as e:\n",
    "            print(e)\n",
    "            ret.append(\"TimeLimitExceeding\")\n",
    "            rtime.append((1<<31)-1)\n",
    "    # try:\n",
    "    #     exec(code,None,local)\n",
    "    #     for key in local.keys:\n",
    "    #         del env[key]\n",
    "    # except:\n",
    "    #     print(\"del error\")\n",
    "    del env\n",
    "    if record_time:\n",
    "        return ret,rtime\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3YMCRK85JVTQ96Q45HAW85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trust_execute(code:str,inputs:List,entry_point:str,record_time=True)->List:\n",
    "    env = {}\n",
    "    exec(code,None, env)\n",
    "    fn = env[entry_point]\n",
    "    ret = []\n",
    "    rtime = []\n",
    "    for i,inp in enumerate(inputs):\n",
    "        if record_time:\n",
    "            start = time.perf_counter_ns()\n",
    "            tmp = fn(*inp) #if fn.__code__.co_argcount > 1 else fn(inp)\n",
    "            end = time.perf_counter_ns()\n",
    "            ret.append(tmp)\n",
    "            rtime.append((end-start)//1000_000)\n",
    "        else:\n",
    "            tmp = fn(*inp) #if fn.__code__.co_argcount > 1 else fn(inp)\n",
    "            ret.append(tmp)\n",
    "    if record_time:\n",
    "        return ret,rtime\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3YMNFT8NRMJBK1AAFMXE2W",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardExecute(dataset:Union[str,Path],inplace = False,is_force_override = False):\n",
    "    def trust_execute(code:str,inputs:List,entry_point:str,record_time=True)->List:\n",
    "        env = {}\n",
    "        exec(code,None, env)\n",
    "        fn = env[entry_point]\n",
    "        ret = []\n",
    "        rtime = []\n",
    "        for i,inp in enumerate(inputs):\n",
    "            if record_time:\n",
    "                start = time.perf_counter_ns()\n",
    "                ret.append(fn(*inp))\n",
    "                end = time.perf_counter_ns()\n",
    "                rtime.append((end-start)//1000_000)\n",
    "            else:\n",
    "                ret.append(fn(*inp))\n",
    "        if record_time:\n",
    "            return ret,rtime\n",
    "        return ret\n",
    "    if isinstance(dataset, str):\n",
    "        dataset = Path(dataset)\n",
    "    if dataset.suffix == \".json\":\n",
    "        with open(dataset,'r') as f:\n",
    "            data_origin = json.load(f)\n",
    "    elif dataset.suffix == '.jsonl':\n",
    "        with open(dataset,'r') as f:\n",
    "            data_origin = {}\n",
    "            for line in f:\n",
    "                item = json.loads(line)\n",
    "                data_origin[item['task_id']] = item\n",
    "    else:\n",
    "        raise Exception(f\"{dataset.suffix} is not supported\")\n",
    "    \"\"\"            \n",
    "        {\"{{task_id}}\":{\n",
    "            \"task_id\":str,\n",
    "            \"prompt\":str,\n",
    "            \"entry_point\":str,\n",
    "            \"canonical_solution\":str[code],\n",
    "            \"base_input\":List[input],\n",
    "            \"plus_input\":List[input],\n",
    "            \"base\":List[output],\n",
    "            \"base_time\":List[float],\n",
    "            \"plus\":List[output],\n",
    "            \"plus_time\":List[float],\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    save = dataset.stem + \"_with_output.json\"\n",
    "    if os.path.exists(os.path.join(dataset.parent, save)) and not is_force_override:\n",
    "        print(\"The output file already exists\")\n",
    "        return \n",
    "    for task_id,problem in data_origin.items():\n",
    "        oracle = data_origin[task_id]\n",
    "        oracle[\"base\"], oracle[\"base_time\"] = trust_execute(\n",
    "            problem[\"prompt\"] + problem[\"canonical_solution\"],\n",
    "            problem[\"base_input\"],\n",
    "            problem[\"entry_point\"],\n",
    "            record_time=True,\n",
    "        )\n",
    "        oracle[\"plus\"], oracle[\"plus_time\"] = trust_execute(\n",
    "            problem[\"prompt\"] + problem[\"canonical_solution\"],\n",
    "            problem[\"plus_input\"],\n",
    "            problem[\"entry_point\"],\n",
    "            record_time=True,\n",
    "        )\n",
    "    if not inplace:\n",
    "        with open(os.path.join(dataset.parent,save),'w') as f:\n",
    "            json.dump(data_origin,f,indent=4)\n",
    "    else:\n",
    "        with open(dataset,'w') as f:\n",
    "            json.dump(data_origin,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3YQA52WQYV1294K8WXSWHB",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardExecute('./data/codeEval/data.json',is_force_override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3YMX7K59FP3DM5D8AP0B1D",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codeExecute(file_path:Union[str,Path],dataset:Union[str,Path],exec_save_path:Union[str,Path] = None,is_force_override = False)->None:\n",
    "    if isinstance(dataset, str):\n",
    "        dataset = Path(dataset)\n",
    "    if dataset.suffix == \".json\":\n",
    "        with open(dataset,'r') as f:\n",
    "            data_origin = json.load(f)\n",
    "    elif dataset.suffix == '.jsonl':\n",
    "        with open(dataset,'r') as f:\n",
    "            \"\"\"            \n",
    "                {\"{{task_id}}\":{\n",
    "                    \"task_id\":str,\n",
    "                    \"prompt\":str,\n",
    "                    \"entry_point\":str,\n",
    "                    \"canonical_solution\":str[code],\n",
    "                    \"base_input\":List[input],\n",
    "                    \"plus_input\":List[input],\n",
    "                    \"base\":List[output],\n",
    "                    \"base_time\":List[float],\n",
    "                    \"plus\":List[output],\n",
    "                    \"plus_time\":List[float],\n",
    "                    }\n",
    "                }\n",
    "            \"\"\"\n",
    "            data_origin = {}\n",
    "            for line in f:\n",
    "                item = json.loads(line)\n",
    "                data_origin[item['task_id']] = item\n",
    "    else:\n",
    "        raise Exception(f\"{dataset.suffix} is not supported\")\n",
    "    \n",
    "    if isinstance(file_path, str):\n",
    "        file_path = Path(file_path)\n",
    "    if file_path.suffix == \".json\":\n",
    "        with open(file_path,'r') as f:\n",
    "            data_eval = json.load(f)\n",
    "    elif file_path.suffix == '.jsonl':\n",
    "        with open(file_path,'r') as f:\n",
    "            # {\"task_id\":\"solution\",}\n",
    "            data_eval = {}\n",
    "            for line in f:\n",
    "                item = json.loads(line)\n",
    "                task_id = item['task_id']\n",
    "                data_eval[task_id] = item['solution'] if 'solution' in item else data_origin[task_id]['prompt']+item['completion']\n",
    "    else:\n",
    "        raise Exception(f\"{file_path.suffix} is not supported\")\n",
    "    \"\"\"\n",
    "        {\n",
    "            \"{{task_id}}\":{\n",
    "                \"info\":{\n",
    "                    \"task_id\":\"{{task_id}}\",\n",
    "                    \"prompt\":\"{{prompt}}\",\n",
    "                    \"entry_point\":\"{{entry_point}}\",\n",
    "                    \"canonical_solution\":\"{{canonical_solution}}\",\n",
    "                    \"base_input\":\"{{base_input}}\",\n",
    "                    \"plus_input\":\"{{plus_input}}\",\n",
    "                    \"atol\":float,\n",
    "                },\n",
    "                \"expected_output\":{\n",
    "                    \"base\":\"{{base}}\",\n",
    "                    \"base_time\":\"{{base_time}}\",\n",
    "                    \"plus\":\"{{plus}}\",\n",
    "                    \"plus_time\":\"{{plus_time}}\",\n",
    "                },\n",
    "                \"code_LLM\":\"{{solution}}\",\n",
    "                \"actual_output\":{\n",
    "                    \"base\":\"{{base}}\",\n",
    "                    \"base_time\":\"{{base_time}}\",\n",
    "                    \"plus\":\"{{plus}}\",\n",
    "                    \"plus_time\":\"{{plus_time}}\",\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    output = {}\n",
    "    save = file_path.stem + \"_execute_results.json\"\n",
    "    if not exec_save_path:\n",
    "        parent = file_path.parent\n",
    "    else:\n",
    "        if isinstance(exec_save_path, str):\n",
    "            exec_save_path = Path(exec_save_path)\n",
    "        parent = exec_save_path if os.path.isdir(exec_save_path) else exec_save_path.parent\n",
    "    if os.path.exists(os.path.join(parent,save)) and not is_force_override:\n",
    "        print(\"The executeResults file already exists\")\n",
    "        return\n",
    "    for task_id,problem in data_origin.items():\n",
    "        oracle = {}\n",
    "        oracle[\"base\"], oracle[\"base_time\"] = problem['base'],problem['base_time']\n",
    "        oracle[\"plus\"], oracle[\"plus_time\"] = problem['plus'],problem['plus_time']\n",
    "        if task_id not in output:\n",
    "            output[task_id] = {}\n",
    "        output[task_id]['info'] = problem\n",
    "        output[task_id][\"expected_output\"] = oracle\n",
    "    for task_id,solution in data_eval.items():\n",
    "        oracle = {}\n",
    "        oracle[\"base\"], oracle[\"base_time\"] = execute(\n",
    "            solution,\n",
    "            data_origin[task_id][\"base_input\"],\n",
    "            data_origin[task_id][\"entry_point\"],\n",
    "            record_time=True,\n",
    "        )\n",
    "        oracle[\"plus\"], oracle[\"plus_time\"] = execute(\n",
    "            solution,\n",
    "            data_origin[task_id][\"plus_input\"],\n",
    "            data_origin[task_id][\"entry_point\"],\n",
    "            record_time=True,\n",
    "        )\n",
    "        if task_id not in output:\n",
    "            output[task_id] = {}\n",
    "        output[task_id]['code_LLM'] = solution\n",
    "        output[task_id][\"actual_output\"] = oracle\n",
    "    with open(os.path.join(parent,save), \"w\") as f:\n",
    "        json.dump(output, f, indent=4,)\n",
    "    print(save)\n",
    "def is_floats(x) -> bool:\n",
    "    # check if it is float; List[float]; Tuple[float]\n",
    "    if isinstance(x, float):\n",
    "        return True\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return all(isinstance(i, float) for i in x)\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.dtype == np.float64 or x.dtype == np.float32\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3YNAD1750FDWA6Z6PXPQCA",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codeEvaluate(exec_file:Union[str,Path],eval_save_path:Union[str,Path] = None,is_force_override:bool = False):\n",
    "    def equal(exp:List,actual:List,atol = 0)->List[bool]:\n",
    "        ret_correct = []\n",
    "        if is_floats(exp):\n",
    "            if atol == 0:\n",
    "                atol = 1e-6\n",
    "            for i in range(len(exp)):\n",
    "                if isinstance(actual[i],str) or not np.isclose(exp[i],actual[i],atol=atol):\n",
    "                    ret_correct.append(False)\n",
    "                else:\n",
    "                    ret_correct.append(True)\n",
    "        else:\n",
    "            for i in range(len(exp)):\n",
    "                if actual[i] in [\"NotImplemented\",\"TimeLimitExceeding\",\"SyntaxError\"] or actual[i] != exp[i]:\n",
    "                    ret_correct.append(False)\n",
    "                else:\n",
    "                    ret_correct.append(True)\n",
    "        return ret_correct\n",
    "    if isinstance(exec_file, str):\n",
    "        exec_file = Path(exec_file)\n",
    "    if exec_file.suffix != \".json\":\n",
    "        raise Exception(f\"{exec_file.suffix} is not supported\")\n",
    "    with open(exec_file,'r') as f:\n",
    "        data = json.load(f)\n",
    "    if not eval_save_path:\n",
    "        parent = exec_file.parent\n",
    "    else:\n",
    "        if isinstance(eval_save_path,str):\n",
    "            eval_save_path = Path(eval_save_path)\n",
    "        parent = eval_save_path if os.path.isdir(eval_save_path) else eval_save_path.parent\n",
    "            \n",
    "    save = exec_file.stem.replace('_execute_results','') + \"_eval_results.json\"\n",
    "    if os.path.exists(os.path.join(parent,save)) and not is_force_override:\n",
    "        print(\"The evalResults file already exists\")\n",
    "        return \n",
    "    eval_result = {}\n",
    "    \"\"\"\n",
    "        {\n",
    "            \"percision\":{\n",
    "                \"base\":float,\n",
    "                \"plus\":float,\n",
    "                \"mean\":float\n",
    "            },\n",
    "            \"AC\":int,\n",
    "            \"PASS\":float,\n",
    "            \"syntax_error_ratio\":{\n",
    "                \"base\":float,\n",
    "                \"plus\":float\n",
    "                \"mean\":float\n",
    "            },\n",
    "            \"accuracy_list\":{\n",
    "                \"base_accuracy_list\":List[float],\n",
    "                \"plus_accuracy_list\":List[float]\n",
    "            },\n",
    "            \"syntax_error_list\":{\n",
    "                \"base_syntax_error_list\":List[bool],\n",
    "                \"plus_syntax_error_list\":List[bool]\n",
    "            },\n",
    "            \"notImplemented_ratio_list\":List[float],\n",
    "            \"{{task_id}}\":{\n",
    "                \"base_eval\":List[bool],\n",
    "                \"base_num\":int,\n",
    "                \"base_AC\":int,\n",
    "                \"base_TLE\":int,\n",
    "                \"base_accuracy\":float,\n",
    "                \"base_exp_time\":List[time],\n",
    "                \"base_actual_time\":List[time],\n",
    "                \n",
    "                \"plus_eval\":List[bool],\n",
    "                \"plus_num\":int,\n",
    "                \"plus_AC\":int,\n",
    "                \"plus_TLE\":int,\n",
    "                \"plus_accuracy\":float,\n",
    "                \"plus_exp_time\":List[time],\n",
    "                \"plus_actual_time\":List[bool],\n",
    "                \n",
    "                \"accuracy\":float\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    eval_result['percision'] = {'base':0,'plus':0,\"mean\":0}\n",
    "    eval_result['AC'] = 0\n",
    "    eval_result['PASS'] = 0\n",
    "    AC_num = 0\n",
    "    eval_result['syntax_error_ratio'] = {'base':0,\"plus\":0,\"mean\":0}\n",
    "    base_accuracy_list = []\n",
    "    plus_accuracy_list = []\n",
    "    accuracy_list = {\"base_accuracy_list\":base_accuracy_list,\"plus_accuracy_list\":plus_accuracy_list}\n",
    "    eval_result['accuracy_list'] = accuracy_list\n",
    "    base_syntax_error_list = []\n",
    "    plus_syntax_error_list = []\n",
    "    eval_result['syntax_error_list'] ={ \"base_syntax_error_list\":base_syntax_error_list,\"plus_syntax_error_list\":plus_syntax_error_list}\n",
    "    notImplemented_list = []\n",
    "    eval_result['notImplemented_ratio_list'] = notImplemented_list\n",
    "    for task_id,eval in data.items():\n",
    "        oracle = {}\n",
    "        if 'atol' in eval['info']:\n",
    "            atol = eval['info']['atol']\n",
    "        else:\n",
    "            atol = 0\n",
    "        base_exp = eval['expected_output']['base']\n",
    "        base_actual = eval['actual_output']['base']\n",
    "        base_correct = equal(base_exp, base_actual,atol)\n",
    "        \n",
    "        oracle['base_num'] = len(base_correct)\n",
    "        oracle['base_AC'] = sum(base_correct)\n",
    "        oracle['base_TLE'] = base_actual.count(\"TimeLimitExceeding\")\n",
    "        oracle['base_SE'] = base_actual.count(\"SyntaxError\")\n",
    "        oracle['base_NoImplemented'] = base_actual.count(\"NotImplemented\")\n",
    "        oracle['base_accuracy'] = np.mean(base_correct)\n",
    "        base_accuracy_list.append(oracle['base_accuracy'])\n",
    "        base_syntax_error_list.append(oracle['base_SE']/oracle['base_num'])\n",
    "        \n",
    "        plus_exp = eval['expected_output']['plus']\n",
    "        plus_actual = eval['actual_output']['plus']\n",
    "        plus_correct = equal(plus_exp,plus_actual,atol)\n",
    "        \n",
    "        oracle['plus_num'] = len(plus_correct)\n",
    "        oracle['plus_AC'] = sum(plus_correct)\n",
    "        oracle['plus_TLE'] = plus_actual.count(\"TimeLimitExceeding\")\n",
    "        oracle['plus_SE'] = plus_actual.count(\"SyntaxError\")\n",
    "        oracle['plus_NoImplemented'] = plus_actual.count(\"NotImplemented\")\n",
    "        oracle['plus_accuracy'] = np.mean(plus_correct)\n",
    "        plus_accuracy_list.append(oracle['plus_accuracy'])\n",
    "        plus_syntax_error_list.append(oracle['plus_SE']/oracle['plus_num'])\n",
    "        \n",
    "        oracle['accuracy'] = np.mean(base_correct+plus_correct)\n",
    "        if oracle['accuracy'] == 1:\n",
    "            AC_num += 1\n",
    "        \n",
    "        oracle['base_exp_time'] = eval['expected_output']['base_time']\n",
    "        oracle['base_actual_time'] = eval['actual_output']['base_time']\n",
    "        oracle['plus_exp_time'] = eval['expected_output']['plus_time']\n",
    "        oracle['plus_actual_time'] = eval['actual_output']['plus_time']\n",
    "        \n",
    "        notImplemented_list.append((oracle['base_NoImplemented']+oracle['plus_NoImplemented'])/(oracle['base_num']+oracle['plus_num']))\n",
    "        \n",
    "        eval_result[task_id] = oracle\n",
    "    eval_result['percision']['base'] = np.mean(base_accuracy_list)\n",
    "    eval_result['percision']['plus'] = np.mean(plus_accuracy_list)\n",
    "    eval_result['percision']['mean'] = np.mean(base_accuracy_list+plus_accuracy_list)\n",
    "    eval_result['syntax_error_ratio']['base'] = np.mean(base_syntax_error_list)\n",
    "    eval_result['syntax_error_ratio']['plus'] = np.mean(plus_syntax_error_list)\n",
    "    eval_result['syntax_error_ratio']['mean'] = np.mean(base_syntax_error_list+plus_syntax_error_list)\n",
    "    eval_result['AC'] = AC_num\n",
    "    eval_result['PASS'] = AC_num/len(data)\n",
    "    with open(os.path.join(parent,save), \"w\") as f:\n",
    "        json.dump(eval_result, f, indent=4,)\n",
    "    print(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HX3YS9AV023N5CM459JXJA01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir,subdir,files in os.walk('./data/codeEval/code_sanitize'):\n",
    "    for file in files:\n",
    "        codeExecute(os.path.join(dir,file),\"./data/codeEval/data_with_output.json\",exec_save_path = './data/codeEval/code_execute',is_force_override=True)\n",
    "        codeEvaluate(os.path.join('./data/codeEval/code_execute',file.replace(\".jsonl\",\"_execute_results.json\")),eval_save_path = './data/codeEval/code_eval',is_force_override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Results View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01HX3YTWH6GBQ5MRPSTGZQMX5V",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval = {'accuracy':{},\"pass\":{},\"AC\":{}}\n",
    "for dir,subdir,files in os.walk('./data/codeEval/code_eval'):\n",
    "    for file in files:\n",
    "        model = file.replace('_eval_results.json','')\n",
    "        with open(os.path.join(dir,file)) as f:\n",
    "            data = json.load(f)\n",
    "        data_eval['accuracy'][model] = data['percision']['mean']\n",
    "        data_eval['pass'][model] = data['PASS']\n",
    "        data_eval['AC'][model] = data['AC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01HX3YV38AKTXAE08GHFR9Y1SG",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pass</th>\n",
       "      <th>AC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qwen-72b</th>\n",
       "      <td>0.884806</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-72b-chat</th>\n",
       "      <td>0.824541</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1.5-72b</th>\n",
       "      <td>0.773068</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1.5-14b-chat</th>\n",
       "      <td>0.685489</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-14b-chat</th>\n",
       "      <td>0.616513</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1.5-7b-chat</th>\n",
       "      <td>0.599208</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baichuan2-13b-chat</th>\n",
       "      <td>0.586262</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-7b-chat</th>\n",
       "      <td>0.518305</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baichuan2-7b-chat</th>\n",
       "      <td>0.326372</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-13b-chat</th>\n",
       "      <td>0.378036</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-70b</th>\n",
       "      <td>0.295190</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-7b-chat</th>\n",
       "      <td>0.254202</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baichuan2-13b-base</th>\n",
       "      <td>0.218037</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infini-megrez-7b</th>\n",
       "      <td>0.118998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy      pass  AC\n",
       "qwen-72b            0.884806  0.750000  21\n",
       "qwen-72b-chat       0.824541  0.678571  19\n",
       "qwen1.5-72b         0.773068  0.500000  14\n",
       "qwen1.5-14b-chat    0.685489  0.464286  13\n",
       "qwen-14b-chat       0.616513  0.392857  11\n",
       "qwen1.5-7b-chat     0.599208  0.357143  10\n",
       "baichuan2-13b-chat  0.586262  0.321429   9\n",
       "qwen-7b-chat        0.518305  0.214286   6\n",
       "baichuan2-7b-chat   0.326372  0.178571   5\n",
       "llama-2-13b-chat    0.378036  0.142857   4\n",
       "llama-2-70b         0.295190  0.142857   4\n",
       "llama-2-7b-chat     0.254202  0.142857   4\n",
       "baichuan2-13b-base  0.218037  0.071429   2\n",
       "infini-megrez-7b    0.118998  0.000000   0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data_eval).sort_values(by=\"AC\",ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\vllm\\lib\\site-packages\\deepeval\\__init__.py:41: UserWarning: You are using deepeval version 0.21.27, however version 0.21.36 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json,re,os,datetime,time,string\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import langchain\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Optional,Dict, Mapping, Union,Tuple\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "import collections\n",
    "import traceback,random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evalplus.sanitize,evalplus.syncheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFINI_API = \"sk-c7cssl4bkglsrwf2\"\n",
    "INFINI_API_2 = \"sk-c7erk6qaqhkz5t72\"\n",
    "INFINI_API_List = [\"sk-c7cssl4bkglsrwf2\", \"sk-c7erk6qaqhkz5t72\",\"sk-c7etq7veyeie4dn2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelList = {\n",
    "    'llama-3-70b-instruct':\"Llama3系列是由Meta开发的Llama系列全新的第三代版本，包含一系列预训练和指令调优的文本生成式模型。Llama3基于优化后的Transformer架构，预训练过程中使用了超过15T tokens的数据，调优后的模型使用SFT和RLHF，以更好地贴合人类对可用性和安全性的偏好。Llama3-70b-Instruct是此系列里，700亿参数的指令调优的模型，针对对话场景用例进行了优化，并在常见的行业基准测试中超越了许多可用的开源聊天模型。Llama3-70b-Instruct支持模型上下文至8k tokens，该模型的数据的知识截止日期为2023年12月。\",\n",
    "    'llama-3-8b-instruct':\"Llama3系列是由Meta开发的Llama系列全新的第三代版本，包含一系列预训练和指令调优的文本生成式模型。Llama3基于优化后的Transformer架构，预训练过程中使用了超过15T tokens的数据，调优后的模型使用SFT和RLHF，以更好地贴合人类对可用性和安全性的偏好。Llama3-8b-Instruct是此系列里，80亿参数的指令调优的模型，针对对话场景用例进行了优化，并在常见的行业基准测试中超越了许多可用的开源聊天模型。Llama3-8b-Instruct支持模型上下文至8k tokens，该模型的数据的知识截止日期为2023年3月。\",\n",
    "    'chatglm3':\"ChatGLM3是智谱AI与清华KEG实验室发布的闭源模型，支持 8K 上下文，经过海量中英标识符的预训练与人类偏好对齐训练，相比一代模型在 MMLU、C-Eval、GSM8K 分别取得了16%、36%、280%的提升，并登顶中文任务榜单C-Eval。适用于对知识量、推理能力、创造力要求较高的场景，比如广告文案、小说写作、知识类写作、代码生成等。\",\n",
    "    'chatglm2-6b':\"ChatGLM2-6b 是由智谱开发的 ChatGLM 系列的第二代版本，支持中英双语的60亿参数规模的开源模型。在保留了初代模型对话流畅、部署门槛较低等众多优秀特性的基础之上，在 MMLU、C-Eval、GSM8K、BBH等主流学术数据集上，都得到了显著的性能提升，并通过基于 FlashAttention 技术，将对话模型的上下文长度（Context Length）提升至 8k tokens，允许更多轮次的对话。\",\n",
    "    'chatglm2-6b-32k':\"ChatGLM2-6b 是由智谱开发的 ChatGLM 系列的第二代版本，支持中英双语的60亿参数规模的开源模型。相较于ChatGLM2-6B，ChatGLM2-6b-32k支持更长的模型上下文至32k tokens。\",\n",
    "    'infini-megrez-7b':\"由无问芯穹公司自主研发的70亿参数大语言模型。在逻辑推理、对话能力等方面有优秀的性能表现。配合无问芯穹自研高效推理引擎，同时支持Nvidia和AMD的GPU，具备更快的推理速度，在性能表现方面更上一层楼。\",\n",
    "    'llama-2-7b-chat':\"Llama2是由Meta开发并开源的大型语言模型（LLM）系列，这是一组从70亿到700亿参数不同规模、经过预训练和微调的生成式文本模型。架构层面，Llama2是一个使用优化型转换器架构的自动回归语言模型。调整后的版本使用有监督的微调（SFT）和带有人类反馈的强化学习（RLHF）以对齐人类对有用性和安全性的偏好。Llama2较Llama系列在多种学术数据集上有着更加不俗的表现，为大量其他模型提供了设计和开发的思路。Llama2-7b-chat是其中70亿的主流参数大小的模型，适用于chat场景，更擅长英文相关的内容。模型支持 4k tokens上下文。\",\n",
    "    'llama-2-13b-chat':\"Llama2是由Meta开发并开源的大型语言模型（LLM）系列，这是一组从70亿到700亿参数不同规模、经过预训练和微调的生成式文本模型。架构层面，Llama2是一个使用优化型转换器架构的自动回归语言模型。调整后的版本使用有监督的微调（SFT）和带有人类反馈的强化学习（RLHF）以对齐人类对有用性和安全性的偏好。Llama2较Llama系列在多种学术数据集上有着更加不俗的表现，为大量其他模型提供了设计和开发的思路。Llama2-7b-chat是其中70亿的主流参数大小的模型，适用于chat场景，更擅长英文相关的内容。模型支持 4k tokens上下文。\",\n",
    "    'llama-2-70b-chat':\"Llama2是由Meta开发并开源的大型语言模型（LLM）系列，这是一组从70亿到700亿参数不同规模、经过预训练和微调的生成式文本模型。架构层面，Llama2是一个使用优化型转换器架构的自动回归语言模型。调整后的版本使用有监督的微调（SFT）和带有人类反馈的强化学习（RLHF）以对齐人类对有用性和安全性的偏好。Llama2较Llama系列在多种学术数据集上有着更加不俗的表现，为大量其他模型提供了设计和开发的思路。Llama2-70b-chat是其中700亿参数的大模型，适用于chat场景，更擅长英文相关的内容，相较该系列里其他规模的的模型，有更强的综合能力。模型支持 4k tokens上下文。\",\n",
    "    'llama-2-70b':\"Llama2是由Meta开发并开源的大型语言模型（LLM）系列，这是一组从70亿到700亿参数不同规模、经过预训练和微调的生成式文本模型。架构层面，Llama2是一个使用优化型转换器架构的自动回归语言模型。调整后的版本使用有监督的微调（SFT）和带有人类反馈的强化学习（RLHF）以对齐人类对有用性和安全性的偏好。Llama2较Llama系列在多种学术数据集上有着更加不俗的表现，为大量其他模型提供了设计和开发的思路。Llama2-70b-base是其中700亿参数的基础大模型，适用于通用语言任务场景，更擅长英文相关的内容，相较该系列里其他规模的的模型，有更强的综合能力。模型支持 4k tokens上下文。\",\n",
    "    'baichuan2-7b-chat':\"Baichuan 2 是百川智能推出的新一代开源大语言模型，采用 2.6 万亿 Tokens 的高质量语料训练。Baichuan2-7b-chat是130亿参数规模用于对话的模型，在C-Eval、MMLU、CMMLU等主流评测数据集上都有不俗的表现。该基模型支持4k tokens上下文。\",\n",
    "    'baichuan2-13b-chat':\"Baichuan 2 是百川智能推出的新一代开源大语言模型，采用 2.6 万亿 Tokens 的高质量语料训练。Baichuan2-13b-chat是130亿参数规模用于对话的模型，在C-Eval、MMLU、CMMLU等主流评测数据集上都有不俗的表现。该基模型支持8k tokens上下文。\",\n",
    "    'baichuan2-13b-base':\"Baichuan 2 是百川智能推出的新一代开源大语言模型，采用 2.6 万亿 Tokens 的高质量语料训练。Baichuan2-13b-base是130亿参数规模的基础模型，适用于通用对话和文本续写，较chat模型更适合于复杂场景的微调后使用。该基模型支持4k tokens上下文。\",\n",
    "    'chatglm3-6b':\"ChatGLM3-6b 是由智谱开发的 ChatGLM 系列最新一代的60亿参数规模的开源模型。ChatGLM3采用了全新设计的 Prompt 格式，并原生支持工具调用（Function Call）、代码执行（Code Interpreter）和 Agent 任务等复杂场景。模型支持 8k tokens上下文。\",\n",
    "    'chatglm3-6b-32k':\"ChatGLM3-6b 是由智谱开发的 ChatGLM 系列最新一代的60亿参数规模的开源模型。相较于ChatGLM之前系列的模型，ChatGLM3采用了更多样的训练数据，并原生支持工具调用（Function Call）、代码执行（Code Interpreter）和 Agent 任务等复杂场景。ChatGLM3-6b-32k在ChatGLM3-6b 基础上进一步强化了对于长文本的理解能力，能够更好的处理最多32k tokens长度的上下文。\",\n",
    "    'chatglm3-6b-base':\"ChatGLM3-6b-base 是由智谱开发的 ChatGLM 系列最新一代的60亿参数规模的开源的基础模型。ChatGLM3-6B-Base 采用了更多样的训练数据、更充分的训练步数和更合理的训练策略。基础模型更适合于复杂场景的微调后使用，该基模型支持32k tokens上下文。\",\n",
    "    'qwen-7b-chat':\"通义千问-7B-chat（Qwen-7B-chat）是阿里云研发的基于Transformer，在超大规模的预训练数据上进行训练得到的70亿参数规模的大语言模型。相较于Qwen-7B-Base模型，Qwen-7B-chat是针对于对话场景以及一些常见的智能对话需求指令对齐的AI助手模型，在更多文本相关的问答场景上有更好的指令跟随能力。模型支持 8k tokens上下文。\",\n",
    "    'qwen-14b-chat':\"通义千问-14B-chat（Qwen-14B-chat）是阿里云研发的基于Transformer，在超大规模的预训练数据上进行训练得到的140亿参数规模的大语言模型。相较于Qwen-14B-Base模型，Qwen-14B-chat是针对于对话场景以及一些常见的智能对话需求指令对齐的AI助手模型，在更多文本相关的问答场景上有更好的指令跟随能力。模型支持 8k tokens上下文。\",\n",
    "    'qwen-72b-chat':\"通义千问-72B-chat（Qwen-72B-chat）是阿里云研发的基于Transformer，在超大规模的预训练数据上进行训练得到的720亿参数规模的大语言模型。相较于Qwen-72B-Base模型，Qwen-72B-chat是针对于对话场景以及一些常见的智能对话需求指令对齐的AI助手模型，在更多文本相关的问答场景上有更好的指令跟随能力。模型支持 32k tokens上下文。\",\n",
    "    'qwen-72b':\"通义千问-72B（Qwen-72B）是阿里云研发的通义千问大模型系列的720亿参数规模的模型。Qwen-72B是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。模型支持 32k tokens上下文。\",\n",
    "    'qwen1.5-7b-chat':\"Qwen1.5系列是Qwen2的Beta版本，是一个基于Transformer的仅解码语言模型，在海量数据上进行预训练。与之前发布的Qwen系列版本相比，Qwen1.5系列base与chat模型均能支持多种语言，在整体聊天和基础能力上都得到了提升，并且支持32k tokens上下文。Qwen1.5-7b-chat是其中专用于chat场景的70亿参数的主流大小模型。\",\n",
    "    'qwen1.5-14b-chat':\"Qwen1.5系列是Qwen2的Beta版本，是一个基于Transformer的仅解码语言模型，在海量数据上进行预训练。与之前发布的Qwen系列版本相比，Qwen1.5系列base与chat模型均能支持多种语言，在整体聊天和基础能力上都得到了提升，并且支持32k tokens上下文。Qwen1.5-14b-chat是其中专用于chat场景的140亿参数的主流大小模型。\",\n",
    "    'qwen1.5-72b-chat':\"Qwen1.5系列是Qwen2的Beta版本，是一个基于Transformer的仅解码语言模型，在海量数据上进行预训练。与之前发布的Qwen系列版本相比，Qwen1.5系列base与chat模型均能支持多种语言，在整体聊天和基础能力上都得到了提升，并且支持32k tokens上下文。Qwen1.5-72b-chat是其中专用于chat场景的720亿参数的大模型。\",\n",
    "    'qwen1.5-72b':\"Qwen1.5系列是Qwen2的Beta版本，是一个基于Transformer的仅解码语言模型，在海量数据上进行预训练。与之前发布的Qwen系列版本相比，Qwen1.5系列base与chat模型均能支持多种语言，在整体聊天和基础能力上都得到了提升，并且支持32k tokens上下文。Qwen1.5-72b-base是其中的720亿参数的基础大模型，适合多种场景的使用。\",\n",
    "}\n",
    "answerModelList = [    \n",
    "    'llama-3-8b-instruct',\n",
    "    # 'chatglm3',\n",
    "    # 'chatglm2-6b',\n",
    "    # 'chatglm2-6b-32k',\n",
    "    'infini-megrez-7b',\n",
    "    'llama-2-7b-chat',\n",
    "    'llama-2-13b-chat',\n",
    "    'llama-2-70b-chat',\n",
    "    'llama-2-70b',\n",
    "    'baichuan2-7b-chat',\n",
    "    'baichuan2-13b-chat',\n",
    "    'baichuan2-13b-base',\n",
    "    # 'chatglm3-6b',\n",
    "    # 'chatglm3-6b-32k',\n",
    "    # 'chatglm3-6b-base',\n",
    "    'qwen-7b-chat',\n",
    "    'qwen-14b-chat',\n",
    "    'qwen-72b-chat',\n",
    "    'qwen-72b',\n",
    "    'qwen1.5-7b-chat',\n",
    "    'qwen1.5-14b-chat',\n",
    "    'qwen1.5-72b',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLMCompletions(prompt,modelName:str = \"infini-megrez-7b\",INFINI_API = \"sk-c7cssl4bkglsrwf2\",returnContent:bool = True,**kwargs):\n",
    "    url = \"https://cloud.infini-ai.com/maas/\"+modelName+\"/nvidia/chat/completions\"\n",
    "    payload = {\n",
    "        \"model\": \"string\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"temperature\": kwargs[\"temperature\"] if \"temperature\" in kwargs else 0.7,\n",
    "        \"top_p\": kwargs[\"top_p\"] if 'top_p' in kwargs else 1,\n",
    "        \"top_k\": kwargs['top_k'] if 'top_k' in kwargs else -1,\n",
    "        \"n\": kwargs['n'] if 'n' in kwargs else 1,\n",
    "        \"max_tokens\": kwargs['max_tokens'] if 'max_tokens' in kwargs else None,\n",
    "        \"stop\": kwargs['stop'] if 'stop' in kwargs else None,\n",
    "        \"presence_penalty\": kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else 0,\n",
    "        \"frequency_penalty\": kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else 0\n",
    "    }\n",
    "    headers = {\n",
    "            'Content-Type': \"application/json\",\n",
    "            'Accept': \"*/*\",\n",
    "            'Authorization': \"Bearer \"+INFINI_API,\n",
    "    } \n",
    "    response = requests.post(url, json=payload, headers=headers,)\n",
    "    if response.status_code == 200:\n",
    "        response.encoding = 'utf-8'\n",
    "        data = response.json()\n",
    "        content = data['choices'][0]['message']['content']\n",
    "        \n",
    "        content = content.replace(',\\n}','\\n}')\n",
    "        if returnContent:\n",
    "            return content\n",
    "        try:\n",
    "            content = json.loads(content)\n",
    "        except:\n",
    "            content = content.replace('\\n','')\n",
    "        data['choices'][0]['message']['content'] = content\n",
    "        \n",
    "        return json.dumps(data['choices'][0]['message']['content'])\n",
    "\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "        return \"Cannot connect to the model \"+modelName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format_ins = {\n",
    "    'id':0,\n",
    "    'AnswerModel':'',\n",
    "    'input':'',\n",
    "    'actual_output':'',\n",
    "    'expected_output':None,\n",
    "    'retrieval_context':None,\n",
    "    'time':-1\n",
    "}\n",
    "def joinErrorToData(errorFile,saveFile):\n",
    "    with open(errorFile, 'r') as ef:\n",
    "        data_ef = json.load(ef)\n",
    "    fileName = data_ef['fileName']\n",
    "    with open(saveFile) as sf:\n",
    "        data_sf = json.load(sf)\n",
    "    if fileName != data_sf['fileName']:\n",
    "        print('FileName not match')\n",
    "        return \n",
    "    if not data_ef['data']:\n",
    "        print('The Errors of this ErrorFile all have been solved!')\n",
    "        return \n",
    "    errorItem = []\n",
    "    for item in data_ef['data']:\n",
    "        data_format_ins['id'] = item['id']\n",
    "        model = item['AnswerModel']\n",
    "        data_format_ins['AnswerModel'] = model\n",
    "        prompt = item['input']\n",
    "        data_format_ins['input'] = prompt\n",
    "        data_format_ins['expected_output'] = item['expected_output']\n",
    "        start = time.perf_counter_ns()\n",
    "        actual_output =  LLMCompletions(prompt,modelName=model,INFINI_API=INFINI_API_2)\n",
    "        end = time.perf_counter_ns()\n",
    "        delta = end-start\n",
    "        idx = 0\n",
    "        while actual_output == \"Cannot connect to the model \"+model and idx<2:\n",
    "            start = time.perf_counter_ns()\n",
    "            actual_output =  LLMCompletions(prompt,modelName=model,INFINI_API=INFINI_API_2)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = end-start\n",
    "            idx += 1\n",
    "        if actual_output == \"Cannot connect to the model \"+model:\n",
    "            errorItem.append(item)\n",
    "            print(\"[error]:\\t\"+str(errorItem[-1]))\n",
    "            continue\n",
    "        print(actual_output)\n",
    "        data_format_ins['time'] = delta\n",
    "        data_format_ins['actual_output'] = actual_output\n",
    "        data_sf['data'].append(data_format_ins.copy())\n",
    "    data_ef['data'] = errorItem\n",
    "    with open(saveFile,'w') as saveF:\n",
    "        json.dump(data_sf,saveF)\n",
    "    with open(errorFile,'w') as error:\n",
    "        json.dump(data_ef,error)\n",
    "    if errorItem:\n",
    "        print(\"There are still some errors! \")\n",
    "    else:\n",
    "        print('The Errors of this ErrorFile all have been solved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDeprecatedModel(filePath):\n",
    "    with open(filePath) as f:\n",
    "        data = json.load(f)\n",
    "    new_data = []\n",
    "    for item in data['data']:\n",
    "        if item['AnswerModel']  in answerModelList:\n",
    "            new_data.append(item)\n",
    "    data['data'] = new_data[:]\n",
    "    with open(filePath,'w') as f:\n",
    "        json.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removeDeprecatedModel('./data/1-2_1_low_freq_ent_sample.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joinErrorToData('./data/4-2_r_with_triples_sampleError.json','./data/4-2_r_with_triples_sample.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff = collections.Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qapairs = []\n",
    "# model_input_id = []\n",
    "# with open('./data/1-1_2_high_freq_ent_sample.json') as saveF:\n",
    "#     data = json.load(saveF)\n",
    "# with open('E:/Repository/KoLA/Sample_Data/1-1_2_high_freq_ent_sample.json') as file:\n",
    "#     data_o = json.load(file)\n",
    "# instructions = data_o['adapter_spec']['instructions']\n",
    "# for item in data_o['request_states']:\n",
    "#     qapairs.append((item['instance']['id'],instructions+'\\n'+item['instance']['input']['text']))\n",
    "# for item in data['data']:\n",
    "#     model_input_id.append([item['AnswerModel'],item['input'],item['id']])\n",
    "# check = [ False for i in range(len(model_input_id))]\n",
    "# for model in answerModelList:\n",
    "#     for id,text in qapairs:\n",
    "#         for i,item in enumerate(model_input_id):\n",
    "#             if model == item[0] and text == item[1] and id == item[2]:\n",
    "#                 check[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model,text,id in model_input_id:\n",
    "#     diff[model] += 1\n",
    "#     diff[text] += 1\n",
    "#     diff[id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "### deprecated ChatLLM,CustomLLM\n",
    "# class ChatLLM(LLM):\n",
    "#     modelName = \"qwen1.5-72b-chat\"\n",
    "#     INFINI_API = \"sk-c7cssl4bkglsrwf2\"\n",
    "#     temperature = 0.8\n",
    "#     top_p = 1\n",
    "#     top_k = -1\n",
    "#     n = 1\n",
    "#     max_tokens:int = None\n",
    "#     stop:Optional[List[str]] = None\n",
    "#     presence_penalty = 0\n",
    "#     frequency_penalty = 0\n",
    "    \n",
    "#     headers = {\n",
    "#             'Content-Type': \"application/json\",\n",
    "#             'Accept': \"*/*\",\n",
    "#             'Authorization': \"Bearer \"+INFINI_API,\n",
    "#     }   \n",
    "#     @property\n",
    "#     def _llm_type(self)->str:\n",
    "#         return \"ChatLLM\"\n",
    "#     @property\n",
    "#     def _identifying_params(self)->Mapping[str,Any]:\n",
    "#         _param_dict = {\n",
    "#             \"modelName\":ChatLLM().modelName,\n",
    "#             \"INFINI_API\":ChatLLM().INFINI_API,\n",
    "#             \"stream\":bool(ChatLLM().stream),\n",
    "#             \"temperature\":ChatLLM().temperature,\n",
    "#             \"top_p\":ChatLLM().top_p,\n",
    "#             \"top_k\":ChatLLM().top_k,\n",
    "#             \"n\":ChatLLM().n,\n",
    "#             \"max_tokens\":ChatLLM().max_tokens,\n",
    "#             \"stop\":ChatLLM().stop,\n",
    "#             \"presence_penalty\":ChatLLM().presence_penalty,\n",
    "#             \"frequency_penalty\":ChatLLM().frequency_penalty,\n",
    "#         }\n",
    "#         return _param_dict\n",
    "#     @classmethod  \n",
    "#     def _call(self, prompt: str, stop: Optional[List[str]]= None,  **kwargs: Any) -> str:\n",
    "#         url = \"https://cloud.infini-ai.com/maas/\"+ChatLLM().modelName+\"/nvidia/chat/completions\"\n",
    "#         payload = {\n",
    "#             \"model\": \"string\",\n",
    "#             \"messages\": [\n",
    "#                 {\n",
    "#                     \"role\": \"user\",\n",
    "#                     \"content\": prompt\n",
    "#                 }\n",
    "#             ],\n",
    "#             \"stream\": False,\n",
    "#             \"temperature\": kwargs[\"temperature\"] if \"temperature\" in kwargs else ChatLLM().temperature,\n",
    "#             \"top_p\": kwargs[\"top_p\"] if 'top_p' in kwargs else ChatLLM().top_p,\n",
    "#             \"top_k\": kwargs['top_k'] if 'top_k' in kwargs else ChatLLM().top_k,\n",
    "#             \"n\": kwargs['n'] if 'n' in kwargs else ChatLLM().n,\n",
    "#             \"max_tokens\": kwargs['max_tokens'] if 'max_tokens' in kwargs else ChatLLM().max_tokens,\n",
    "#             \"stop\": stop if stop else ChatLLM().stop,\n",
    "#             \"presence_penalty\": kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else ChatLLM().presence_penalty,\n",
    "#             \"frequency_penalty\": kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else ChatLLM().frequency_penalty\n",
    "#         }\n",
    "#         response = requests.post(url, json=payload, headers=ChatLLM().headers)\n",
    "#         if response.status_code == 200:\n",
    "#             response.encoding = 'utf-8'\n",
    "#             data = response.json()\n",
    "#             content = data['choices'][0]['message']['content']\n",
    "#             if isinstance(content,str):    \n",
    "#                 content = content.replace(',\\n}','\\n}')\n",
    "#                 content = content.replace(']\\n}',']}')\n",
    "#                 content = content.replace('\\\\','\\\\\\\\')\n",
    "#                 flag = False\n",
    "#                 if 'statements' in content:\n",
    "#                     regex = re.compile('\\\"statements\\\":\\s+\\[.*\\]\\}',re.DOTALL)\n",
    "#                     flag = True\n",
    "#                 elif 'verdicts' in content:\n",
    "#                     regex = re.compile('\\\"verdicts\\\":\\s+\\[.*\\]\\}', re.DOTALL) \n",
    "#                     flag = True\n",
    "#                 if flag:\n",
    "#                     matchStr =regex.search(content)\n",
    "#                     if matchStr:\n",
    "#                         content = '{'+matchStr.group()\n",
    "#             try:\n",
    "#                 content = json.loads(content)\n",
    "#             except:\n",
    "#                 pass\n",
    "#             data['choices'][0]['message']['content'] = content\n",
    "                \n",
    "#             return json.dumps(data['choices'][0]['message']['content'])\n",
    "\n",
    "#         else:\n",
    "#             return \"Cannot connect to the model \"+ChatLLM().modelName\n",
    "#     def setParameter(self,**kwargs):\n",
    "#         self.temperature = kwargs[\"temperature\"] if \"temperature\" in kwargs else ChatLLM().temperature\n",
    "#         self.top_p = kwargs['top_p'] if 'top_p' in  kwargs else ChatLLM().top_p\n",
    "#         self.top_k = kwargs['top_k'] if 'top_k' in  kwargs else ChatLLM().top_k\n",
    "#         self.n = kwargs['n'] if 'n' in kwargs else ChatLLM().n\n",
    "#         self.max_tokens = kwargs['max_tokens'] if 'max_tokens' in kwargs else ChatLLM().max_tokens\n",
    "#         self.stop = kwargs['stop'] if 'stop' in kwargs else ChatLLM().stop\n",
    "#         self.presence_penalty = kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else ChatLLM().presence_penalty\n",
    "#         self.frequency_penalty = kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else ChatLLM().frequency_penalty\n",
    "\n",
    "# class CustomLLM(DeepEvalBaseLLM):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         model\n",
    "#     ):\n",
    "#         self.model = model\n",
    "\n",
    "#     def load_model(self):\n",
    "#         return self.model\n",
    "\n",
    "#     def generate(self, prompt: str) -> str:\n",
    "#         chat_model = self.load_model()\n",
    "#         return chat_model.invoke(prompt)\n",
    "#     async def a_generate(self, prompt: str) -> str:\n",
    "#         chat_model = self.load_model()\n",
    "#         res = await chat_model.ainvoke(prompt)\n",
    "#         return res\n",
    "\n",
    "#     def get_model_name(self):\n",
    "#         return \"CustomLLM\"\n",
    "\n",
    "# custom_model = ChatLLM()\n",
    "\n",
    "# evaluateModel = CustomLLM(model=custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatLLM(LLM):\n",
    "    @property\n",
    "    def modelName(self)->str:\n",
    "        return \"qwen1.5-72b-chat\"\n",
    "    @property\n",
    "    def INFINI_API_List(self)->List[str]:\n",
    "        return [\"sk-c7cssl4bkglsrwf2\", \"sk-c7erk6qaqhkz5t72\",\"sk-c7etq7veyeie4dn2\"]\n",
    "    @property\n",
    "    def temperature(self)->float:\n",
    "        return 0.7\n",
    "    @property\n",
    "    def top_p(self)->float:\n",
    "        return 0.1\n",
    "    @property\n",
    "    def top_k(self)->int:\n",
    "        return -1\n",
    "    @property\n",
    "    def n(self)->int:\n",
    "        return 1\n",
    "    @property\n",
    "    def max_tokens(self)->int:\n",
    "        return None\n",
    "    @property\n",
    "    def stop(self)->Optional[List[str]]:\n",
    "        return None\n",
    "    @property\n",
    "    def presence_penalty(self)->float:\n",
    "        return 0\n",
    "    @property\n",
    "    def frequency_penalty(self)->float:\n",
    "        return 0\n",
    "    def getHeader(self,index_api):  \n",
    "        headers = {\n",
    "            'Content-Type': \"application/json\",\n",
    "            'Accept': \"*/*\",\n",
    "            'Authorization': \"Bearer \"+self.INFINI_API_List[index_api%len(self.INFINI_API_List)],\n",
    "        }\n",
    "        return headers\n",
    "    @property\n",
    "    def _llm_type(self)->str:\n",
    "        return \"ChatLLM\"\n",
    "    @property\n",
    "    def _identifying_params(self)->Mapping[str,Any]:\n",
    "        _param_dict = {\n",
    "            \"modelName\":self.modelName,\n",
    "            \"INFINI_API\":self.getHeader(self.__fields__['index_api'] if 'index_api' in self.__fields__ else 0),\n",
    "            \"stream\":bool(self.stream),\n",
    "            \"temperature\":self.temperature,\n",
    "            \"top_p\":self.top_p,\n",
    "            \"top_k\":self.top_k,\n",
    "            \"n\":self.n,\n",
    "            \"max_tokens\":self.max_tokens,\n",
    "            \"stop\":self.stop,\n",
    "            \"presence_penalty\":self.presence_penalty,\n",
    "            \"frequency_penalty\":self.frequency_penalty,\n",
    "        }\n",
    "        return _param_dict\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]]= None, run_manager= None,**kwargs: Any) -> str:\n",
    "        url = \"https://cloud.infini-ai.com/maas/\"+str(self.modelName)+\"/nvidia/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"string\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"stream\": False,\n",
    "            \"temperature\": kwargs[\"temperature\"] if \"temperature\" in kwargs else self.temperature,\n",
    "            \"top_p\": kwargs[\"top_p\"] if 'top_p' in kwargs else self.top_p,\n",
    "            \"top_k\": kwargs['top_k'] if 'top_k' in kwargs else self.top_k,\n",
    "            \"n\": kwargs['n'] if 'n' in kwargs else self.n,\n",
    "            \"max_tokens\": kwargs['max_tokens'] if 'max_tokens' in kwargs else self.max_tokens,\n",
    "            \"stop\": stop if stop else self.stop,\n",
    "            \"presence_penalty\": kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else self.presence_penalty,\n",
    "            \"frequency_penalty\": kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else self.frequency_penalty\n",
    "        }\n",
    "        index = 0\n",
    "        if 'index_api' not in self.__fields__:\n",
    "            self.__fields__['index_api'] = -1\n",
    "        index_api = self.__fields__['index_api']+1\n",
    "        length = len(self.INFINI_API_List)\n",
    "        while index < length:\n",
    "            response = requests.post(url, json=payload, headers=self.getHeader(index_api))\n",
    "            if response.status_code == 200:\n",
    "                response.encoding = 'utf-8'\n",
    "                data = response.json()\n",
    "                print(\"response json success\")\n",
    "                content = data['choices'][0]['message']['content']\n",
    "                if isinstance(content,str):   \n",
    "                    content = content.replace(',\\n}','\\n}')\n",
    "                    content = content.replace(']\\n}',']}')\n",
    "                    if 'statements' in content:\n",
    "                        regex = re.compile('\\\"statements\\\":\\s+\\[.*\\]\\}',re.DOTALL)\n",
    "                        matchStr =regex.search(content)\n",
    "                        if matchStr:\n",
    "                            content = '{'+matchStr.group()\n",
    "                    elif 'verdicts' in content:\n",
    "                        regex = re.compile('\\\"verdicts\\\":\\s+\\[.*\\]\\}',re.DOTALL)\n",
    "                        matchStr =regex.search(content)\n",
    "                        if matchStr is not None:\n",
    "                            content ='{' +matchStr.group()\n",
    "                            regex = re.compile(\"\\\"reason\\\":(.*?)\\}\",re.DOTALL)\n",
    "                            matchStr = regex.findall(content)\n",
    "                            for string in matchStr:\n",
    "                                tmp = string.strip()[1:-1].replace('\"','\\\\\\\"')\n",
    "                                tmp = '\\\"'+tmp+\"\\\"\"\n",
    "                                content = content.replace(string,tmp)\n",
    "                if isinstance(content,str):\n",
    "                    return content\n",
    "                data['choices'][0]['message']['content'] = content\n",
    "                return json.dumps(data['choices'][0]['message']['content'])\n",
    "\n",
    "            index += 1\n",
    "            index_api =  (index_api+1)%length\n",
    "            self.__fields__['index_api'] = index_api\n",
    "            print(response.status_code)\n",
    "            try:\n",
    "                print(response.json())\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(1)\n",
    "        return \"Cannot connect to the model \"+self.modelName\n",
    "    def setParameter(self,**kwargs):\n",
    "        self.temperature = kwargs[\"temperature\"] if \"temperature\" in kwargs else self.temperature\n",
    "        self.top_p = kwargs['top_p'] if 'top_p' in  kwargs else self.top_p\n",
    "        self.top_k = kwargs['top_k'] if 'top_k' in  kwargs else self.top_k\n",
    "        self.n = kwargs['n'] if 'n' in kwargs else self.n\n",
    "        self.max_tokens = kwargs['max_tokens'] if 'max_tokens' in kwargs else self.max_tokens\n",
    "        self.stop = kwargs['stop'] if 'stop' in kwargs else self.stop\n",
    "        self.presence_penalty = kwargs[\"presence_penalty\"]  if 'presence_penalty' in kwargs else self.presence_penalty\n",
    "        self.frequency_penalty = kwargs['frequency_penalty'] if 'frequency_penalty' in kwargs else self.frequency_penalty\n",
    "    \n",
    "\n",
    "class CustomLLM(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model\n",
    "    ):\n",
    "        self.model = model\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        global path\n",
    "        chat_model = self.load_model()\n",
    "        ret = chat_model.invoke(prompt)\n",
    "        idx = 0\n",
    "        if ret == \"Cannot connect to the model \"+self.get_model_name() and idx<2:\n",
    "            time.sleep(5)\n",
    "            ret = chat_model.invoke(prompt)\n",
    "            idx += 1\n",
    "        return ret\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        try:\n",
    "            return self.model.modelName\n",
    "        except:\n",
    "            return \"CustomLLM\"\n",
    "custom_model = ChatLLM()\n",
    "evaluateModel = CustomLLM(model=custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"verdict\":\"yes\"}', '{\"verdict\":\"no\",\"reason\":\"123\"}']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = \"\\\"verdicts\\\": [{\\\"verdict\\\":\\\"yes\\\"} , {\\\"verdict\\\":\\\"no\\\",\\\"reason\\\":\\\"123\\\"}]\"\n",
    "regex = re.compile(\"\\{\\s*\\\"verdict\\\"\\s*:.*?\\}\")\n",
    "matchStr = regex.findall(content)\n",
    "matchStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_format_example = {\n",
    "    'metric_metadata':{\n",
    "        'metric':None,\n",
    "        'threshold':0,\n",
    "        'success':True,\n",
    "        'score':0.8,\n",
    "        'reason':'',\n",
    "        'strictMode': False,\n",
    "        'evaluationModel': 'CustomLLM',\n",
    "        'evaluationCost': 0\n",
    "    },\n",
    "    'metric_configuration': {\n",
    "        'threshold': 0.5,\n",
    "        'evaluation_model': 'CustomLLM',\n",
    "        'strict_mode': False,\n",
    "        'include_reason': True\n",
    "    }\n",
    "}\n",
    "\n",
    "data_format_example = {\n",
    "    'id':0,\n",
    "    'AnswerModel':'',\n",
    "    'input':'',\n",
    "    'actual_output':'',\n",
    "    'expected_output':None,\n",
    "    'retrieval_context':None,\n",
    "    'cached_metrics_data':[\n",
    "        {\n",
    "            'metric_metadata':{\n",
    "                'metric':None,\n",
    "                'success':True,\n",
    "                'score':0.8,\n",
    "                'reason':'',\n",
    "                'statements':'',\n",
    "                'verdicts':'',\n",
    "                'evaluationCost': 0\n",
    "            },\n",
    "            'metric_configuration': {\n",
    "                'threshold': 0.5,\n",
    "                'evaluation_model': 'CustomLLM',\n",
    "                'strict_mode': False,\n",
    "                'include_reason': True\n",
    "            }\n",
    "        },\n",
    "        metrics_format_example\n",
    "    ]\n",
    "}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['data.json', 'data.jsonl', 'infini-megrez-7b_samples.jsonl']\n",
      "['baichuan2-13b-base.jsonl', 'baichuan2-13b-chat.jsonl', 'baichuan2-7b-chat.jsonl']\n",
      "['baichuan2-13b-base.jsonl', 'baichuan2-13b-chat.jsonl', 'baichuan2-7b-chat.jsonl', 'infini-megrez-7b.jsonl', 'llama-2-13b-chat.jsonl', 'llama-2-70b-chat.jsonl', 'llama-2-70b.jsonl', 'llama-2-7b-chat.jsonl', 'qwen-14b-chat.jsonl', 'qwen-72b-chat.jsonl', 'qwen-72b.jsonl', 'qwen-7b-chat.jsonl', 'qwen1.5-14b-chat.jsonl', 'qwen1.5-72b.jsonl', 'qwen1.5-7b-chat.jsonl']\n",
      "['baichuan2-13b-base.jsonl', 'baichuan2-13b-chat.jsonl', 'baichuan2-7b-chat.jsonl', 'infini-megrez-7b.jsonl', 'infini-megrez-7b_samples.jsonl', 'llama-2-13b-chat.jsonl', 'llama-2-70b-chat.jsonl', 'llama-2-70b.jsonl', 'llama-2-7b-chat.jsonl', 'qwen-14b-chat.jsonl', 'qwen-72b-chat.jsonl', 'qwen-72b.jsonl', 'qwen-7b-chat.jsonl', 'qwen1.5-14b-chat.jsonl', 'qwen1.5-72b.jsonl', 'qwen1.5-7b-chat.jsonl']\n",
      "[]\n",
      "['1-1_2_high_freq_ent_sample - copy.json', '1-1_2_high_freq_ent_sample.json', '1-2_1_low_freq_ent_sample.json', '1-3_r_1_simple_sample_sample.json', '2-1_COPEN++csj_sample.json', '2-2_COPEN++cpj_sample.json', '2-3_COPEN++cic_sample.json', '2-4_FewNERD++inter_sample.json', '2-4_FewNERD++intra_sample.json', '2-4_FewNERD++supervised_sample.json', '2-5_DocRED_sample.json', '2-6_MAVEN_sample.json', '2-7_MAVEN-ERE_sample.json', '2-8_r_DocRED_sample.json', '3-1_hotpotqa_sample.json', '3-2_2wikimultihopqa_sample.json', '3-3_musique_sample.json', '3-4_kqapro_sample.json', '3-5_KoRC++ood_sample.json', '3-6_r_KoRC++ood_sample.json', '4-1_without_triples_sample.json', '4-1_with_triples_sample.json', '4-2_r_without_triples_sample.json', '4-2_r_with_triples_sample.json']\n",
      "['math401.json', 'math50.json', 'math50_eval_result.json', 'math50_eval_result_df.json', 'save.rar']\n",
      "['llama-2-70b-chat.json']\n",
      "['baichuan2-13b-base.json', 'baichuan2-13b-chat.json', 'baichuan2-7b-chat.json', 'infini-megrez-7b.json', 'llama-2-13b-chat.json', 'llama-2-7b-chat.json', 'qwen-14b-chat.json', 'qwen-72b-chat.json', 'qwen-72b.json', 'qwen-7b-chat.json', 'qwen1.5-14b-chat.json', 'qwen1.5-72b.json', 'qwen1.5-7b-chat.json']\n"
     ]
    }
   ],
   "source": [
    "for dirName,subDirName ,fileNames in os.walk('./data'):\n",
    "    print(fileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = ['1-3_r_1_simple_sample_sample.json', '2-1_COPEN++csj_sample.json', '2-2_COPEN++cpj_sample.json', '2-3_COPEN++cic_sample.json', '2-4_FewNERD++inter_sample.json', '2-4_FewNERD++intra_sample.json', '2-4_FewNERD++supervised_sample.json', '2-5_DocRED_sample.json', '2-6_MAVEN_sample.json', '2-7_MAVEN-ERE_sample.json', '2-8_r_DocRED_sample.json', '3-1_hotpotqa_sample.json', '3-2_2wikimultihopqa_sample.json', '3-3_musique_sample.json', '3-4_kqapro_sample.json', '3-5_KoRC++ood_sample.json', '3-6_r_KoRC++ood_sample.json', '4-1_without_triples_sample.json', '4-1_with_triples_sample.json', '4-2_r_without_triples_sample.json', '4-2_r_with_triples_sample.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric,FaithfulnessMetric,HallucinationMetric,BaseMetric\n",
    "from deepeval.test_case import LLMTestCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics  = [\n",
    "    AnswerRelevancyMetric(\n",
    "        threshold=0.5,\n",
    "        model=evaluateModel,\n",
    "        include_reason=True\n",
    "    ),\n",
    "    HallucinationMetric(\n",
    "        threshold=0.5,\n",
    "        model=evaluateModel,\n",
    "        include_reason=True\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./eval/error/2-1_COPEN++csj_sample.json') as f:\n",
    "#     data = json.load(f)\n",
    "# data['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_case = LLMTestCase(input=data['data'][0]['input'],\n",
    "#                         actual_output=data['data'][0]['actual_output'],\n",
    "#                         context=[data['data'][0]['expected_output']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics[0].measure(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_file(filename:Union[str,Path],save_file:Union[str,Path],error_file:Union[str,Path],force_save:bool = False,metrics:List[BaseMetric] = [AnswerRelevancyMetric(threshold=0.5,model=evaluateModel,include_reason=True),HallucinationMetric(threshold=0.5,model=evaluateModel,include_reason=True)]):\n",
    "    \"\"\"_summary_\n",
    "        the function is used to evaluate the LLM output saved in `filename` by the metric in `metrics`,the successful eval results will be saved into `save_file` and the error item will be saved into `error_file`\n",
    "    \n",
    "    Args:\n",
    "        `filename` (Union[str,Path]): the filename saves the LLM generation results\n",
    "        `save_file` (Union[str,Path]): the filename will save the evaluate results\n",
    "        `error_file` (Union[str,Path]): the filename will save the error eval item\n",
    "        `force_save` (bool, optional): if the value is `True`,function will rerun all eval item in `filename` and directly override the `save_file` and `error_file`. \n",
    "                    Defaults to False.\n",
    "        `metrics` (List[BaseMetric], optional): a list of evaluation metrics. \n",
    "                    Defaults to [AnswerRelevancyMetric(threshold=0.5,model=evaluateModel,include_reason=True),HallucinationMetric(threshold=0.5,model=evaluateModel,include_reason=True)].\n",
    "    \"\"\"\n",
    "    def is_same_eval_item(x,item):\n",
    "        if x['id'] == item['id'] and x['input'] == item['input'] and x['actual_output'] == item['actual_output'] and x['AnswerModel'] == item['AnswerModel'] and x['expected_output'] == item['expected_output']:\n",
    "            return True\n",
    "        return False\n",
    "    with open(filename,'r') as f:\n",
    "        data = json.load(f)\n",
    "    save,error = dict(),dict()\n",
    "    if  Path(save_file).is_file() and not force_save:\n",
    "        with open(save_file) as f:\n",
    "            save = json.load(f)\n",
    "        if 'fileName' in save and  save['fileName'] != data['fileName']:\n",
    "            print(\"The save_file does not match the file name!\")\n",
    "            return\n",
    "    else:\n",
    "        save = {'fileName':data['fileName'],'class':data['class'],'data':[]}\n",
    "\n",
    "    if Path(error_file).is_file() and not force_save:\n",
    "        with open(error_file) as f:\n",
    "            error = json.load(f)\n",
    "        if 'fileName' in error and  error['fileName'] != data['fileName']:\n",
    "            print(\"The error_file does not match the file name!\")\n",
    "            return\n",
    "    else:\n",
    "        error = {'fileName' :data['fileName'],'class':data['class'],'data':[]}\n",
    "    for metric in metrics:\n",
    "        for item in data['data']:\n",
    "            data_format_ins = {\n",
    "                'id':0,\n",
    "                'AnswerModel':'',\n",
    "                'input':'',\n",
    "                'actual_output':'',\n",
    "                'expected_output':None,\n",
    "                'retrieval_context':None,\n",
    "                'cached_metrics_data':[]\n",
    "            }\n",
    "            metrics_format_ins = {\n",
    "                'metric_metadata':{\n",
    "                    'metric':None,\n",
    "                    'success':True,\n",
    "                    'score':0.8,\n",
    "                    'reason':'',\n",
    "                    'statements':'',\n",
    "                    'verdicts':'',\n",
    "                    'evaluationCost': 0\n",
    "                },\n",
    "                'metric_configuration': {\n",
    "                    'threshold': 0.5,\n",
    "                    'evaluation_model': 'CustomLLM',\n",
    "                    'strict_mode': False,\n",
    "                    'include_reason': True\n",
    "                }\n",
    "            }\n",
    "            errors_format_ins = {\n",
    "                'id':0,\n",
    "                'AnswerModel':'',\n",
    "                'input':'',\n",
    "                'actual_output':'',\n",
    "                'expected_output':None,\n",
    "                'retrieval_context':None,\n",
    "                'cached_metrics_data':[\n",
    "                    {            \n",
    "                        'metric_metadata':{\n",
    "                            'metric':None,\n",
    "                        },\n",
    "                        'metric_configuration': {\n",
    "                            'threshold': 0.5,\n",
    "                            'evaluation_model': 'CustomLLM',\n",
    "                            'strict_mode': False,\n",
    "                            'include_reason': True\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            data_format_ins['id'] = item['id']\n",
    "            data_format_ins['AnswerModel'] = item['AnswerModel']\n",
    "            data_format_ins['input'] = item['input']\n",
    "            data_format_ins['actual_output'] = item['actual_output']\n",
    "            data_format_ins['expected_output'] = item['expected_output']\n",
    "            tag = False\n",
    "            for x in save['data']:\n",
    "                if is_same_eval_item(item,x):\n",
    "                    for metric_data in x['cached_metrics_data']:\n",
    "                        if metric_data['metric_metadata']['metric'] == metric.__name__:\n",
    "                            if metric_data['metric_configuration']['threshold'] == metric.threshold and metric_data['metric_configuration']['evaluation_model'] == metric.evaluation_model and metric_data['metric_configuration']['strict_mode'] == metric.strict_mode and metric_data['metric_configuration']['include_reason'] == metric.include_reason:\n",
    "                                tag = True\n",
    "                                print(\"HAVE:\")\n",
    "                                print(x)\n",
    "                                break\n",
    "            if tag:\n",
    "                continue\n",
    "            test_case = LLMTestCase(\n",
    "                input= item['input'],\n",
    "                actual_output=item['actual_output'],\n",
    "                context=[item['expected_output']],\n",
    "            )\n",
    "            try:\n",
    "                metric.measure(test_case)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                path.append(e)\n",
    "                errors_format_ins['id'] = item['id']\n",
    "                errors_format_ins['AnswerModel'] = item['AnswerModel']\n",
    "                errors_format_ins['input'] = item['input']\n",
    "                errors_format_ins['actual_output'] = item['actual_output']\n",
    "                errors_format_ins['expected_output'] = item['expected_output']\n",
    "                errors_format_ins['cached_metrics_data'][0]['metric_metadata']['metric'] = metric.__name__\n",
    "                errors_format_ins['cached_metrics_data'][0]['metric_configuration'] = {'threshold':metric.threshold,'evaluation_model':metric.evaluation_model,'strict_mode':metric.strict_mode,'include_reason':metric.include_reason}\n",
    "                error['data'].append(errors_format_ins.copy())\n",
    "                print(errors_format_ins)\n",
    "                with open(error_file,'w') as f:\n",
    "                    json.dump(error,f,indent=4)\n",
    "                continue\n",
    "            metrics_format_ins['metric_metadata']['metric'] = metric.__name__\n",
    "            metrics_format_ins['metric_metadata']['score'] = metric.score\n",
    "            metrics_format_ins['metric_metadata']['success'] = metric.is_successful()\n",
    "            metrics_format_ins['metric_metadata']['reason'] = metric.reason\n",
    "            \n",
    "            metrics_format_ins['metric_metadata']['statements'] = getattr(metric,'statements','')\n",
    "            metrics_format_ins['metric_metadata']['verdicts'] = str(getattr(metric,'verdicts',''))\n",
    "            metrics_format_ins['metric_metadata']['evaluationCost'] = metric.evaluation_cost\n",
    "\n",
    "            metrics_format_ins['metric_configuration']['threshold'] = metric.threshold\n",
    "            metrics_format_ins['metric_configuration']['strict_mode'] = metric.strict_mode\n",
    "            metrics_format_ins['metric_configuration']['evaluation_model'] = metric.evaluation_model\n",
    "            metrics_format_ins['metric_configuration']['include_reason'] = metric.include_reason\n",
    "\n",
    "            data_format_ins['cached_metrics_data'].append(metrics_format_ins.copy())\n",
    "            flag = True\n",
    "            for each in save['data']:\n",
    "                if is_same_eval_item(each, data_format_ins):\n",
    "                    each['cached_metrics_data'].append(metrics_format_ins.copy())\n",
    "                    flag = False\n",
    "                    break\n",
    "            if flag:\n",
    "                save['data'].append(data_format_ins.copy())\n",
    "                print(data_format_ins)\n",
    "            with open(save_file,'w') as f:\n",
    "                json.dump(save,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinEvalErrorToData(errorFile:Union[str,Path],saveFile:Union[str,Path])->None:\n",
    "    \"\"\"_summary_\n",
    "        the function is used to rerun the error item in the `errorFile` and append the results into the `saveFile` \n",
    "        \n",
    "    Args:\n",
    "        `errorFile` (Union[str,Path]): the JSON file saves the error item in the before running\n",
    "        `saveFile` (Union[str,Path]): the JSON file saves the pass result\n",
    "        \n",
    "    Returns:\n",
    "        None: the result will override the original file \n",
    "    \"\"\"\n",
    "    def is_same_eval_item(x,item):\n",
    "        if x['id'] == item['id'] and x['input'] == item['input'] and x['actual_output'] == item['actual_output'] and x['AnswerModel'] == item['AnswerModel'] and x['expected_output'] == item['expected_output']:\n",
    "            return True\n",
    "        return False\n",
    "    with open(errorFile,'r') as f:\n",
    "        data_er = json.load(f)\n",
    "    with open(saveFile,'r') as f:\n",
    "        data_sv = json.load(f)\n",
    "    if data_er['fileName'] != data_sv['fileName']:\n",
    "        print(\"The save_file does not match the error_file!\")\n",
    "        return\n",
    "    error = {'fileName' :data_er['fileName'],'class':data_er['class'],'data':[]}\n",
    "    while data_er['data']:\n",
    "        item = data_er['data'].pop()\n",
    "        data_format_ins = {\n",
    "            'id':0,\n",
    "            'AnswerModel':'',\n",
    "            'input':'',\n",
    "            'actual_output':'',\n",
    "            'expected_output':None,\n",
    "            'context':None,\n",
    "            'retrieval_context':None,\n",
    "            'cached_metrics_data':[]\n",
    "        }\n",
    "        metrics_format_ins = {\n",
    "            'metric_metadata':{\n",
    "                'metric':None,\n",
    "                'success':True,\n",
    "                'score':0.8,\n",
    "                'reason':'',\n",
    "                'statements':'',\n",
    "                'verdicts':'',\n",
    "                'evaluationCost': 0\n",
    "            },\n",
    "            'metric_configuration': {\n",
    "                'threshold': 0.5,\n",
    "                'evaluation_model': 'CustomLLM',\n",
    "                'strict_mode': False,\n",
    "                'include_reason': True\n",
    "            }\n",
    "        }\n",
    "        errors_format_ins = {\n",
    "            'id':0,\n",
    "            'AnswerModel':'',\n",
    "            'input':'',\n",
    "            'actual_output':'',\n",
    "            'expected_output':None,\n",
    "            'retrieval_context':None,\n",
    "            'cached_metrics_data':[\n",
    "                {            \n",
    "                    'metric_metadata':{\n",
    "                        'metric':None,\n",
    "                    },\n",
    "                    'metric_configuration': {\n",
    "                        'threshold': 0.5,\n",
    "                        'evaluation_model': 'CustomLLM',\n",
    "                        'strict_mode': False,\n",
    "                        'include_reason': True\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        data_format_ins['id'] = item['id']\n",
    "        data_format_ins['AnswerModel'] = item['AnswerModel']\n",
    "        data_format_ins['input'] = item['input']\n",
    "        data_format_ins['actual_output'] = item['actual_output']\n",
    "        data_format_ins['expected_output'] = item['expected_output']\n",
    "        \n",
    "        tag = False\n",
    "        for x in data_sv['data']:\n",
    "            if is_same_eval_item(item,x):\n",
    "                for metric_data in x['cached_metrics_data']:\n",
    "                    if metric_data['metric_metadata']['metric'] == item['cached_metrics_data'][0]['metric_metadata']['metric']:\n",
    "                        if metric_data['metric_configuration']['threshold'] == item['cached_metrics_data'][0]['metric_configuration']['threshold'] and metric_data['metric_configuration']['evaluation_model'] == item['cached_metrics_data'][0]['metric_configuration']['evaluation_model'] and metric_data['metric_configuration']['strict_mode'] == item['cached_metrics_data'][0]['metric_configuration']['strict_mode'] and metric_data['metric_configuration']['include_reason'] == item['cached_metrics_data'][0]['metric_configuration']['include_reason']:\n",
    "                            tag = True\n",
    "                            print(\"HAVE:\")\n",
    "                            print(x)\n",
    "                            break\n",
    "        if tag:\n",
    "            continue\n",
    "        test_case = LLMTestCase(\n",
    "            input= item['input'],\n",
    "            actual_output=item['actual_output'],\n",
    "            context=[item['expected_output']],\n",
    "        )\n",
    "        if item['cached_metrics_data'][0]['metric_metadata']['metric'] == 'Answer Relevancy':\n",
    "            metric = AnswerRelevancyMetric(\n",
    "                threshold=item['cached_metrics_data'][0]['metric_configuration']['threshold'],\n",
    "                model = evaluateModel,\n",
    "                include_reason=item['cached_metrics_data'][0]['metric_configuration']['include_reason']\n",
    "            )\n",
    "        elif item['cached_metrics_data'][0]['metric_metadata']['metric'] == 'Hallucination':\n",
    "            metric = HallucinationMetric(\n",
    "                threshold=item['cached_metrics_data'][0]['metric_configuration']['threshold'],\n",
    "                model = evaluateModel,\n",
    "                include_reason=item['cached_metrics_data'][0]['metric_configuration']['include_reason']\n",
    "            )\n",
    "        else:\n",
    "            print(\"unkonwn metric!\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            metric.measure(test_case)\n",
    "        except Exception as e:\n",
    "            print(traceback.print_exc())\n",
    "            errors_format_ins['id'] = item['id']\n",
    "            errors_format_ins['AnswerModel'] = item['AnswerModel']\n",
    "            errors_format_ins['input'] = item['input']\n",
    "            errors_format_ins['actual_output'] = item['actual_output']\n",
    "            errors_format_ins['expected_output'] = item['expected_output']\n",
    "            errors_format_ins['cached_metrics_data'][0]['metric_metadata']['metric'] = metric.__name__\n",
    "            errors_format_ins['cached_metrics_data'][0]['metric_configuration'] = {'threshold':metric.threshold,'evaluation_model':metric.evaluation_model,'strict_mode':metric.strict_mode,'include_reason':metric.include_reason}\n",
    "            error['data'].append(errors_format_ins.copy())\n",
    "            print(errors_format_ins)\n",
    "            with open(errorFile,'w') as f:\n",
    "                json.dump(data_er,f,indent=4)\n",
    "            continue\n",
    "        metrics_format_ins['metric_metadata']['metric'] = metric.__name__\n",
    "        metrics_format_ins['metric_metadata']['score'] = metric.score\n",
    "        metrics_format_ins['metric_metadata']['success'] = metric.is_successful()\n",
    "        metrics_format_ins['metric_metadata']['reason'] = metric.reason\n",
    "        \n",
    "        metrics_format_ins['metric_metadata']['statements'] = getattr(metric,'statements','')\n",
    "        metrics_format_ins['metric_metadata']['verdicts'] = str(getattr(metric,'verdicts',''))\n",
    "        metrics_format_ins['metric_metadata']['evaluationCost'] = metric.evaluation_cost\n",
    "\n",
    "        metrics_format_ins['metric_configuration']['threshold'] = metric.threshold\n",
    "        metrics_format_ins['metric_configuration']['strict_mode'] = metric.strict_mode\n",
    "        metrics_format_ins['metric_configuration']['evaluation_model'] = metric.evaluation_model\n",
    "        metrics_format_ins['metric_configuration']['include_reason'] = metric.include_reason\n",
    "\n",
    "        data_format_ins['cached_metrics_data'].append(metrics_format_ins.copy())\n",
    "        flag = True\n",
    "        for each in data_sv['data']:\n",
    "            if is_same_eval_item(each, data_format_ins):\n",
    "                each['cached_metrics_data'].append(metrics_format_ins.copy())\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            data_sv['data'].append(data_format_ins.copy())\n",
    "            print(data_format_ins)\n",
    "        with open(saveFile,'w') as f:\n",
    "            json.dump(data_sv,f,indent=4)\n",
    "    \n",
    "    with open(errorFile,'w') as f:\n",
    "        json.dump(error,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fileName': '2-5_DocRED_sample.json',\n",
       " 'class': 'Knowledge Understanding',\n",
       " 'data': [{'id': 1103,\n",
       "   'AnswerModel': 'baichuan2-13b-base',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:Brian McGuinness\\nText: entity0 Brian McGuinness entity0 ( born entity0 Bernard Francis McGuinness entity0 , entity1 22 October 1927 entity1 , in entity2 Wrexham entity2 , entity3 United Kingdom entity3 ) is a entity4 British entity4 philosopher . \\n Formerly a pupil of entity5 RM Hare entity5 , entity6 McGuinness entity6 has become a noted expert in the works of entity7 Ludwig Wittgenstein entity7 . \\n entity6 McGuinness entity6 was a Fellow and Tutor at entity8 Queen 's College entity8 in entity9 Oxford University entity9 from entity10 1953 entity10 to entity11 1988 entity11 , and took a post at the entity12 Netherlands Institute for Advanced Study entity12 . \\n Since entity13 1990 entity13 , he is a professor at the entity14 University of Siena entity14 , entity15 Italy entity15 . \\n From entity13 1990 entity13 to entity16 1993 entity16 , he was director of the faculty of philosophy and social sciences of this university . \\n During his time at entity17 Queen 's entity17 , he was an invited speaker at the entity18 Oxford Socratic Club entity18 , speaking with entity19 J. D. Mabbott entity19 on ` entity20 The Problem of Free Will entity20 ` on entity21 Nov. 14 , 1955 entity21 . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': ' \\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\n',\n",
       "   'expected_output': '(entity0,date of birth,entity1)\\n(entity0,place of birth,entity2)\\n(entity0,country of citizenship,entity3)\\n(entity2,country,entity3)\\n(entity8,country,entity3)\\n(entity8,part of,entity9)\\n(entity14,country,entity15)\\n(entity6,date of birth,entity1)\\n(entity6,place of birth,entity2)\\n(entity6,country of citizenship,entity3)\\n(entity9,has part,entity8)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 2244,\n",
       "   'AnswerModel': 'baichuan2-13b-chat',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:Jakarta International Film Festival\\nText: The entity0 Jakarta International Film Festival entity0 ( entity1 JIFFEST entity1 ) is the major film festival of entity2 Indonesia entity2 held every entity3 December entity3 in the capital , entity4 Jakarta entity4 , since entity5 1999 entity5 . \\n The number of entity6 Indonesian entity6 films shown at the festival had grown from entity7 four entity7 in entity5 1999 entity5 to around entity8 100 entity8 by entity9 2009 entity9 . \\n Since entity10 2006 entity10 , entity1 JIFFEST entity1 has hosted an entity6 Indonesian entity6 Feature Film Competition with foreign film professionals acting as juries . \\n entity1 JIFFEST entity1 's script development competition and workshop winners include entity11 Wahyu Aditya entity11 ( entity12 2004 entity12 ) , entity13 World Champion International Young Creative Entrepreneur of the Year entity13 ( entity14 2007 entity14 ) ; entity15 Tumpal Tampubolon entity15 ( entity16 2005 entity16 ) , entity17 Asian Young Filmmakers Fellow Korea entity17 ( entity18 2008 entity18 ) ; entity19 Salman Aristo entity19 ( entity10 2006 entity10 ) , writer of entity20 Ayat - Ayat Cinta entity20 ( entity14 2007 entity14 ) , entity21 Laskar Pelangi entity21 ( entity18 2008 entity18 ) , and entity22 Garuda di Dadaku entity22 ( entity9 2009 entity9 ) ; entity23 Yuli Andari Merdekaningtyas entity23 ( entity10 2006 entity10 ) , and director of entity24 Suster Apung entity24 , winner of entity25 Eagle Awards Metro TV entity25 ( entity10 2006 entity10 ) . \\n The festival is on a shaky financial footing and is hoping to continue by switching its funding source from foreign donors to government grants and private donations . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': 'In the text above, the following relations are present:\\n\\n1. head of government - Indonesia\\n2. country - Indonesia\\n3. place of birth - unknown (probably not applicable to entities in this case)\\n4. place of death - unknown (probably not applicable to entities in this case)\\n5. father - unknown (probably not applicable to entities in this case)\\n6. mother - unknown (probably not applicable to entities in this case)\\n7. spouse - unknown (probably not applicable to entities in this case)\\n8. country of citizenship - Indonesia\\n9. continent - Asia\\n10. instance of - film festival\\n11. head of state - unknown (probably not applicable to entities in this case)\\n12. capital - Jakarta\\n13. official language - Indonesian\\n14. position held - writer, director, etc. (not applicable to the entity Jakarta International Film Festival)\\n15. child - unknown (probably not applicable to entities in this case)\\n16. author - unknown (probably not applicable to entities in this case)\\n17. member of sports team - unknown (probably not applicable to entities in this case)\\n18. director - unknown (probably not applicable to entities in this case)\\n19. screenwriter - unknown (probably not applicable to entities in this case)\\n20. educated at - unknown (probably not applicable to entities in this case)\\n21. composer - unknown (probably not applicable to entities in this case)\\n22. member of political party - unknown (probably not applicable to entities in this case)\\n23. employer - unknown (probably not applicable to entities in this case)\\n24. founded by - unknown (probably not applicable to entities in this case)\\n25. league - unknown (probably not applicable to entities in this case)\\n26. publisher - unknown (probably not applicable to entities in this case)\\n27. owned by - unknown (probably not applicable to entities in this case)\\n28. located in the administrative territorial entity - Indonesia\\n29. genre - film festival\\n30. operator - unknown (probably not applicable to entities in this case)\\n31. religion - unknown (probably not applicable to entities in this case)\\n32. contains administrative territorial entity - Indonesia\\n33. follows - unknown (probably not applicable to entities in this case)\\n34. followed by - unknown (probably not applicable to entities in this case)\\n35. headquarters location - Jakarta\\n36. cast member - unknown (probably not applicable to entities in this case)\\n37. producer - unknown (probably not applicable to entities in this case)\\n38. award received - unknown (probably not applicable to entities in this case)\\n39. creator - unknown (probably not applicable to entities in this case)\\n40. parent taxon - unknown (probably not applicable to entities in this case)\\n41. ethnic group - unknown (probably not applicable to entities in this case)\\n42. performer - unknown (probably not applicable to entities in this case)\\n43. manufacturer - unknown (probably not applicable to entities in this case)\\n44. developer - unknown (probably not applicable to entities in this case)\\n45. series - unknown (probably not applicable to entities in this case)\\n46. sister city - unknown (probably not applicable to entities in this case)\\n47. legislative body - unknown (probably not applicable to entities in this case)\\n48. basin country - unknown (probably not applicable to entities in this case)\\n49. located in or next to body of water - unknown (probably not applicable to entities in this case)\\n50. military branch - unknown (probably not applicable to entities in this case)\\n51. record label - unknown (probably not applicable to entities in this case)\\n52. production company - unknown (probably not applicable to entities in this case)\\n53. location - Jakarta\\n54. subclass of - unknown (probably not applicable to entities in this case)\\n55. subsidiary - unknown (probably not applicable to entities in this case)\\n56. part of - unknown (probably not applicable to entities in this case)\\n57. original language of work - unknown (probably not applicable to entities in this case)\\n58. platform - unknown (probably not applicable to entities in this case)\\n59. mouth of the watercourse - unknown (probably not applicable to entities in this case)\\n60. original network - unknown (probably not applicable to entities in this case)\\n61. member of - unknown (probably not applicable to entities in this case)\\n62. chairperson - unknown (probably not applicable to entities in this case)\\n63. country of origin - unknown (probably not applicable to entities in this case)\\n64. has part - unknown (probably not applicable to entities in this case)\\n65. residence - unknown (probably not applicable to entities in this case)\\n66. date of birth - unknown (probably not applicable to entities in this case)\\n67. date of death - unknown (probably not applicable to entities in this case)\\n68. inception - 1999\\n69. dissolved, abolished or demolished - unknown (probably not applicable to entities in this case)\\n70. publication date - unknown (probably not applicable to entities in this case)\\n71. start time - unknown (probably not applicable to entities in this case)\\n72. end time - unknown (probably not applicable to entities in this case)\\n73. point in time - unknown (probably not applicable to entities in this case)\\n74. conflict - unknown (probably not applicable to entities in this case)\\n75. characters - unknown (probably not applicable to entities in this case)\\n76. lyrics by - unknown (probably not applicable to entities in this case)\\n77. located on terrain feature - unknown (probably not applicable to entities in this case)\\n78. participant - unknown (probably not applicable to entities in this case)\\n79. influenced by - unknown (probably not applicable to entities in this case)\\n80. location of formation - unknown (probably not applicable to entities in this case)\\n81. parent organization - unknown (probably not applicable to entities in this case)\\n82. notable work - unknown (probably not applicable to entities in this case)\\n83. separated from - unknown (probably not applicable to entities in this case)\\n84. narrative location - unknown (probably not applicable to entities in this case)\\n85. work location - unknown (probably not applicable to entities in this case)\\n86. applies to jurisdiction - unknown (probably not applicable to entities in this case)\\n87. product or material produced - unknown (probably not applicable to entities in this case)\\n88. unemployment rate - unknown (probably not applicable to entities in this case)\\n89. territory claimed by - unknown (probably not applicable to entities in this case)\\n90. participant of - unknown (probably not applicable to entities in this case)\\n91. replaces - unknown (probably not applicable to entities in this case)\\n92. replaced by - unknown (probably not applicable to entities in this case)\\n93. capital of - unknown (probably not applicable to entities in this case)\\n94. languages spoken - unknown (probably not applicable to entities in this case)\\n95. written or signed - unknown (probably not applicable to entities in this case)\\n96. present in work - unknown (probably not applicable to entities in this case)\\n97. sibling - unknown (probably not applicable to entities in this case) ',\n",
       "   'expected_output': '(entity2,capital,entity4)\\n(entity2,contains administrative territorial entity,entity4)\\n(entity4,capital of,entity2)\\n(entity4,country,entity2)\\n(entity4,located in the administrative territorial entity,entity2)\\n(entity4,country,entity6)\\n(entity4,located in the administrative territorial entity,entity6)\\n(entity4,capital of,entity6)\\n(entity0,country,entity2)\\n(entity0,inception,entity5)\\n(entity0,country,entity6)\\n(entity6,capital,entity4)\\n(entity6,contains administrative territorial entity,entity4)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 2244,\n",
       "   'AnswerModel': 'baichuan2-7b-chat',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:Jakarta International Film Festival\\nText: The entity0 Jakarta International Film Festival entity0 ( entity1 JIFFEST entity1 ) is the major film festival of entity2 Indonesia entity2 held every entity3 December entity3 in the capital , entity4 Jakarta entity4 , since entity5 1999 entity5 . \\n The number of entity6 Indonesian entity6 films shown at the festival had grown from entity7 four entity7 in entity5 1999 entity5 to around entity8 100 entity8 by entity9 2009 entity9 . \\n Since entity10 2006 entity10 , entity1 JIFFEST entity1 has hosted an entity6 Indonesian entity6 Feature Film Competition with foreign film professionals acting as juries . \\n entity1 JIFFEST entity1 's script development competition and workshop winners include entity11 Wahyu Aditya entity11 ( entity12 2004 entity12 ) , entity13 World Champion International Young Creative Entrepreneur of the Year entity13 ( entity14 2007 entity14 ) ; entity15 Tumpal Tampubolon entity15 ( entity16 2005 entity16 ) , entity17 Asian Young Filmmakers Fellow Korea entity17 ( entity18 2008 entity18 ) ; entity19 Salman Aristo entity19 ( entity10 2006 entity10 ) , writer of entity20 Ayat - Ayat Cinta entity20 ( entity14 2007 entity14 ) , entity21 Laskar Pelangi entity21 ( entity18 2008 entity18 ) , and entity22 Garuda di Dadaku entity22 ( entity9 2009 entity9 ) ; entity23 Yuli Andari Merdekaningtyas entity23 ( entity10 2006 entity10 ) , and director of entity24 Suster Apung entity24 , winner of entity25 Eagle Awards Metro TV entity25 ( entity10 2006 entity10 ) . \\n The festival is on a shaky financial footing and is hoping to continue by switching its funding source from foreign donors to government grants and private donations . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': 'In the above text, the following relations are present:\\n\\n- country: Indonesia\\n- place of birth: Indonesia\\n- head of government: -\\n- country of citizenship: Indonesia\\n- capital: Jakarta\\n- legislative body: -\\n- official language: Indonesian\\n- position held: -\\n- parent taxon: -\\n- ethnic group: -\\n- employer: -\\n- founded by: -\\n- headquartered in: Jakarta\\n- follows: -\\n- followed by: -\\n- producer: -\\n- screenwriter: -\\n- composer: -\\n- member of political party: -\\n- publisher: -\\n- owner: -\\n- contains administrative territorial entity: -\\n- located in the administrative territorial entity: Indonesia\\n- genre: -\\n- operator: -\\n- religion: -\\n- contains administrative territorial entity: -\\n- follows: -\\n- followed by: -\\n- headquarters location: Jakarta\\n- cast member: -\\n- producer: -\\n- award received: -\\n- creator: -\\n- parent taxon: -\\n- ethnic group: -\\n- performer: -\\n- manufacturer: -\\n- developer: -\\n- series: -\\n- sister city: -\\n- legislative body: -\\n- basin country: -\\n- located in or next to body of water: -\\n- military branch: -\\n- record label: -\\n- production company: -\\n- location: -\\n- subclass of: -\\n- subsidiary: -\\n- part of: -\\n- original language of work: -\\n- platform: -\\n- mouth of the watercourse: -\\n- original network: -\\n- member of: -\\n- chairperson: -\\n- country of origin: -\\n- has part: -\\n- residence: -\\n- date of birth: -\\n- date of death: -\\n- inception: -\\n- dissolved: -\\n- abolished or demolished: -\\n- publication date: -\\n- start time: -\\n- end time: -\\n- point in time: -\\n- conflict: -\\n- characters: -\\n- lyrics by: -\\n- located on terrain feature: -\\n- participant: -\\n- influenced by: -\\n- location of formation: -\\n- parent organization: -\\n- notable work: -\\n- separated from: -\\n- narrative location: -\\n- work location: -\\n- applies to jurisdiction: -\\n- product or material produced: -\\n- unemployment rate: -\\n- territory claimed by: -\\n- participant of: -\\n- replaces: -\\n- replaced by: - ',\n",
       "   'expected_output': '(entity2,capital,entity4)\\n(entity2,contains administrative territorial entity,entity4)\\n(entity4,capital of,entity2)\\n(entity4,country,entity2)\\n(entity4,located in the administrative territorial entity,entity2)\\n(entity4,country,entity6)\\n(entity4,located in the administrative territorial entity,entity6)\\n(entity4,capital of,entity6)\\n(entity0,country,entity2)\\n(entity0,inception,entity5)\\n(entity0,country,entity6)\\n(entity6,capital,entity4)\\n(entity6,contains administrative territorial entity,entity4)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 2700,\n",
       "   'AnswerModel': 'baichuan2-7b-chat',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:List of companies of France\\nText: entity0 France entity0 is a country whose territory consists of metropolitan entity0 France entity0 in western entity1 Europe entity1 , as well as several overseas regions and territories . \\n A member of the entity2 Group of 7 entity2 ( formerly entity3 G8 entity3 ) leading industrialised countries , , it is ranked as the world 's ninth - largest and the entity4 EU entity4 's second - largest economy by purchasing power parity . \\n With entity5 31 entity5 of the entity6 500 entity6 biggest companies in the world in entity7 2015 entity7 , entity0 France entity0 ranks fourth in the entity8 Fortune Global 500 entity8 , ahead of entity9 Germany entity9 and the entity10 UK entity10 . \\n According to the entity11 World Trade Organization entity11 ( entity11 WTO entity11 ) , in entity12 2009 entity12 entity0 France entity0 was the world 's sixth - largest exporter and the fourth - largest importer of manufactured goods . \\n entity13 French entity13 companies have maintained key positions in the insurance and banking industries : entity14 AXA entity14 is the world 's largest insurance company . \\n The leading entity13 French entity13 banks are entity15 BNP Paribas entity15 and the entity16 Crédit Agricole entity16 , ranking as the world 's largest and sixth - largest banks in entity17 2010 entity17 ( by assets ) , while the entity18 Société Générale entity18 group was ranked the world 's eighth - largest in entity12 2009 entity12 . \\n For further information on the types of business entities in this country and their abbreviations , see ` entity19 Business entities in France entity19 ` . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': 'head of government, country, country of citizenship, capital, official language, position held, member of political party, employer, founder of, followed by, director, screenwriter, composer, creator, producer, author, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling ',\n",
       "   'expected_output': '(entity0,continent,entity1)\\n(entity0,member of,entity3)\\n(entity0,member of,entity4)\\n(entity0,member of,entity11)\\n(entity0,member of,entity14)\\n(entity3,participant,entity0)\\n(entity4,contains administrative territorial entity,entity0)\\n(entity15,country,entity0)\\n(entity16,country,entity0)\\n(entity18,country,entity0)\\n(entity2,participant,entity0)\\n(entity2,replaced by,entity3)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 149,\n",
       "   'AnswerModel': 'baichuan2-7b-chat',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:Have You Ever Been in Love (song)\\nText: ` entity0 Have You Ever Been in Love entity0 ` is a song recorded by entity1 Canadian entity1 recording artist entity2 Celine Dion entity2 , included first on her seventh entity3 English entity3 studio album entity4 A New Day Has Come entity4 ( entity5 2002 entity5 ) and later , on her entity6 eight entity6 entity3 English entity3 studio album entity7 One Heart entity7 ( entity8 2003 entity8 ) . \\n The song is a power ballad , written by entity9 Anders Bagge entity9 , entity10 Peer Åström entity10 , entity11 Tom Nichols entity11 , entity12 Daryl Hall entity12 and entity13 Laila Bagge entity13 , while production was handled by entity14 Bagge & Peer entity14 . \\n ` entity0 Have You Ever Been in Love entity0 ` builds from a gentle , piano - laced opening into a theatrical , string - framed climax . \\n The song received acclaim from music critics , while being reviewed in both albums . \\n Many critics called it a classic - sounding ballad and one of the strongest cuts from the album . \\n Critics also noted similarities between entity2 Dion entity2 and entity15 Barbra Streisand entity15 . \\n ` entity0 Have You Ever Been in Love entity0 ` was released on entity16 14 April 2003 entity16 , as entity7 One Heart entity7 's second ( promotional only ) single in the entity17 United States entity17 and entity1 Canada entity1 , while on entity18 3 November 2003 entity18 , it was released as the third commercial single in selected entity19 European entity19 countries . \\n The song spent entity20 fourteen weeks entity20 at number 2 on the entity17 US entity17 entity21 Hot Adult Contemporary Tracks entity21 , setting a record for most weeks at the second position . \\n The music video was shot between entity22 29–30 April 2003 entity22 in entity23 Los Angeles entity23 and released on entity24 2 June 2003 entity24 . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': 'In the above text, the following relationships can be extracted:\\n\\n1. country: Canada\\n2. artist: Celine Dion\\n3. album: A New Day Has Come\\n4. song: Have You Ever Been in Love\\n5. studio album: One Heart\\n6. genre: power ballad\\n7. production team: Bagge & Peer\\n8. years: 2002 and 2003\\n9. album release date: 2002 and 2003\\n10. music video release date: 2003\\n11. special edition release date: 2003\\n12. single release date: 2003\\n13. music video location: Los Angeles\\n14. country of origin: Sweden\\n15. language: English\\n16. original language: Swedish\\n17. record label: Sony Music Entertainment\\n18. publisher: Sony BMG Music Entertainment\\n19. theater: Theatre St. Louis\\n20. theatre: Fox Theatre, St. Louis\\n21. theatre: Fox Theater, St. Louis\\n22. theatre: Fox St. Louis Theater\\n23. theatre: Fox Theatre in St. Louis\\n24. theatre: Fox St. Louis Theatre\\n25. theatre: Fox St. Louis, MO\\n26. theatre: Fox St. Louis, Missouri\\n27. theatre: Fox St. Louis, MO Theatre\\n28. theatre: Fox St. Louis, Missouri Theatre\\n29. theatre: Fox St. Louis, MO - Theatre\\n30. theatre: Fox St. Louis, MO Theatre -\\n\\nPlease note that some of these relationships may not be relevant to the specific context of the question. However, they were extracted from the text. ',\n",
       "   'expected_output': '(entity0,part of,entity4)\\n(entity0,part of,entity7)\\n(entity0,performer,entity2)\\n(entity0,publication date,entity16)\\n(entity4,publication date,entity5)\\n(entity4,followed by,entity7)\\n(entity4,performer,entity2)\\n(entity7,follows,entity4)\\n(entity7,performer,entity2)\\n(entity7,publication date,entity8)\\n(entity2,country of citizenship,entity1)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 1103,\n",
       "   'AnswerModel': 'baichuan2-7b-chat',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:Brian McGuinness\\nText: entity0 Brian McGuinness entity0 ( born entity0 Bernard Francis McGuinness entity0 , entity1 22 October 1927 entity1 , in entity2 Wrexham entity2 , entity3 United Kingdom entity3 ) is a entity4 British entity4 philosopher . \\n Formerly a pupil of entity5 RM Hare entity5 , entity6 McGuinness entity6 has become a noted expert in the works of entity7 Ludwig Wittgenstein entity7 . \\n entity6 McGuinness entity6 was a Fellow and Tutor at entity8 Queen 's College entity8 in entity9 Oxford University entity9 from entity10 1953 entity10 to entity11 1988 entity11 , and took a post at the entity12 Netherlands Institute for Advanced Study entity12 . \\n Since entity13 1990 entity13 , he is a professor at the entity14 University of Siena entity14 , entity15 Italy entity15 . \\n From entity13 1990 entity13 to entity16 1993 entity16 , he was director of the faculty of philosophy and social sciences of this university . \\n During his time at entity17 Queen 's entity17 , he was an invited speaker at the entity18 Oxford Socratic Club entity18 , speaking with entity19 J. D. Mabbott entity19 on ` entity20 The Problem of Free Will entity20 ` on entity21 Nov. 14 , 1955 entity21 . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': 'The relationship between the person and the philosopher is `is a`. The relationship between the person and the university is `is a faculty of`. The relationship between the person and the institution is `is a director of`. The relationship between the person and the place is `was born in`. The relationship between the person and the year is `was born in`. The relationship between the person and the place is `was born in`. The relationship between the person and the year is `was born in`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. The relationship between the person and the institution is `was a Fellow and Tutor at`. ',\n",
       "   'expected_output': '(entity0,date of birth,entity1)\\n(entity0,place of birth,entity2)\\n(entity0,country of citizenship,entity3)\\n(entity2,country,entity3)\\n(entity8,country,entity3)\\n(entity8,part of,entity9)\\n(entity14,country,entity15)\\n(entity6,date of birth,entity1)\\n(entity6,place of birth,entity2)\\n(entity6,country of citizenship,entity3)\\n(entity9,has part,entity8)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 2700,\n",
       "   'AnswerModel': 'infini-megrez-7b',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:List of companies of France\\nText: entity0 France entity0 is a country whose territory consists of metropolitan entity0 France entity0 in western entity1 Europe entity1 , as well as several overseas regions and territories . \\n A member of the entity2 Group of 7 entity2 ( formerly entity3 G8 entity3 ) leading industrialised countries , , it is ranked as the world 's ninth - largest and the entity4 EU entity4 's second - largest economy by purchasing power parity . \\n With entity5 31 entity5 of the entity6 500 entity6 biggest companies in the world in entity7 2015 entity7 , entity0 France entity0 ranks fourth in the entity8 Fortune Global 500 entity8 , ahead of entity9 Germany entity9 and the entity10 UK entity10 . \\n According to the entity11 World Trade Organization entity11 ( entity11 WTO entity11 ) , in entity12 2009 entity12 entity0 France entity0 was the world 's sixth - largest exporter and the fourth - largest importer of manufactured goods . \\n entity13 French entity13 companies have maintained key positions in the insurance and banking industries : entity14 AXA entity14 is the world 's largest insurance company . \\n The leading entity13 French entity13 banks are entity15 BNP Paribas entity15 and the entity16 Crédit Agricole entity16 , ranking as the world 's largest and sixth - largest banks in entity17 2010 entity17 ( by assets ) , while the entity18 Société Générale entity18 group was ranked the world 's eighth - largest in entity12 2009 entity12 . \\n For further information on the types of business entities in this country and their abbreviations , see ` entity19 Business entities in France entity19 ` . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': \" entity0 is a country, and entity1 entity2 is the capital city of entity0 France entity1. Both entity0 and entity2 are entities within the predefined set of entities. The capital city is a location, which follows various guidelines for what constitutes a capital city within the predefined set of relations.\\n\\nThe entity0 's territory consists of entity3 France entity3 , which is a collection of various administrative entities known as territories. France has several overseas regions and territories that are entities within the predefined set, although they are not located in the predefined set of relations.\\n\\nentity4 is a leading industrialised country, entity5 (31 entity6) is the size of the entity4 's economy in terms of purchasing power parity, and entity7 entity8 is the date ( entity9 for Germany entity9 and entity10 for the entity10 ) in entity10 's global rank based on entity11 Fortune Global 500 entity11 . France ranks in entity12 2015 entity12 .\\n\\nThe entity13 and entity14 are a pair of the world 's largest exporter and importer of manufactured goods, and entity15 and entity16 are the leading French banks in entity17 2010 entity17 rankings. The entity18 entity18 is a French bank or financial institution, and entity19 is a category of business entities in France.\\n\\nFor a complete list of French companies, we do not have the complete set of entities included in the predefined set of relations provided. The provided text is not exhaustive, and additional entities are not included to ensure the full range of entities in the real world that are relevant to the question of business entities in France.\",\n",
       "   'expected_output': '(entity0,continent,entity1)\\n(entity0,member of,entity3)\\n(entity0,member of,entity4)\\n(entity0,member of,entity11)\\n(entity0,member of,entity14)\\n(entity3,participant,entity0)\\n(entity4,contains administrative territorial entity,entity0)\\n(entity15,country,entity0)\\n(entity16,country,entity0)\\n(entity18,country,entity0)\\n(entity2,participant,entity0)\\n(entity2,replaced by,entity3)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 149,\n",
       "   'AnswerModel': 'infini-megrez-7b',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:Have You Ever Been in Love (song)\\nText: ` entity0 Have You Ever Been in Love entity0 ` is a song recorded by entity1 Canadian entity1 recording artist entity2 Celine Dion entity2 , included first on her seventh entity3 English entity3 studio album entity4 A New Day Has Come entity4 ( entity5 2002 entity5 ) and later , on her entity6 eight entity6 entity3 English entity3 studio album entity7 One Heart entity7 ( entity8 2003 entity8 ) . \\n The song is a power ballad , written by entity9 Anders Bagge entity9 , entity10 Peer Åström entity10 , entity11 Tom Nichols entity11 , entity12 Daryl Hall entity12 and entity13 Laila Bagge entity13 , while production was handled by entity14 Bagge & Peer entity14 . \\n ` entity0 Have You Ever Been in Love entity0 ` builds from a gentle , piano - laced opening into a theatrical , string - framed climax . \\n The song received acclaim from music critics , while being reviewed in both albums . \\n Many critics called it a classic - sounding ballad and one of the strongest cuts from the album . \\n Critics also noted similarities between entity2 Dion entity2 and entity15 Barbra Streisand entity15 . \\n ` entity0 Have You Ever Been in Love entity0 ` was released on entity16 14 April 2003 entity16 , as entity7 One Heart entity7 's second ( promotional only ) single in the entity17 United States entity17 and entity1 Canada entity1 , while on entity18 3 November 2003 entity18 , it was released as the third commercial single in selected entity19 European entity19 countries . \\n The song spent entity20 fourteen weeks entity20 at number 2 on the entity17 US entity17 entity21 Hot Adult Contemporary Tracks entity21 , setting a record for most weeks at the second position . \\n The music video was shot between entity22 29–30 April 2003 entity22 in entity23 Los Angeles entity23 and released on entity24 2 June 2003 entity24 . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': \" 1. Head of Government: The text `entity0 is the head of government entity0` states that the person mentioned is the head of the government or government administration of entity0.\\n2. Country: The text mentions `entity0 is from entity0` or `entity0 is a country entity0` indicating that entity0 is a citizen or inhabitant of entity0, the country in which they reside.\\n3. Place of Birth: The text mentions the place entity0 was born in, e.g., `entity0 was born in entity0` or `entity0 was born in entity0`.\\n4. Place of Death: Similar to place of birth, the text states where entity0 died, e.g., `entity0 died in entity0` or `entity0 passed away in entity0`.\\n5. Father: In the context of the text, `entity0 is the father of entity1` indicates that entity0 is the biological father of entity1.\\n6. Mother: The text states, e.g., `entity0 is the mother of entity2` or `entity0 is the mother of entity3` if entity0 is the biological mother of entity2 or entity3.\\n7. Spouse: If entity0 is the marital spouse of entity1, the text indicates this, e.g., `entity0 is the spouse of entity1` or `entity0 is entity1's spouse`.\\n8. Country of Citizenship: The text states entity0 is a citizen or inhabitant of the country in which they reside, i.e., `entity0 is a citizen of entity4` or `entity0 is from entity4`.\\n9. Continent: The text would mention the continent if entity0 is associated with a particular continent, e.g., `entity0 is from entity4 on entity5`.\\n10. Instance of: The text would use this relation if entity0 is an instance of entity6, i.e., `entity0 is an entity7 instance8` or `entity0 is an entity7 instance9`.\\n11. Head of State: The text states entity0 holds the office of head of state or government, e.g., `entity0 is the head of state entity0` or `entity0 is head of entity0`.\\n12. Capital: If entity0 is the capital city of a country, the text would mention the capital city, e.g., `entity0 is the capital of entity0` or `entity0 is entity0's capital`.\\n13. Official Language: The text would state the official language entity0 speaks, e.g., `entity0 speaks entity1 language` or `entity0 is fluent in entity2 language`.\\n14. Position Held: The text would indicate the position entity0 holds, e.g., `entity0 holds the position of entity10` or `entity0 is an entity11`.\\n15. Child: The text would state that entity0 is the biological child of entity1, e.g., `entity0 is the child of entity2` or `entity0 is the offspring of entity3`.\\n16. Author: The text would mention if entity0 is an author or has written books, e.g., `entity0 is a published author` or `entity0 is an author of books`.\\n17. Member of Political Party: The text states if entity0 belongs to or is affiliated with entity1 political party, e.g., `entity0 is a member of entity2 political party` or `entity0 aligns herself with entity3`.\\n18. Employer: The text states entity0 is employed by entity3 or another entity4, e.g., `entity0 works for entity5` or `entity0 is employed by entity6`.\\n19. Founded By: If entity0 founded entity7, the text would state that entity0 founded entity7, e.g., `entity0 founded entity8` or `entity0 established entity9`.\\n20. League: The text would state if entity0 is affiliated with entity1 league or organization, e.g., `entity0 is affiliated with entity2 league` or `entity0 belongs to entity3`.\\n21. Publisher: If entity0 is associated with entity1 publisher, the text would mention the publisher, e.g., `entity0 is affiliated with entity2 publisher` or `entity0 is represented by entity3`.\\n22. Owned By: The text would state if entity0 is owned by entity1 or another entity2, e.g., `entity0 is owned by entity3` or `entity0 is entity4 property`.\\n23. Located In The Administrative Territorial Entity: The text would mention the administrative territory or region over which entity0 is located, e.g., `entity0 is located in entity5` or `entity0 is entity6 area`.\\n24. Genre: The text would mention the genre if it is a particular genre in which entity0 is associated, e.g., `entity0 belongs to entity7 genre` or `entity0 is part of entity8 genre`.\\n25. Operator: If entity0 is a part of an operation, the text would mention the operator or process, e.g., `entity0 is an operator of entity9`.\\n26. Religion: The text would state the religion or spiritual beliefs of entity0, e.g., `entity0 practices entity1 religion` or `entity0 adheres to entity2 faith`.\\n27. Contains Administrative Territorial Entity: The text would state if entity0 contains or houses entity1, e.g., `entity0 contains entity2` or `entity0 encompasses entity3`.\\n28. Follows: The text would indicate if entity0 follows or is followed by entity4, e.g., `entity0 is followed by entity5` or `entity0 is the one following entity6`.\\n29. Followed By: The text would state if entity0 is followed by entity7, e.g., `entity0 is the one followed by entity8` or `entity0 is entity9 successor`.\\n30. Head Of State: The text would state if entity0 holds the office of head of state or government, e.g., `entity0 is the head of state entity0` or `entity0 is head of entity1`.\",\n",
       "   'expected_output': '(entity0,part of,entity4)\\n(entity0,part of,entity7)\\n(entity0,performer,entity2)\\n(entity0,publication date,entity16)\\n(entity4,publication date,entity5)\\n(entity4,followed by,entity7)\\n(entity4,performer,entity2)\\n(entity7,follows,entity4)\\n(entity7,performer,entity2)\\n(entity7,publication date,entity8)\\n(entity2,country of citizenship,entity1)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 2700,\n",
       "   'AnswerModel': 'llama-2-13b-chat',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:List of companies of France\\nText: entity0 France entity0 is a country whose territory consists of metropolitan entity0 France entity0 in western entity1 Europe entity1 , as well as several overseas regions and territories . \\n A member of the entity2 Group of 7 entity2 ( formerly entity3 G8 entity3 ) leading industrialised countries , , it is ranked as the world 's ninth - largest and the entity4 EU entity4 's second - largest economy by purchasing power parity . \\n With entity5 31 entity5 of the entity6 500 entity6 biggest companies in the world in entity7 2015 entity7 , entity0 France entity0 ranks fourth in the entity8 Fortune Global 500 entity8 , ahead of entity9 Germany entity9 and the entity10 UK entity10 . \\n According to the entity11 World Trade Organization entity11 ( entity11 WTO entity11 ) , in entity12 2009 entity12 entity0 France entity0 was the world 's sixth - largest exporter and the fourth - largest importer of manufactured goods . \\n entity13 French entity13 companies have maintained key positions in the insurance and banking industries : entity14 AXA entity14 is the world 's largest insurance company . \\n The leading entity13 French entity13 banks are entity15 BNP Paribas entity15 and the entity16 Crédit Agricole entity16 , ranking as the world 's largest and sixth - largest banks in entity17 2010 entity17 ( by assets ) , while the entity18 Société Générale entity18 group was ranked the world 's eighth - largest in entity12 2009 entity12 . \\n For further information on the types of business entities in this country and their abbreviations , see ` entity19 Business entities in France entity19 ` . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': '  Sure! Here are the relations in the predefined set of relations found in the text:\\n\\nformat: (<entity_ID>, relation, <entity_ID>)\\n\\n1. (France, head of government, none)\\n2. (France, country, none)\\n3. (France, place of birth, none)\\n4. (France, place of death, none)\\n5. (France, father, none)\\n6. (France, mother, none)\\n7. (France, spouse, none)\\n8. (France, country of citizenship, none)\\n9. (France, continent, Europe)\\n10. (France, instance of, country)\\n11. (France, head of state, none)\\n12. (France, capital, Paris)\\n13. (France, official language, French)\\n14. (France, position held, member of the Group of 7)\\n15. (France, child, none)\\n16. (France, author, none)\\n17. (France, member of sports team, none)\\n18. (France, director, none)\\n19. (France, screenwriter, none)\\n20. (France, educated at, none)\\n21. (France, composer, none)\\n22. (France, member of political party, none)\\n23. (France, employer, none)\\n24. (France, founded by, none)\\n25. (France, league, none)\\n26. (France, publisher, none)\\n27. (France, owned by, none)\\n28. (France, located in the administrative territorial entity, metropolitan France)\\n29. (France, genre, none)\\n30. (France, operator, none)\\n31. (France, religion, none)\\n32. (France, contains administrative territorial entity, overseas regions and territories)\\n33. (France, follows, none)\\n34. (France, followed by, none)\\n35. (France, headquarters location, Paris)\\n36. (France, cast member, none)\\n37. (France, producer, none)\\n38. (France, award received, none)\\n39. (France, creator, none)\\n40. (France, parent taxon, none)\\n41. (France, ethnic group, none)\\n42. (France, performer, none)\\n43. (France, manufacturer, none)\\n44. (France, developer, none)\\n45. (France, series, none)\\n46. (France, sister city, none)\\n47. (France, legislative body, none)\\n48. (France, basin country, none)\\n49. (France, located in or next to body of water, none)\\n50. (France, military branch, none)\\n51. (France, record label, none)\\n52. (France, production company, none)\\n53. (France, location, metropolitan France)\\n54. (France, subclass of, country)\\n55. (France, subsidiary, none)\\n56. (France, part of, the Group of 7)\\n57. (France, original language of work, French)\\n58. (France, platform, none)\\n59. (France, mouth of the watercourse, none)\\n60. (France, original network, none)\\n61. (France, member of, the EU)\\n62. (France, notable work, none)\\n63. (France, separated from, none)\\n64. (France, narrative location, none)\\n65. (France, work location, Paris)\\n66. (France, applies to jurisdiction, metropolitan France)\\n67. (France, product or material produced, none)\\n68. (France, unemployment rate, none)\\n69. (France, territory claimed by, none)\\n70. (France, participant of, the Group of 20)\\n71. (France, replaces, none)\\n72. (France, replaced by, none)\\n73. (France, capital of, Paris)\\n74. (France, languages spoken, French)\\n75. (France, written or signed, none)\\n76. (France, present in work, none)\\n77. (France, sibling, none)\\n\\nNote that there are no relations found in the text that correspond to the predefined set of relations `parent organization`, `influenced by`, `location of formation`, `notable work`, `separated from`, `narrative location`, `work location`, `applies to jurisdiction`, `product or material produced`, `unemployment rate`, `territory claimed by`, `participant of`, `replaces`, `replaced by`, `capital of`, `languages spoken`, `written or signed`, `present in work`, `sibling`.',\n",
       "   'expected_output': '(entity0,continent,entity1)\\n(entity0,member of,entity3)\\n(entity0,member of,entity4)\\n(entity0,member of,entity11)\\n(entity0,member of,entity14)\\n(entity3,participant,entity0)\\n(entity4,contains administrative territorial entity,entity0)\\n(entity15,country,entity0)\\n(entity16,country,entity0)\\n(entity18,country,entity0)\\n(entity2,participant,entity0)\\n(entity2,replaced by,entity3)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 149,\n",
       "   'AnswerModel': 'llama-2-13b-chat',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:Have You Ever Been in Love (song)\\nText: ` entity0 Have You Ever Been in Love entity0 ` is a song recorded by entity1 Canadian entity1 recording artist entity2 Celine Dion entity2 , included first on her seventh entity3 English entity3 studio album entity4 A New Day Has Come entity4 ( entity5 2002 entity5 ) and later , on her entity6 eight entity6 entity3 English entity3 studio album entity7 One Heart entity7 ( entity8 2003 entity8 ) . \\n The song is a power ballad , written by entity9 Anders Bagge entity9 , entity10 Peer Åström entity10 , entity11 Tom Nichols entity11 , entity12 Daryl Hall entity12 and entity13 Laila Bagge entity13 , while production was handled by entity14 Bagge & Peer entity14 . \\n ` entity0 Have You Ever Been in Love entity0 ` builds from a gentle , piano - laced opening into a theatrical , string - framed climax . \\n The song received acclaim from music critics , while being reviewed in both albums . \\n Many critics called it a classic - sounding ballad and one of the strongest cuts from the album . \\n Critics also noted similarities between entity2 Dion entity2 and entity15 Barbra Streisand entity15 . \\n ` entity0 Have You Ever Been in Love entity0 ` was released on entity16 14 April 2003 entity16 , as entity7 One Heart entity7 's second ( promotional only ) single in the entity17 United States entity17 and entity1 Canada entity1 , while on entity18 3 November 2003 entity18 , it was released as the third commercial single in selected entity19 European entity19 countries . \\n The song spent entity20 fourteen weeks entity20 at number 2 on the entity17 US entity17 entity21 Hot Adult Contemporary Tracks entity21 , setting a record for most weeks at the second position . \\n The music video was shot between entity22 29–30 April 2003 entity22 in entity23 Los Angeles entity23 and released on entity24 2 June 2003 entity24 . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': \"  Sure! Here are the relations in the predefined set of relations that can be extracted from the text:\\n\\n1. head of government: Celine Dion (entity2) is the head of government of her studio albums (entity3, entity4, entity6, and entity7)\\n2. country: The song `Have You Ever Been in Love` (entity0) is from Canada (entity1), and it was recorded by a Canadian recording artist (entity2)\\n3. place of birth: The song was not specifically mentioned to be written or recorded in any particular place, so there is no relation for place of birth.\\n4. place of death: No information is given about the place of death.\\n5. father: No information is given about the father of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n6. mother: No information is given about the mother of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n7. spouse: No information is given about the spouse of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n8. country of citizenship: Celine Dion (entity2) is a Canadian citizen (entity1).\\n9. continent: The song `Have You Ever Been in Love` (entity0) is from North America (entity1).\\n10. instance of: The song `Have You Ever Been in Love` (entity0) is an instance of a power ballad.\\n11. head of state: No information is given about the head of state of Canada (entity1) or the song `Have You Ever Been in Love` (entity0).\\n12. capital: No information is given about the capital of Canada (entity1) or the song `Have You Ever Been in Love` (entity0).\\n13. official language: No information is given about the official language of Canada (entity1) or the song `Have You Ever Been in Love` (entity0).\\n14. position held: Celine Dion (entity2) held the position of recording artist for the song `Have You Ever Been in Love` (entity0).\\n15. child: No information is given about the children of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n16. author: The song `Have You Ever Been in Love` (entity0) was written by Anders Bagge (entity9), Peer Åström (entity10), Tom Nichols (entity11), Daryl Hall (entity12), and Laila Bagge (entity13).\\n17. member of sports team: No information is given about the members of any sports teams.\\n18. director: No information is given about the directors of the song `Have You Ever Been in Love` (entity0) or the music video.\\n19. screenwriter: No information is given about the screenwriters of the song `Have You Ever Been in Love` (entity0) or the music video.\\n20. educated at: No information is given about the educational background of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n21. composer: The song `Have You Ever Been in Love` (entity0) was composed by Anders Bagge (entity9), Peer Åström (entity10), Tom Nichols (entity11), Daryl Hall (entity12), and Laila Bagge (entity13).\\n22. member of political party: No information is given about the political party affiliations of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n23. employer: No information is given about the employers of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n24. founded by: No information is given about the founders of the song `Have You Ever Been in Love` (entity0) or Celine Dion (entity2).\\n25. league: No information is given about the league affiliations of the song `Have You Ever Been in Love` (entity0) or Celine Dion (entity2).\\n26. publisher: No information is given about the publishers of the song `Have You Ever Been in Love` (entity0).\\n27. owned by: No information is given about the ownership of the song `Have You Ever Been in Love` (entity0) or Celine Dion (entity2).\\n28. located in the administrative territorial entity: The song `Have You Ever Been in Love` (entity0) was recorded in Canada (entity1), and Celine Dion (entity2) is a Canadian artist.\\n29. genre: The song `Have You Ever Been in Love` (entity0) is a power ballad.\\n30. operator: No information is given about the operators of the song `Have You Ever Been in Love` (entity0) or Celine Dion (entity2).\\n31. religion: No information is given about the religion of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n32. contains administrative territorial entity: The song `Have You Ever Been in Love` (entity0) contains the administrative territorial entity of Canada (entity1).\\n33. follows: No information is given about the followers of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n34. followed by: No information is given about the followers of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n35. headquarters location: No information is given about the headquarters location of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n36. cast member: No information is given about the cast members of the music video for `Have You Ever Been in Love` (entity0).\\n37. producer: No information is given about the producers of the song `Have You Ever Been in Love` (entity0) or the music video.\\n38. award received: No information is given about awards received by Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n39. creator: The song `Have You Ever Been in Love` (entity0) was created by Anders Bagge (entity9), Peer Åström (entity10), Tom Nichols (entity11), Daryl Hall (entity12), and Laila Bagge (entity13).\\n40. parent taxon: No information is given about the parent taxon of the song `Have You Ever Been in Love` (entity0) or Celine Dion (entity2).\\n41. ethnic group: No information is given about the ethnic group of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n42. performer: Celine Dion (entity2) performed the song `Have You Ever Been in Love` (entity0).\\n43. manufacturer: No information is given about the manufacturers of the song `Have You Ever Been in Love` (entity0) or Celine Dion (entity2).\\n44. developer: No information is given about the developers of the song `Have You Ever Been in Love` (entity0) or Celine Dion (entity2).\\n45. series: No information is given about any series related to the song `Have You Ever Been in Love` (entity0) or Celine Dion (entity2).\\n46. sister city: No information is given about any sister cities of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n47. legislative body: No information is given about the legislative body of Canada (entity1) or the song `Have You Ever Been in Love` (entity0).\\n48. basin country: No information is given about the basin country of Canada (entity1) or the song `Have You Ever Been in Love` (entity0).\\n49. located in or next to body of water: The song `Have You Ever Been in Love` (entity0) was recorded in Los Angeles (entity24), which is located next to the Pacific Ocean.\\n50. military branch: No information is given about the military branch affiliations of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n51. record label: The song `Have You Ever Been in Love` (entity0) was released on the record label of Sony Music Entertainment (entity14).\\n52. production company: No information is given about the production company of the song `Have You Ever Been in Love` (entity0) or the music video.\\n53. location: The song `Have You Ever Been in Love` (entity0) was recorded in Los Angeles (entity24), California, USA.\\n54. platform: No information is given about the platform of the song `Have You Ever Been in Love` (entity0) or Celine Dion (entity2).\\n55. mouth of the watercourse: No information is given about the mouth of any watercourses related to the song `Have You Ever Been in Love` (entity0) or Celine Dion (entity2).\\n56. original network: No information is given about the original network of the song `Have You Ever Been in Love` (entity0) or Celine Dion (entity2).\\n57. member of: Celine Dion (entity2) is a member of the Canadian recording industry (entity1).\\n58. notable work: The song `Have You Ever Been in Love` (entity0) is a notable work by Celine Dion (entity2).\\n59. parent organization: No information is given about the parent organization of Celine Dion (entity2) or the song `Have You Ever Been in Love` (entity0).\\n60. present in work: The song `Have You Ever Been in Love` (entity0) is present in Celine Dion's (entity2) work.\\n\\nI hope this helps! Let me know if you have any further questions or if there's anything else I can assist you with.\",\n",
       "   'expected_output': '(entity0,part of,entity4)\\n(entity0,part of,entity7)\\n(entity0,performer,entity2)\\n(entity0,publication date,entity16)\\n(entity4,publication date,entity5)\\n(entity4,followed by,entity7)\\n(entity4,performer,entity2)\\n(entity7,follows,entity4)\\n(entity7,performer,entity2)\\n(entity7,publication date,entity8)\\n(entity2,country of citizenship,entity1)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 2244,\n",
       "   'AnswerModel': 'llama-2-7b-chat',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:Jakarta International Film Festival\\nText: The entity0 Jakarta International Film Festival entity0 ( entity1 JIFFEST entity1 ) is the major film festival of entity2 Indonesia entity2 held every entity3 December entity3 in the capital , entity4 Jakarta entity4 , since entity5 1999 entity5 . \\n The number of entity6 Indonesian entity6 films shown at the festival had grown from entity7 four entity7 in entity5 1999 entity5 to around entity8 100 entity8 by entity9 2009 entity9 . \\n Since entity10 2006 entity10 , entity1 JIFFEST entity1 has hosted an entity6 Indonesian entity6 Feature Film Competition with foreign film professionals acting as juries . \\n entity1 JIFFEST entity1 's script development competition and workshop winners include entity11 Wahyu Aditya entity11 ( entity12 2004 entity12 ) , entity13 World Champion International Young Creative Entrepreneur of the Year entity13 ( entity14 2007 entity14 ) ; entity15 Tumpal Tampubolon entity15 ( entity16 2005 entity16 ) , entity17 Asian Young Filmmakers Fellow Korea entity17 ( entity18 2008 entity18 ) ; entity19 Salman Aristo entity19 ( entity10 2006 entity10 ) , writer of entity20 Ayat - Ayat Cinta entity20 ( entity14 2007 entity14 ) , entity21 Laskar Pelangi entity21 ( entity18 2008 entity18 ) , and entity22 Garuda di Dadaku entity22 ( entity9 2009 entity9 ) ; entity23 Yuli Andari Merdekaningtyas entity23 ( entity10 2006 entity10 ) , and director of entity24 Suster Apung entity24 , winner of entity25 Eagle Awards Metro TV entity25 ( entity10 2006 entity10 ) . \\n The festival is on a shaky financial footing and is hoping to continue by switching its funding source from foreign donors to government grants and private donations . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': '  Based on the text provided, the following relations can be identified in the predefined set of relations:\\n* Head of government: None\\n* Country: Indonesia (mentioned multiple times)\\n* Place of birth: None\\n* Place of death: None\\n* Father: None\\n* Mother: None\\n* Spouse: None\\n* Country of citizenship: None\\n* Continent: Asia (mentioned in the text)\\n* Instance of: None\\n* Head of state: None\\n* Capital: Jakarta (mentioned multiple times)\\n* Official language: Indonesian (mentioned in the text)\\n* Position held: None\\n* Child: None\\n* Author: None\\n* Member of sports team: None\\n* Director: Multiple (mentioned multiple times)\\n* Screenwriter: None\\n* Educated at: None\\n* Composer: None\\n* Member of political party: None\\n* Employer: None\\n* Founded by: None\\n* League: None\\n* Publisher: None\\n* Owned by: None\\n* Located in the administrative territorial entity: Jakarta (mentioned multiple times)\\n* Genre: None\\n* Operator: None\\n* Religion: None\\n* Contains administrative territorial entity: Jakarta (mentioned multiple times)\\n* Follows: None\\n* Followed by: None\\n* Headquarters location: Jakarta (mentioned multiple times)\\n* Cast member: None\\n* Producer: Multiple (mentioned multiple times)\\n* Award received: None\\n* Creator: None\\n* Parent taxon: None\\n* Ethnic group: None\\n* Performer: None\\n* Manufacturer: None\\n* Developer: None\\n* Series: None\\n* Sister city: None\\n* Legislative body: None\\n* Basin country: None\\n* Located in or next to body of water: None\\n* Military branch: None\\n* Record label: None\\n* Production company: None\\n* Location: Jakarta (mentioned multiple times)\\n* Subclass of: None\\n* Subsidiary: None\\n* Part of: None\\n* Original language of work: Indonesian (mentioned in the text)\\n* Platform: None\\n* Mouth of the watercourse: None\\n* Original network: None\\n* Member of: None\\n* Chairperson: None\\n* Country of origin: Indonesia (mentioned multiple times)\\n* Has part: None\\n* Residence: Jakarta (mentioned multiple times)\\n* Date of birth: None\\n* Date of death: None\\n* Inception: None\\n* Dissolved: None\\n* Abolished or demolished: None\\n* Publication date: None\\n* Start time: None\\n* End time: None\\n* Point in time: None\\n* Conflict: None\\n* Characters: None\\n* Lyrics by: None\\n* Located on terrain feature: None\\n* Participant: Multiple (mentioned multiple times)\\n* Influenced by: None\\n* Location of formation: Jakarta (mentioned multiple times)\\n* Parent organization: None\\n* Notable work: None\\n* Separated from: None\\n* Narrative location: Jakarta (mentioned multiple times)\\n* Work location: Jakarta (mentioned multiple times)\\n* Applies to jurisdiction: None\\n* Product or material produced: None\\n* Unemployment rate: None\\n* Territory claimed by: None\\n* Participant of: Multiple (mentioned multiple times)\\n* Replaces: None\\n* Replaced by: None\\n* Capital of: Jakarta (mentioned multiple times)\\n* Languages spoken, written or signed: Indonesian (mentioned in the text)\\n\\nNote that some of the relations may not be explicitly mentioned in the text, but they can be inferred based on the information provided.',\n",
       "   'expected_output': '(entity2,capital,entity4)\\n(entity2,contains administrative territorial entity,entity4)\\n(entity4,capital of,entity2)\\n(entity4,country,entity2)\\n(entity4,located in the administrative territorial entity,entity2)\\n(entity4,country,entity6)\\n(entity4,located in the administrative territorial entity,entity6)\\n(entity4,capital of,entity6)\\n(entity0,country,entity2)\\n(entity0,inception,entity5)\\n(entity0,country,entity6)\\n(entity6,capital,entity4)\\n(entity6,contains administrative territorial entity,entity4)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 2700,\n",
       "   'AnswerModel': 'llama-2-7b-chat',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:List of companies of France\\nText: entity0 France entity0 is a country whose territory consists of metropolitan entity0 France entity0 in western entity1 Europe entity1 , as well as several overseas regions and territories . \\n A member of the entity2 Group of 7 entity2 ( formerly entity3 G8 entity3 ) leading industrialised countries , , it is ranked as the world 's ninth - largest and the entity4 EU entity4 's second - largest economy by purchasing power parity . \\n With entity5 31 entity5 of the entity6 500 entity6 biggest companies in the world in entity7 2015 entity7 , entity0 France entity0 ranks fourth in the entity8 Fortune Global 500 entity8 , ahead of entity9 Germany entity9 and the entity10 UK entity10 . \\n According to the entity11 World Trade Organization entity11 ( entity11 WTO entity11 ) , in entity12 2009 entity12 entity0 France entity0 was the world 's sixth - largest exporter and the fourth - largest importer of manufactured goods . \\n entity13 French entity13 companies have maintained key positions in the insurance and banking industries : entity14 AXA entity14 is the world 's largest insurance company . \\n The leading entity13 French entity13 banks are entity15 BNP Paribas entity15 and the entity16 Crédit Agricole entity16 , ranking as the world 's largest and sixth - largest banks in entity17 2010 entity17 ( by assets ) , while the entity18 Société Générale entity18 group was ranked the world 's eighth - largest in entity12 2009 entity12 . \\n For further information on the types of business entities in this country and their abbreviations , see ` entity19 Business entities in France entity19 ` . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': '  Sure, I can extract relations from the given text using the predefined set of relations. Here are the relations found in the text:\\n* head of government: (France, Emmanuel Macron, instance of)\\n* country: (France, country of)\\n* place of birth: (France, location of birth)\\n* place of death: (France, location of death)\\n* father: (France, parent)\\n* mother: (France, parent)\\n* spouse: (France, spouse of)\\n* country of citizenship: (France, country of citizenship)\\n* continent: (France, Europe)\\n* instance of: (France, country)\\n* head of state: (France, President of France)\\n* capital: (France, Paris)\\n* official language: (France, French)\\n* position held: (France, President of France)\\n* child: (France, child of)\\n* author: (France, author of)\\n* member of sports team: (France, member of the French national football team)\\n* director: (France, director of)\\n* screenwriter: (France, screenwriter of)\\n* educated at: (France, educated at the École Polytechnique)\\n* composer: (France, composer of)\\n* member of political party: (France, member of the Les Républicains political party)\\n* employer: (France, employer of)\\n* founded by: (France, founded by the French Republic)\\n* league: (France, member of the European Union)\\n* publisher: (France, publisher of)\\n* owned by: (France, owned by the French state)\\n* located in the administrative territorial entity: (France, located in the administrative territorial entity of France)\\n* genre: (France, country of)\\n* operator: (France, operator of)\\n* religion: (France, religion of)\\n* contains administrative territorial entity: (France, contains the administrative territorial entity of French overseas departments and territories)\\n* follows: (France, follows the European Union)\\n* followed by: (France, followed by the European Union)\\n* headquarters location: (France, headquarters location of)\\n* cast member: (France, cast member of)\\n* producer: (France, producer of)\\n* award received: (France, award received by)\\n* creator: (France, creator of)\\n* parent taxon: (France, parent taxon of)\\n* ethnic group: (France, ethnic group of)\\n* performer: (France, performer of)\\n* manufacturer: (France, manufacturer of)\\n* developer: (France, developer of)\\n* series: (France, series of)\\n* sister city: (France, sister city of)\\n* legislative body: (France, legislative body of)\\n* basin country: (France, basin country of)\\n* located in or next to body of water: (France, located in or next to the Mediterranean Sea)\\n* military branch: (France, military branch of)\\n* record label: (France, record label of)\\n* production company: (France, production company of)\\n* location: (France, location of)\\n* subclass of: (France, subclass of)\\n* subsidiary: (France, subsidiary of)\\n* part of: (France, part of)\\n* original language of work: (France, original language of work in)\\n* platform: (France, platform of)\\n* mouth of the watercourse: (France, mouth of the Seine River)\\n* original network: (France, original network of)\\n* member of: (France, member of the European Union)\\n* chairperson: (France, chairperson of the European Council)\\n* country of origin: (France, country of origin)\\n* has part: (France, has part of the overseas departments and territories)\\n* residence: (France, residence of the President of France)\\n* date of birth: (France, date of birth of)\\n* date of death: (France, date of death of)\\n* inception: (France, inception of the French Republic)\\n* dissolved: (France, dissolved on)\\n* abolished or demolished: (France, abolished or demolished on)\\n* publication date: (France, publication date of)\\n* start time: (France, start time of)\\n* end time: (France, end time of)\\n* point in time: (France, point in time of)\\n* conflict: (France, conflict of)\\n* characters: (France, characters of)\\n* lyrics by: (France, lyrics by)\\n* located on terrain feature: (France, located on the terrain feature of the French Alps)\\n* participant: (France, participant in)\\n* influenced by: (France, influenced by the Renaissance)\\n* location of formation: (France, location of formation of)\\n* parent organization: (France, parent organization of)\\n* notable work: (France, notable work of)\\n* separated from: (France, separated from the European Union)\\n* narrative location: (France, narrative location of)\\n* work location: (France, work location of)\\n* applies to jurisdiction: (France, applies to the jurisdiction of the French Republic)\\n* product or material produced: (France, product or material produced in)\\n* unemployment rate: (France, unemployment rate of)\\n* territory claimed by: (France, territory claimed by)\\n* participant of: (France, participant of the European Union)\\n* replaces: (France, replaces the European Union)\\n* replaced by: (France, replaced by the European Union)\\n* capital of: (France, capital of)\\n* languages spoken, written or signed: (France, languages spoken, written or signed in French)\\n* present in work: (France, present in work of the French language)\\n* sibling: (France, sibling of the European Union)\\n\\nNote that some of these relations may not be explicitly mentioned in the text, but they are part of the predefined set of relations and could be inferred based on the context.',\n",
       "   'expected_output': '(entity0,continent,entity1)\\n(entity0,member of,entity3)\\n(entity0,member of,entity4)\\n(entity0,member of,entity11)\\n(entity0,member of,entity14)\\n(entity3,participant,entity0)\\n(entity4,contains administrative territorial entity,entity0)\\n(entity15,country,entity0)\\n(entity16,country,entity0)\\n(entity18,country,entity0)\\n(entity2,participant,entity0)\\n(entity2,replaced by,entity3)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 1103,\n",
       "   'AnswerModel': 'llama-2-7b-chat',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:Brian McGuinness\\nText: entity0 Brian McGuinness entity0 ( born entity0 Bernard Francis McGuinness entity0 , entity1 22 October 1927 entity1 , in entity2 Wrexham entity2 , entity3 United Kingdom entity3 ) is a entity4 British entity4 philosopher . \\n Formerly a pupil of entity5 RM Hare entity5 , entity6 McGuinness entity6 has become a noted expert in the works of entity7 Ludwig Wittgenstein entity7 . \\n entity6 McGuinness entity6 was a Fellow and Tutor at entity8 Queen 's College entity8 in entity9 Oxford University entity9 from entity10 1953 entity10 to entity11 1988 entity11 , and took a post at the entity12 Netherlands Institute for Advanced Study entity12 . \\n Since entity13 1990 entity13 , he is a professor at the entity14 University of Siena entity14 , entity15 Italy entity15 . \\n From entity13 1990 entity13 to entity16 1993 entity16 , he was director of the faculty of philosophy and social sciences of this university . \\n During his time at entity17 Queen 's entity17 , he was an invited speaker at the entity18 Oxford Socratic Club entity18 , speaking with entity19 J. D. Mabbott entity19 on ` entity20 The Problem of Free Will entity20 ` on entity21 Nov. 14 , 1955 entity21 . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': \"  Sure! Based on the text provided, here are the relations that can be identified in the predefined set of relations:\\n* (Brian McGuinness, head of government, entity0)\\nBrian McGuinness is not a head of government, as he is a philosopher and not a political leader.\\n* (Brian McGuinness, country, entity2)\\nBrian McGuinness is from the United Kingdom (entity3), not from entity2 (Wrexham).\\n* (Brian McGuinness, place of birth, entity1)\\nBrian McGuinness was born in entity1 (Wrexham), not in entity0 (Bernard Francis McGuinness).\\n* (Brian McGuinness, father, entity4)\\nThere is no information in the text about Brian McGuinness's father.\\n* (Brian McGuinness, mother, entity5)\\nThere is no information in the text about Brian McGuinness's mother.\\n* (Brian McGuinness, spouse, entity6)\\nThere is no information in the text about Brian McGuinness's spouse.\\n* (Brian McGuinness, country of citizenship, entity4)\\nBrian McGuinness is a British philosopher (entity4), not a citizen of any other country.\\n* (Brian McGuinness, continent, entity3)\\nBrian McGuinness is from the continent of Europe (entity3), not from any other continent.\\n* (Brian McGuinness, instance of, entity8)\\nBrian McGuinness is an instance of a philosopher (entity4), not of any other type of entity.\\n* (Brian McGuinness, head of state, None)\\nBrian McGuinness is not a head of state, as he is a philosopher and not a political leader.\\n* (Brian McGuinness, capital, entity1)\\nBrian McGuinness is from the city of Wrexham (entity1), not from any other city or capital.\\n* (Brian McGuinness, official language, English)\\nBrian McGuinness's official language is English (not specified in the text).\\n* (Brian McGuinness, position held, philosopher)\\nBrian McGuinness is a philosopher (position held), not a member of any other profession or position.\\n* (Brian McGuinness, child, None)\\nBrian McGuinness does not have any children, as there is no information in the text about his family.\\n* (Brian McGuinness, author, None)\\nBrian McGuinness is not an author, as there is no information in the text about his writings or publications.\\n* (Brian McGuinness, member of sports team, None)\\nBrian McGuinness is not a member of any sports team, as there is no information in the text about his involvement in sports.\\n* (Brian McGuinness, director, None)\\nBrian McGuinness is not a director, as there is no information in the text about his involvement in film or other media.\\n* (Brian McGuinness, screenwriter, None)\\nBrian McGuinness is not a screenwriter, as there is no information in the text about his involvement in film or other media.\\n* (Brian McGuinness, educated at, Queen's College, Oxford)\\nBrian McGuinness was educated at Queen's College, Oxford (entity8), not at any other institution.\\n* (Brian McGuinness, composer, None)\\nBrian McGuinness is not a composer, as there is no information in the text about his musical interests or background.\\n* (Brian McGuinness, member of political party, None)\\nBrian McGuinness is not a member of any political party, as there is no information in the text about his political affiliations.\\n* (Brian McGuinness, employer, None)\\nBrian McGuinness does not have an employer, as there is no information in the text about his professional career or work history.\\n* (Brian McGuinness, founded by, None)\\nBrian McGuinness did not found any organizations or institutions, as there is no information in the text about his involvement in founding or establishing any entities.\\n* (Brian McGuinness, league, None)\\nBrian McGuinness is not a member of any league or organization, as there is no information in the text about his involvement in any group or association.\\n* (Brian McGuinness, publisher, None)\\nBrian McGuinness is not a publisher, as there is no information in the text about his involvement in publishing or media.\\n* (Brian McGuinness, owned by, None)\\nBrian McGuinness does not own any organizations or entities, as there is no information in the text about his ownership or financial interests.\\n* (Brian McGuinness, located in or next to body of water, None)\\nBrian McGuinness is not located in or next to any body of water, as there is no information in the text about his geographical location or proximity to any waterway.\\n* (Brian McGuinness, military branch, None)\\nBrian McGuinness is not a member of any military branch, as there is no information in the text about his military service or background.\\n* (Brian McGuinness, record label, None)\\nBrian McGuinness is not a member of any record label, as there is no information in the text about his involvement in music or recording industry.\\n* (Brian McGuinness, production company, None)\\nBrian McGuinness is not a member of any production company, as there is no information in the text about his involvement in film or other media production.\\n* (Brian McGuinness, location, entity1)\\nBrian McGuinness is from the location of Wrexham (entity1), not from any other location.\\n* (Brian McGuinness, narrative location, entity1)\\nThe narrative location of Brian McGuinness is Wrexham (entity1), not from any other location.\\n* (Brian McGuinness, work location, entity1)\\nThe work location of Brian McGuinness is Wrexham (entity1), not from any other location.\\n* (Brian McGuinness, applies to jurisdiction, None)\\nBrian McGuinness does not apply to any jurisdiction, as there is no information in the text about his legal or political status.\\n* (Brian McGuinness, product or material produced, None)\\nBrian McGuinness does not produce any products or materials, as there is no information in the text about his professional career or work history.\\n* (Brian McGuinness, unemployment rate, None)\\nBrian McGuinness does not have any information about unemployment rates, as there is no information in the text about his professional career or work history.\\n* (Brian McGuinness, territory claimed by, None)\\nBrian McGuinness does not have any information about territory claimed by, as there is no information in the text about his geographical location or political status.\\n* (Brian McGuinness, participant, None)\\nBrian McGuinness is not a participant in any events or activities, as there is no information in the text about his involvement in any group or organization.\\n* (Brian McGuinness, influenced by, None)\\nBrian McGuinness does not have any information about influences, as there is no information in the text about his personal beliefs or interests.\\n* (Brian McGuinness, location of formation, entity1)\\nBrian McGuinness was formed in the location of Wrexham (entity1), not from any other location.\\n* (Brian McGuinness, parent organization, None)\\nBrian McGuinness does not have any information about parent organizations, as there is no information in the text about his affiliation with any larger groups or institutions.\\n* (Brian McGuinness, notable work, None)\\nBrian McGuinness does not have any notable works, as there is no information in the text about his writings or publications.\\n* (Brian McGuinness, separated from, None)\\nBrian McGuinness does not have any information about separation, as there is no information in the text about his personal life or relationships.\\n* (Brian McGuinness, conflict, None)\\nBrian McGuinness does not have any information about conflicts, as there is no information in the text about his involvement in any disputes or controversies.\\n* (Brian McGuinness, characters, None)\\nBrian McGuinness does not have any information about characters, as there is no information in the text about his involvement in any creative works or productions.\\n* (Brian McGuinness, lyrics by, None)\\nBrian McGuinness does not have any information about lyrics, as there is no information in the text about his involvement in music or poetry.\\n* (Brian McGuinness, located on terrain feature, None)\\nBrian McGuinness does not have any information about terrain features, as there is no information in the text about his geographical location or proximity to any natural features.\\n* (Brian McGuinness, participant, entity3)\\nBrian McGuinness is a participant in entity3 (the United Kingdom), not from any other entity.\\n* (Brian McGuinness, creator, entity3)\\nBrian McGuinness is the creator of entity3 (the United Kingdom), not from any other entity.\\n* (Brian McGuinness, parent taxon, entity3)\\nBrian McGuinness is a parent taxon of entity3 (the United Kingdom), not from any other entity.\\n* (Brian McGuinness, ethnic group, entity4)\\nBrian McGuinness is an ethnic group of entity4 (British), not from any other entity.\\n* (Brian McGuinness, performer, entity4)\\nBrian McGuinness is a performer of entity4 (British), not from any other entity.\\n* (Brian McGuinness, manufacturer, entity4)\\nBrian McGuinness is a manufacturer of entity4 (British), not from any other entity.\\n* (Brian McGuinness, developer, entity4)\\nBrian McGuinness is a developer of entity4 (British), not from any other entity.\\n* (Brian McGuinness, sister city, entity4)\\nBrian McGuinness has a sister city of entity4 (British), not from any other entity.\\n* (Brian McGuinness, legislative body, entity4)\\nBrian McGuinness has a legislative body of entity4 (British), not from any other entity.\\n* (Brian McGuinness, basin country, entity4)\\nBrian McGuinness is a basin country of entity4 (British), not from any other entity.\\n* (Brian McGuinness, located in or next to body of water, entity4)\\nBrian McGuinness is located in or next to entity4 (the Irish Sea), not from any other entity.\\n* (Brian McGuinness, military branch, entity4)\\nBrian McGuinness is a military branch of entity4 (British), not from any other entity.\\n* (Brian McGuinness, record label, entity4)\\nBrian McGuinness is a record label of entity4 (British), not from any other entity.\\n* (Brian McGuinness, production company, entity4)\\nBrian McGuinness is a production company of entity4 (British), not from any other entity.\\n* (Brian McGuinness, location, entity1)\\nBrian McGuinness is located in entity1 (Wrexham), not from any other location.\\n* (Brian McGuinness, narrative location, entity1)\\nThe narrative location of Brian McGuinness is entity1 (Wrexham), not from any other location.\\n* (Brian McGuinness, work location, entity1)\\nThe work location of Brian McGuinness is entity1 (Wrexham), not from any other location.\\n* (Brian McGuinness, applies to jurisdiction, entity1)\\nBrian McGuinness applies to jurisdiction entity1 (Wales), not from any other jurisdiction.\\n* (Brian McGuinness, product or material produced, entity1)\\nBrian McGuinness produces entity1 (Wrexham), not from any other product or material.\\n* (Brian McGuinness, unemployment rate, entity1)\\nThe unemployment rate of Brian McGuinness is for entity1 (Wrexham), not from any other location or jurisdiction.\\n* (Brian McGuinness, territory claimed by, entity1)\\nBrian McGuinness claims territory entity1 (Wrexham), not from any other territory.\\n* (Brian McGuinness, participant, entity1)\\nBrian McGuinness is a participant in entity1 (Wrexham), not from any other entity.\\n* (Brian McGuinness, influenced by, entity1)\\nBrian McGuinness is influenced by entity1 (Wrexham), not from any other location or factor.\\n* (Brian McGuinness, location of formation, entity1)\\nBrian McGuinness was formed in the location of entity1 (Wrexham), not from any other location.\\n* (Brian McGuinness, parent organization, entity1)\\nBrian McGuinness has a parent organization of entity1 (Wales), not from any other entity.\\n* (Brian McGuinness, notable work, entity1)\\nBrian McGuinness has notable work in entity1 (Wrexham), not from any other location or entity.\\n* (Brian McGuinness, separated from, entity1)\\nBrian McGuinness is separated from entity1 (Wrexham), not from any other location or entity.\\n* (Brian McGuinness, conflict, entity1)\\nBrian McGuinness is in conflict with entity1\",\n",
       "   'expected_output': '(entity0,date of birth,entity1)\\n(entity0,place of birth,entity2)\\n(entity0,country of citizenship,entity3)\\n(entity2,country,entity3)\\n(entity8,country,entity3)\\n(entity8,part of,entity9)\\n(entity14,country,entity15)\\n(entity6,date of birth,entity1)\\n(entity6,place of birth,entity2)\\n(entity6,country of citizenship,entity3)\\n(entity9,has part,entity8)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 149,\n",
       "   'AnswerModel': 'llama-3-8b-instruct',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:Have You Ever Been in Love (song)\\nText: ` entity0 Have You Ever Been in Love entity0 ` is a song recorded by entity1 Canadian entity1 recording artist entity2 Celine Dion entity2 , included first on her seventh entity3 English entity3 studio album entity4 A New Day Has Come entity4 ( entity5 2002 entity5 ) and later , on her entity6 eight entity6 entity3 English entity3 studio album entity7 One Heart entity7 ( entity8 2003 entity8 ) . \\n The song is a power ballad , written by entity9 Anders Bagge entity9 , entity10 Peer Åström entity10 , entity11 Tom Nichols entity11 , entity12 Daryl Hall entity12 and entity13 Laila Bagge entity13 , while production was handled by entity14 Bagge & Peer entity14 . \\n ` entity0 Have You Ever Been in Love entity0 ` builds from a gentle , piano - laced opening into a theatrical , string - framed climax . \\n The song received acclaim from music critics , while being reviewed in both albums . \\n Many critics called it a classic - sounding ballad and one of the strongest cuts from the album . \\n Critics also noted similarities between entity2 Dion entity2 and entity15 Barbra Streisand entity15 . \\n ` entity0 Have You Ever Been in Love entity0 ` was released on entity16 14 April 2003 entity16 , as entity7 One Heart entity7 's second ( promotional only ) single in the entity17 United States entity17 and entity1 Canada entity1 , while on entity18 3 November 2003 entity18 , it was released as the third commercial single in selected entity19 European entity19 countries . \\n The song spent entity20 fourteen weeks entity20 at number 2 on the entity17 US entity17 entity21 Hot Adult Contemporary Tracks entity21 , setting a record for most weeks at the second position . \\n The music video was shot between entity22 29–30 April 2003 entity22 in entity23 Los Angeles entity23 and released on entity24 2 June 2003 entity24 . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': 'Here are the relations extracted from the text in the required format:\\n\\n* (Celine Dion, is recorded by, Have You Ever Been in Love)\\n* (Anders Bagge, is written by, Have You Ever Been in Love)\\n* (Peer Åström, is written by, Have You Ever Been in Love)\\n* (Tom Nichols, is written by, Have You Ever Been in Love)\\n* (Daryl Hall, is written by, Have You Ever Been in Love)\\n* (Laila Bagge, is written by, Have You Ever Been in Love)\\n* (Bagge & Peer, is produced by, Have You Ever Been in Love)\\n* (Barbra Streisand, is similar to, Celine Dion)\\n* (A New Day Has Come, includes, Have You Ever Been in Love)\\n* (One Heart, includes, Have You Ever Been in Love)\\n* (14 April 2003, is the release date of, Have You Ever Been in Love)\\n* (3 November 2003, is the release date of, Have You Ever Been in Love)\\n* (United States, is the release location of, Have You Ever Been in Love)\\n* (Canada, is the release location of, Have You Ever Been in Love)\\n* (Los Angeles, is the location of, Have You Ever Been in Love)\\n* (2 June 2003, is the release date of, the music video of Have You Ever Been in Love)\\n* (29-30 April 2003, is the filming date of, the music video of Have You Ever Been in Love)\\n\\nNote that some of these relations may not be directly relevant to the predefined set of relations, but they are all present in the text and can be extracted using the required format.',\n",
       "   'expected_output': '(entity0,part of,entity4)\\n(entity0,part of,entity7)\\n(entity0,performer,entity2)\\n(entity0,publication date,entity16)\\n(entity4,publication date,entity5)\\n(entity4,followed by,entity7)\\n(entity4,performer,entity2)\\n(entity7,follows,entity4)\\n(entity7,performer,entity2)\\n(entity7,publication date,entity8)\\n(entity2,country of citizenship,entity1)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 2700,\n",
       "   'AnswerModel': 'llama-3-8b-instruct',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:List of companies of France\\nText: entity0 France entity0 is a country whose territory consists of metropolitan entity0 France entity0 in western entity1 Europe entity1 , as well as several overseas regions and territories . \\n A member of the entity2 Group of 7 entity2 ( formerly entity3 G8 entity3 ) leading industrialised countries , , it is ranked as the world 's ninth - largest and the entity4 EU entity4 's second - largest economy by purchasing power parity . \\n With entity5 31 entity5 of the entity6 500 entity6 biggest companies in the world in entity7 2015 entity7 , entity0 France entity0 ranks fourth in the entity8 Fortune Global 500 entity8 , ahead of entity9 Germany entity9 and the entity10 UK entity10 . \\n According to the entity11 World Trade Organization entity11 ( entity11 WTO entity11 ) , in entity12 2009 entity12 entity0 France entity0 was the world 's sixth - largest exporter and the fourth - largest importer of manufactured goods . \\n entity13 French entity13 companies have maintained key positions in the insurance and banking industries : entity14 AXA entity14 is the world 's largest insurance company . \\n The leading entity13 French entity13 banks are entity15 BNP Paribas entity15 and the entity16 Crédit Agricole entity16 , ranking as the world 's largest and sixth - largest banks in entity17 2010 entity17 ( by assets ) , while the entity18 Société Générale entity18 group was ranked the world 's eighth - largest in entity12 2009 entity12 . \\n For further information on the types of business entities in this country and their abbreviations , see ` entity19 Business entities in France entity19 ` . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': 'Here are the relations extracted from the text in the format (entity_ID, relation, entity_ID):\\n\\n1. (entity0, country, entity1)\\n2. (entity0, country of origin, entity2)\\n3. (entity0, country of origin, entity4)\\n4. (entity5, part of, entity6)\\n5. (entity0, ranks, entity8)\\n6. (entity0, ahead of, entity9)\\n7. (entity0, ahead of, entity10)\\n8. (entity11, organization, entity0)\\n9. (entity0, exporter of, entity12)\\n10. (entity0, importer of, entity12)\\n11. (entity14, instance of, entity13)\\n12. (entity15, instance of, entity13)\\n13. (entity16, instance of, entity13)\\n14. (entity18, instance of, entity13)\\n\\nNote that some entities may have multiple relations, but I have only listed each relation once.',\n",
       "   'expected_output': '(entity0,continent,entity1)\\n(entity0,member of,entity3)\\n(entity0,member of,entity4)\\n(entity0,member of,entity11)\\n(entity0,member of,entity14)\\n(entity3,participant,entity0)\\n(entity4,contains administrative territorial entity,entity0)\\n(entity15,country,entity0)\\n(entity16,country,entity0)\\n(entity18,country,entity0)\\n(entity2,participant,entity0)\\n(entity2,replaced by,entity3)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 2244,\n",
       "   'AnswerModel': 'llama-3-8b-instruct',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:Jakarta International Film Festival\\nText: The entity0 Jakarta International Film Festival entity0 ( entity1 JIFFEST entity1 ) is the major film festival of entity2 Indonesia entity2 held every entity3 December entity3 in the capital , entity4 Jakarta entity4 , since entity5 1999 entity5 . \\n The number of entity6 Indonesian entity6 films shown at the festival had grown from entity7 four entity7 in entity5 1999 entity5 to around entity8 100 entity8 by entity9 2009 entity9 . \\n Since entity10 2006 entity10 , entity1 JIFFEST entity1 has hosted an entity6 Indonesian entity6 Feature Film Competition with foreign film professionals acting as juries . \\n entity1 JIFFEST entity1 's script development competition and workshop winners include entity11 Wahyu Aditya entity11 ( entity12 2004 entity12 ) , entity13 World Champion International Young Creative Entrepreneur of the Year entity13 ( entity14 2007 entity14 ) ; entity15 Tumpal Tampubolon entity15 ( entity16 2005 entity16 ) , entity17 Asian Young Filmmakers Fellow Korea entity17 ( entity18 2008 entity18 ) ; entity19 Salman Aristo entity19 ( entity10 2006 entity10 ) , writer of entity20 Ayat - Ayat Cinta entity20 ( entity14 2007 entity14 ) , entity21 Laskar Pelangi entity21 ( entity18 2008 entity18 ) , and entity22 Garuda di Dadaku entity22 ( entity9 2009 entity9 ) ; entity23 Yuli Andari Merdekaningtyas entity23 ( entity10 2006 entity10 ) , and director of entity24 Suster Apung entity24 , winner of entity25 Eagle Awards Metro TV entity25 ( entity10 2006 entity10 ) . \\n The festival is on a shaky financial footing and is hoping to continue by switching its funding source from foreign donors to government grants and private donations . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': 'Here are the relations extracted from the text in the required format:\\n\\n* (entity0, head of government, entity2)\\n* (entity0, country, entity2)\\n* (entity0, place of birth, entity4)\\n* (entity0, place of death, None)\\n* (entity1, instance of, entity0)\\n* (entity1, head of state, None)\\n* (entity1, capital, entity4)\\n* (entity1, official language, None)\\n* (entity2, country of citizenship, entity0)\\n* (entity2, continent, None)\\n* (entity11, author, entity20)\\n* (entity11, member of, entity1)\\n* (entity13, author, entity21)\\n* (entity13, member of, entity1)\\n* (entity15, author, entity22)\\n* (entity15, member of, entity1)\\n* (entity19, author, entity21)\\n* (entity19, member of, entity1)\\n* (entity23, author, entity24)\\n* (entity23, member of, entity1)\\n* (entity24, creator, entity25)\\n* (entity25, award received, entity25)\\n* (entity1, hosted, entity6)\\n* (entity1, funded by, entity2)\\n* (entity2, government grants, entity1)\\n\\nNote that some entities do not have relations with the predefined set of relations, so I did not include those. Also, some entities have multiple relations with the same entity, but I only included each relation once.',\n",
       "   'expected_output': '(entity2,capital,entity4)\\n(entity2,contains administrative territorial entity,entity4)\\n(entity4,capital of,entity2)\\n(entity4,country,entity2)\\n(entity4,located in the administrative territorial entity,entity2)\\n(entity4,country,entity6)\\n(entity4,located in the administrative territorial entity,entity6)\\n(entity4,capital of,entity6)\\n(entity0,country,entity2)\\n(entity0,inception,entity5)\\n(entity0,country,entity6)\\n(entity6,capital,entity4)\\n(entity6,contains administrative territorial entity,entity4)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 2700,\n",
       "   'AnswerModel': 'qwen-72b',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:List of companies of France\\nText: entity0 France entity0 is a country whose territory consists of metropolitan entity0 France entity0 in western entity1 Europe entity1 , as well as several overseas regions and territories . \\n A member of the entity2 Group of 7 entity2 ( formerly entity3 G8 entity3 ) leading industrialised countries , , it is ranked as the world 's ninth - largest and the entity4 EU entity4 's second - largest economy by purchasing power parity . \\n With entity5 31 entity5 of the entity6 500 entity6 biggest companies in the world in entity7 2015 entity7 , entity0 France entity0 ranks fourth in the entity8 Fortune Global 500 entity8 , ahead of entity9 Germany entity9 and the entity10 UK entity10 . \\n According to the entity11 World Trade Organization entity11 ( entity11 WTO entity11 ) , in entity12 2009 entity12 entity0 France entity0 was the world 's sixth - largest exporter and the fourth - largest importer of manufactured goods . \\n entity13 French entity13 companies have maintained key positions in the insurance and banking industries : entity14 AXA entity14 is the world 's largest insurance company . \\n The leading entity13 French entity13 banks are entity15 BNP Paribas entity15 and the entity16 Crédit Agricole entity16 , ranking as the world 's largest and sixth - largest banks in entity17 2010 entity17 ( by assets ) , while the entity18 Société Générale entity18 group was ranked the world 's eighth - largest in entity12 2009 entity12 . \\n For further information on the types of business entities in this country and their abbreviations , see ` entity19 Business entities in France entity19 ` . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': 'Here is the list of relations in the predefined set of relations in the above text:\\n\\n1. head of government\\n2. country\\n3. place of birth\\n4. place of death\\n5. father\\n6. mother\\n7. spouse\\n8. country of citizenship\\n9. continent\\n10. instance of\\n11. head of state\\n12. capital\\n13. official language\\n14. position held\\n15. child\\n16. author\\n17. member of sports team\\n18. director\\n19. screenwriter\\n20. educated at\\n21. composer\\n22. member of political party\\n23. employer\\n24. founded by\\n25. league\\n26. publisher\\n27. owned by\\n28. located in the administrative territorial entity\\n29. genre\\n30. operator\\n31. religion\\n32. contains administrative territorial entity\\n33. follows\\n34. followed by\\n35. headquarters location\\n36. cast member\\n37. producer\\n38. award received\\n39. creator\\n40. parent taxon\\n41. ethnic group\\n42. performer\\n43. manufacturer\\n44. developer\\n45. series\\n46. sister city\\n47. legislative body\\n48. basin country\\n49. located in or next to body of water\\n50. military branch\\n51. record label\\n52. production company\\n53. location\\n54. subclass of\\n55. subsidiary\\n56. part of\\n57. original language of work\\n58. platform\\n59. mouth of the watercourse\\n60. original network\\n61. member of\\n62. chairperson\\n63. country of origin\\n64. has part\\n65. residence\\n66. date of birth\\n67. date of death\\n68. inception\\n69. dissolved\\n70. abolished or demolished\\n71. publication date\\n72. start time\\n73. end time\\n74. point in time\\n75. conflict\\n76. characters\\n77. lyrics by\\n78. located on terrain feature\\n79. participant\\n80. influenced by\\n81. location of formation\\n82. parent organization\\n83. notable work\\n84. separated from\\n85. narrative location\\n86. work location\\n87. applies to jurisdiction\\n88. product or material produced\\n89. unemployment rate\\n90. territory claimed by\\n91. participant of\\n92. replaces\\n93. replaced by\\n94. capital of\\n95. languages spoken, written or signed\\n96. present in work\\n97. sibling',\n",
       "   'expected_output': '(entity0,continent,entity1)\\n(entity0,member of,entity3)\\n(entity0,member of,entity4)\\n(entity0,member of,entity11)\\n(entity0,member of,entity14)\\n(entity3,participant,entity0)\\n(entity4,contains administrative territorial entity,entity0)\\n(entity15,country,entity0)\\n(entity16,country,entity0)\\n(entity18,country,entity0)\\n(entity2,participant,entity0)\\n(entity2,replaced by,entity3)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 1103,\n",
       "   'AnswerModel': 'qwen-72b',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:Brian McGuinness\\nText: entity0 Brian McGuinness entity0 ( born entity0 Bernard Francis McGuinness entity0 , entity1 22 October 1927 entity1 , in entity2 Wrexham entity2 , entity3 United Kingdom entity3 ) is a entity4 British entity4 philosopher . \\n Formerly a pupil of entity5 RM Hare entity5 , entity6 McGuinness entity6 has become a noted expert in the works of entity7 Ludwig Wittgenstein entity7 . \\n entity6 McGuinness entity6 was a Fellow and Tutor at entity8 Queen 's College entity8 in entity9 Oxford University entity9 from entity10 1953 entity10 to entity11 1988 entity11 , and took a post at the entity12 Netherlands Institute for Advanced Study entity12 . \\n Since entity13 1990 entity13 , he is a professor at the entity14 University of Siena entity14 , entity15 Italy entity15 . \\n From entity13 1990 entity13 to entity16 1993 entity16 , he was director of the faculty of philosophy and social sciences of this university . \\n During his time at entity17 Queen 's entity17 , he was an invited speaker at the entity18 Oxford Socratic Club entity18 , speaking with entity19 J. D. Mabbott entity19 on ` entity20 The Problem of Free Will entity20 ` on entity21 Nov. 14 , 1955 entity21 . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': \"Sure, I can help you with that. Here are the relations in the predefined set of relations in the given text:\\n\\n1. Head of government: No relation\\n2. Country: United Kingdom, Italy\\n3. Place of birth: Wrexham, United Kingdom\\n4. Place of death: No relation\\n5. Father: No relation\\n6. Mother: No relation\\n7. Spouse: No relation\\n8. Country of citizenship: No relation\\n9. Continent: No relation\\n10. Instance of: No relation\\n11. Head of state: No relation\\n12. Capital: No relation\\n13. Official language: No relation\\n14. Position held: Fellow and Tutor at Queen's College in Oxford University\\n15. Child: No relation\\n16. Author: No relation\\n17. Member of sports team: No relation\\n18. Director: No relation\\n19. Screenwriter: No relation\\n20. Educated at: No relation\\n21. Composer: No relation\\n22. Member of political party: No relation\\n23. Employer: No relation\\n24. Founded by: No relation\\n25. League: No relation\\n26. Publisher: No relation\\n27. Owned by: No relation\\n28. Located in the administrative territorial entity: No relation\\n29. Genre: No relation\\n30. Operator: No relation\\n31. Religion: No relation\\n32. Contains administrative territorial entity: No relation\\n33. Follows: No relation\\n34. Followed by: No relation\\n35. Headquarters location: No relation\\n36. Cast member: No relation\\n37. Producer: No relation\\n38. Award received: No relation\\n39. Creator: No relation\\n40. Parent taxon: No relation\\n41. Ethnic group: No relation\\n42. Performer: No relation\\n43. Manufacturer: No relation\\n44. Developer: No relation\\n45. Series: No relation\\n46. Sister city: No relation\\n47. Legislative body: No relation\\n48. Basin country: No relation\\n49. Located in or next to body of water: No relation\\n50. Military branch: No relation\\n51. Record label: No relation\\n52. Production company: No relation\\n53. Location: No relation\\n54. Subclass of: No relation\\n55. Subsidiary: No relation\\n56. Part of: No relation\\n57. Original language of work: No relation\\n58. Platform: No relation\\n59. Mouth of the watercourse: No relation\\n60. Original network: No relation\\n61. Member of: No relation\\n62. Chairperson: No relation\\n63. Country of origin: No relation\\n64. Has part: No relation\\n65. Residence: No relation\\n66. Date of birth: 22 October 1927\\n67. Date of death: No relation\\n68. Inception: No relation\\n69. Dissolved, abolished or demolished: No relation\\n70. Publication date: No relation\\n71. Start time: No relation\\n72. End time: No relation\\n73. Point in time: No relation\\n74. Conflict: No relation\\n75. Characters: No relation\\n76. Lyrics by: No relation\\n77. Located on terrain feature: No relation\\n78. Participant: No relation\\n79. Influenced by: No relation\\n80. Location of formation: No relation\\n81. Parent organization: No relation\\n82. Notable work: No relation\\n83. Separated from: No relation\\n84. Narrative location: No relation\\n85. Work location: No relation\\n86. Applies to jurisdiction: No relation\\n87. Product or material produced: No relation\\n88. Unemployment rate: No relation\\n89. Territory claimed by: No relation\\n90. Participant of: No relation\\n91. Replaces: No relation\\n92. Replaced by: No relation\\n93. Capital of: No relation\\n94. Languages spoken, written or signed: No relation\\n95. Present in work: No relation\\n96. Sibling: No relation\\n\\nI hope this helps. Let me know if you have any other questions.\",\n",
       "   'expected_output': '(entity0,date of birth,entity1)\\n(entity0,place of birth,entity2)\\n(entity0,country of citizenship,entity3)\\n(entity2,country,entity3)\\n(entity8,country,entity3)\\n(entity8,part of,entity9)\\n(entity14,country,entity15)\\n(entity6,date of birth,entity1)\\n(entity6,place of birth,entity2)\\n(entity6,country of citizenship,entity3)\\n(entity9,has part,entity8)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]},\n",
       "  {'id': 2244,\n",
       "   'AnswerModel': 'qwen-7b-chat',\n",
       "   'input': \"Please follow the above demonstration, extract relations from the [Question text].\\nNote the relation need to be in the predefined set of relations.\\nThe output format required to is the same as the demonstration, format:(<entity_ID>, relation, <entity_ID>).\\nThe predefined set of relations:\\n{head of government, country, place of birth, place of death, father, mother, spouse, country of citizenship, continent, instance of, head of state, capital, official language, position held, child, author, member of sports team, director, screenwriter, educated at, composer, member of political party, employer, founded by, league, publisher, owned by, located in the administrative territorial entity, genre, operator, religion, contains administrative territorial entity, follows, followed by, headquarters location, cast member, producer, award received, creator, parent taxon, ethnic group, performer, manufacturer, developer, series, sister city, legislative body, basin country, located in or next to body of water, military branch, record label, production company, location, subclass of, subsidiary, part of, original language of work, platform, mouth of the watercourse, original network, member of, chairperson, country of origin, has part, residence, date of birth, date of death, inception, dissolved, abolished or demolished, publication date, start time, end time, point in time, conflict, characters, lyrics by, located on terrain feature, participant, influenced by, location of formation, parent organization, notable work, separated from, narrative location, work location, applies to jurisdiction, product or material produced, unemployment rate, territory claimed by, participant of, replaces, replaced by, capital of, languages spoken, written or signed, present in work, sibling}\\n\\nTitle:Jakarta International Film Festival\\nText: The entity0 Jakarta International Film Festival entity0 ( entity1 JIFFEST entity1 ) is the major film festival of entity2 Indonesia entity2 held every entity3 December entity3 in the capital , entity4 Jakarta entity4 , since entity5 1999 entity5 . \\n The number of entity6 Indonesian entity6 films shown at the festival had grown from entity7 four entity7 in entity5 1999 entity5 to around entity8 100 entity8 by entity9 2009 entity9 . \\n Since entity10 2006 entity10 , entity1 JIFFEST entity1 has hosted an entity6 Indonesian entity6 Feature Film Competition with foreign film professionals acting as juries . \\n entity1 JIFFEST entity1 's script development competition and workshop winners include entity11 Wahyu Aditya entity11 ( entity12 2004 entity12 ) , entity13 World Champion International Young Creative Entrepreneur of the Year entity13 ( entity14 2007 entity14 ) ; entity15 Tumpal Tampubolon entity15 ( entity16 2005 entity16 ) , entity17 Asian Young Filmmakers Fellow Korea entity17 ( entity18 2008 entity18 ) ; entity19 Salman Aristo entity19 ( entity10 2006 entity10 ) , writer of entity20 Ayat - Ayat Cinta entity20 ( entity14 2007 entity14 ) , entity21 Laskar Pelangi entity21 ( entity18 2008 entity18 ) , and entity22 Garuda di Dadaku entity22 ( entity9 2009 entity9 ) ; entity23 Yuli Andari Merdekaningtyas entity23 ( entity10 2006 entity10 ) , and director of entity24 Suster Apung entity24 , winner of entity25 Eagle Awards Metro TV entity25 ( entity10 2006 entity10 ) . \\n The festival is on a shaky financial footing and is hoping to continue by switching its funding source from foreign donors to government grants and private donations . \\n\\nRelations in the predefined set of relations in the above text:?\\n\",\n",
       "   'actual_output': 'The relations in the predefined set of relations in the given text are:\\n\\n  * head of government: None\\n  * country: Indonesia\\n  * place of birth: None\\n  * place of death: None\\n  * father: None\\n  * mother: None\\n  * spouse: None\\n  * country of citizenship: Indonesia\\n  * continent: Asia\\n  * instance of: Film festival\\n  * head of state: President of Indonesia\\n  * capital: Jakarta\\n  * official language: Indonesian\\n  * position held: None\\n  * child: None\\n  * author: None\\n  * member of sports team: None\\n  * director: None\\n  * screenwriter: None\\n  * educated at: None\\n  * composer: None\\n  * member of political party: None\\n  * employer: None\\n  * founded by: None\\n  * league: None\\n  * publisher: None\\n  * owned by: None\\n  * located in the administrative territorial entity: Province of DKI Jakarta\\n  * genre: Film\\n  * operator: Indonesian Film and Art Center (ICA)\\n  * religion: None\\n  * contains administrative territorial entity: None\\n  * follows: None\\n  * followed by: None\\n  * headquarters location: Jakarta\\n  * cast member: None\\n  * producer: None\\n  * award received: None\\n  * creator: None\\n  * parent taxon: None\\n  * ethnic group: None\\n  * performer: None\\n  * manufacturer: None\\n  * developer: None\\n  * series: None\\n  * sister city: None\\n  * legislative body: None\\n  * basin country: None\\n  * located in or next to body of water: Java Sea\\n  * military branch: None\\n  * record label: None\\n  * production company: None\\n  * location: Jakarta\\n  * subclass of: None\\n  * subsidiary: None\\n  * part of: None\\n  * original language of work: Indonesian\\n  * platform: None\\n  * mouth of the watercourse: Java Sea\\n  * original network: None\\n  * member of: None\\n  * chairperson: None\\n  * country of origin: None\\n  * has part: None\\n  * residence: None\\n  * date of birth: None\\n  * date of death: None\\n  * inception: 1999\\n  * dissolved: None\\n  * abolished or demolished: None\\n  * publication date: None\\n  * start time: None\\n  * end time: None\\n  * point in time: None\\n  * conflict: None\\n  * characters: None\\n  * lyrics by: None\\n  * located on terrain feature: None\\n  * participant: None\\n  * influenced by: None\\n  * location of formation: None\\n  * parent organization: None\\n  * notable work: None\\n  * separated from: None\\n  * narrative location: None\\n  * work location: Jakarta\\n  * applies to jurisdiction: None\\n  * product or material produced: None\\n  * unemployment rate: None\\n  * territory claimed by: None\\n  * participant of: None\\n  * replaces: None\\n  * replaced by: None\\n  * capital of: None\\n  * languages spoken: Indonesian\\n  * written or signed: None\\n  * present in work: None\\n  * sibling: None',\n",
       "   'expected_output': '(entity2,capital,entity4)\\n(entity2,contains administrative territorial entity,entity4)\\n(entity4,capital of,entity2)\\n(entity4,country,entity2)\\n(entity4,located in the administrative territorial entity,entity2)\\n(entity4,country,entity6)\\n(entity4,located in the administrative territorial entity,entity6)\\n(entity4,capital of,entity6)\\n(entity0,country,entity2)\\n(entity0,inception,entity5)\\n(entity0,country,entity6)\\n(entity6,capital,entity4)\\n(entity6,contains administrative territorial entity,entity4)\\n',\n",
       "   'retrieval_context': None,\n",
       "   'cached_metrics_data': [{'metric_metadata': {'metric': 'Answer Relevancy'},\n",
       "     'metric_configuration': {'threshold': 0.5,\n",
       "      'evaluation_model': 'qwen1.5-72b-chat',\n",
       "      'strict_mode': False,\n",
       "      'include_reason': True}}]}]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./eval/error/2-5_DocRED_sample.json') as f:\n",
    "    tmp = json.load(f)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./eval/error/2-4_FewNERD++supervised_sample.json','r') as f:\n",
    "#     data = json.load(f)\n",
    "# for item in data['data']:\n",
    "#     item['actual_output'] = item['actual_output'].replace(\"[/INST]\",'')\n",
    "#     item['actual_output'] = item['actual_output'].replace(\"[INST]\",'')\n",
    "# with open('./eval/error/2-4_FewNERD++supervised_sample.json','w') as f:\n",
    "#     json.dump(data,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e2cf87657f4eea8bd92d9f9c20c9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files_error = ['1-1_2_high_freq_ent_sample.json',]# '1-2_1_low_freq_ent_sample.json', '1-3_r_1_simple_sample_sample.json', '2-2_COPEN++cpj_sample.json', '2-4_FewNERD++inter_sample.json', '2-4_FewNERD++intra_sample.json', '2-4_FewNERD++supervised_sample.json', '2-5_DocRED_sample.json', '2-6_MAVEN_sample.json',  '2-8_r_DocRED_sample.json', '3-1_hotpotqa_sample.json', '3-2_2wikimultihopqa_sample.json', '3-3_musique_sample.json', '3-4_kqapro_sample.json', '3-5_KoRC++ood_sample.json', '3-6_r_KoRC++ood_sample.json',  '4-1_with_triples_sample.json', '4-2_r_with_triples_sample.json']\n",
    "for file in files_error:\n",
    "    joinEvalErrorToData('./eval/error/'+file,'./eval/save/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joinEvalErrorToData('./eval/error/2-5_DocRED_sample.json','./eval/save/2-5_DocRED_sample.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(\"\\\"reason\\\":(.*?)\\}\",re.DOTALL)\n",
    "matchStr = regex.findall(path[1])\n",
    "# matchStr = regex.sub(lambda x:\"\\\"reason\\\":\\\"\"+x.group(0).strip().replace(\"\\\"reason\\\":\",\"\").strip()[1:-1].replace('\"','\\\\\\\"'),path[1])\n",
    "matchStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchStr[2].strip()[1:-1].replace('\"','\\\\\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex.sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['{\"verdicts\": [\\n        {\\n            \"verdict\": \"idk\"\\n        },\\n        {\\n            \"verdict\": \"no\",\\n            \"reason\": \"The statement \\'I am unable to provide an answer to your question\\' acknowledges the inability to answer but doesn\\'t provide any relevant information about the similarity with Rose.\"\\n        },\\n        {\\n            \"verdict\": \"yes\",\\n            \"reason\": \"The statement \\'it is not clear what \"Rose\" refers to\\' is relevant as it points out the need for clarification to determine similarity.\"\\n        },\\n        {\\n            \"verdict\": \"yes\",\\n            \"reason\": \"The statement \\'Could you please provide more context or information?\\' is relevant as it directly asks for additional details to establish the similarity with Rose.\"\\n        }\\n    ]}',\n",
    " '{\"verdicts\": [\\n        {\\n            \"verdict\": \"no\",\\n            \"reason\": \"The statement \\'I\\'m sorry,\\' does not provide any information or similarity comparison with Rose.\"\\n        },\\n        {\\n            \"verdict\": \"yes\",\\n            \"reason\": \"The statement \\'I need more context to answer your question.\\' is relevant as it acknowledges the need for additional information to determine similarity with Rose.\"\\n        },\\n        {\\n            \"verdict\": \"yes\",\\n            \"reason\": \"The statement \\'Could you please clarify what \"Rose\" refers to?\\' is relevant as it seeks to understand the specific context or entity named Rose for a proper comparison.\"\\n        },\\n        {\\n            \"verdict\": \"yes\",\\n            \"reason\": \"The statement \\'What you are looking for in terms of a conceptually similar entity?\\' is relevant as it asks for the criteria or aspects to consider when identifying a conceptually similar entity to Rose.\"\\n        }\\n    ]}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_answer_kilt(answers, text) -> bool:\n",
    "    text = normalize_kilt(text)\n",
    "    for single_answer in answers:\n",
    "        single_answer = normalize_kilt(single_answer)\n",
    "        if single_answer in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# answer normalization\n",
    "def normalize_kilt(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in fileNames:\n",
    "#     evaluate_file('./data/'+file,'./eval/save/'+file,'./eval/error/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./eval/save/2-1_COPEN++csj_sample.json') as f:\n",
    "    data_view = json.load(f)\n",
    "noEvalItem = []\n",
    "for item in data_view['data']:\n",
    "    if len(item['cached_metrics_data']) <2:\n",
    "        noEvalItem.append(item)\n",
    "noEvalItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = noEvalItem[0]\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input= item['input'],\n",
    "    actual_output=item['actual_output'],\n",
    "    context=[item['expected_output']],\n",
    ")\n",
    "metric = AnswerRelevancyMetric(\n",
    "    threshold=0.5,\n",
    "    model = evaluateModel,\n",
    "    include_reason=True,\n",
    ")\n",
    "metric.measure(test_case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in [noEvalItem[0]]:\n",
    "    metrics_format_ins = {\n",
    "        'metric_metadata':{\n",
    "            'metric':None,\n",
    "            'success':True,\n",
    "            'score':0.8,\n",
    "            'reason':'',\n",
    "            'statements':'',\n",
    "            'verdicts':'',\n",
    "            'evaluationCost': 0\n",
    "        },\n",
    "        'metric_configuration': {\n",
    "            'threshold': 0.5,\n",
    "            'evaluation_model': 'CustomLLM',\n",
    "            'strict_mode': False,\n",
    "            'include_reason': True\n",
    "        }\n",
    "    }\n",
    "    test_case = LLMTestCase(\n",
    "        input= item['input'],\n",
    "        actual_output=item['actual_output'],\n",
    "        context=[item['expected_output']],\n",
    "    )\n",
    "    metric = AnswerRelevancyMetric(\n",
    "        threshold=0.5,\n",
    "        model = evaluateModel,\n",
    "        include_reason=True,async_mode=False\n",
    "    )\n",
    "    metric.measure(test_case)\n",
    "    \n",
    "    metrics_format_ins['metric_metadata']['metric'] = metric.__name__\n",
    "    metrics_format_ins['metric_metadata']['score'] = metric.score\n",
    "    metrics_format_ins['metric_metadata']['success'] = metric.is_successful()\n",
    "    metrics_format_ins['metric_metadata']['reason'] = metric.reason\n",
    "    \n",
    "    metrics_format_ins['metric_metadata']['statements'] = getattr(metric,'statements','')\n",
    "    metrics_format_ins['metric_metadata']['verdicts'] = str(getattr(metric,'verdicts',''))\n",
    "    metrics_format_ins['metric_metadata']['evaluationCost'] = metric.evaluation_cost\n",
    "\n",
    "    metrics_format_ins['metric_configuration']['threshold'] = metric.threshold\n",
    "    metrics_format_ins['metric_configuration']['strict_mode'] = metric.strict_mode\n",
    "    metrics_format_ins['metric_configuration']['evaluation_model'] = metric.evaluation_model\n",
    "    metrics_format_ins['metric_configuration']['include_reason'] = metric.include_reason\n",
    "    \n",
    "    print(metrics_format_ins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATH PROCESS AND EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/math401/math50.json') as f:\n",
    "#     data = json.load(f)\n",
    "# data_new  = {'fileName': data['fileName'],'data':[]}\n",
    "# for item in data['data']:\n",
    "#     data_format = {'id':item['id'],'input':item['input'],'expected_output':item['expected_output']}\n",
    "#     data_new['data'].append(data_format.copy())\n",
    "# with open('./data/math401/math50.json','w') as f:\n",
    "#     json.dump(data_new,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/math401/math50.json','r') as f:\n",
    "    data_eval  = json.load(f)\n",
    "data_eval['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/math401/save/infini-megrez-7b.json','r') as f:\n",
    "#     data_401 = json.load(f)\n",
    "#     data_401_new = {'fileName': data_401['fileName'],'data':[]}\n",
    "#     for item in data_401['data']:\n",
    "#         for x in data['data']:\n",
    "#             if item['input'] =='Only return the correct answer of the question.\\n'+ x['input']:\n",
    "#                 item['id'] = x['id']\n",
    "#                 item['is_correct'] = -1\n",
    "#                 data_401_new['data'].append(item.copy())\n",
    "# with open('./data/math401/save/infini-megrez-7b.json','w') as f:\n",
    "#     json.dump(data_401_new,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_result(filePath:Union[str,Path])->None:\n",
    "    \"\"\"\n",
    "    _summary_\n",
    "        the function is used to sort the results saved in the JSON `filepath` by `id` field\n",
    "        \n",
    "    Args:\n",
    "        `filePath` (Union[str,Path]): the JSON file path\n",
    "\n",
    "    Returns:\n",
    "        None: the result will override the original `filePath` \n",
    "    \"\"\"\n",
    "    with open(filePath,'r') as f:\n",
    "        data = json.load(f)\n",
    "    data['data'].sort(key = lambda x:x['id'])\n",
    "    with open(filePath,'w') as f:\n",
    "        json.dump(data,f,indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addField(file:Union[str,Path],field:str,default:Any)->None:\n",
    "    \"\"\"\n",
    "    _summary_\n",
    "        the function is used to add a field into the `.json` `file`\n",
    "\n",
    "    Args:\n",
    "        `file` (Union[str,Path]): the filename ,the file should be JSON file\n",
    "        `field` (str): the field name\n",
    "        `default` (Any): the default value of the added field,the value will add or subtract a Random from -500_000_000 to 500_000_000 if the field is `time`\n",
    "        \n",
    "    Returns:\n",
    "        None: the result will override the original `file` \n",
    "    \"\"\"\n",
    "    with open(file,'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data['data']:\n",
    "        if field not in item:\n",
    "            item[field] = default\n",
    "            if field == 'time':\n",
    "                item[field] += random.randint(-500_000_000,500_000_000)\n",
    "    with open(file,'w') as f:\n",
    "        json.dump(data,f,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir,subdir ,files in os.walk('./data/math401/save'):\n",
    "    for file in files:\n",
    "        addField(os.path.join(dir,file),'extract_answer',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumberAnswer(text:str)->Union[float,None]:\n",
    "    \"\"\"_summary_\n",
    "        the function is used to extract the number from the text\n",
    "\n",
    "    Args:\n",
    "        `text` (str): the text contains the number\n",
    "        \n",
    "    Returns:\n",
    "        Union[float,None]: the number in the `text`, or None if the `text` does not contain the number\n",
    "    \"\"\"\n",
    "    text = text.split('=')\n",
    "    if text:\n",
    "        text = text[-1]\n",
    "        regex = re.compile('([+-]?\\d+[,0-9]*[.]?[0-9]*)')\n",
    "        ret = regex.findall(text)\n",
    "        if ret:\n",
    "            return eval(ret[-1].replace(',',''))\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAnswer(file:Union[str,Path]):\n",
    "    \"\"\"\n",
    "    _summary_:\n",
    "        the function is used to process the answer that the LLM returned , namely extracting the number from the `actual_output` and save as `extract_answer`, and transform `expected_output` from str to number[int,float] \n",
    "\n",
    "    Args:\n",
    "        `file` (Union[str,Path]): the filename of the file saving the answer created by the LLM\n",
    "        \n",
    "    Returns:\n",
    "        None : the result will be written into the original `file`\n",
    "    \"\"\"\n",
    "    with open(file,'r') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data['data']:\n",
    "        if item['is_correct'] == -1:\n",
    "            item['extract_answer'] = getNumberAnswer(item['actual_output'])\n",
    "            item['expected_output'] = eval(item['expected_output'])\n",
    "            if item['extract_answer'] is None :\n",
    "                item['is_correct'] = 0\n",
    "            else:\n",
    "                item['is_correct'] =1 if abs(item['expected_output']-item['extract_answer']) < 1e-3 else 0\n",
    "    with open(file,'w') as f:\n",
    "        json.dump(data,f,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir,subdir ,files in os.walk('./data/math401/save'):\n",
    "    for file in files:\n",
    "        processAnswer(os.path.join(dir,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dir,subdir ,files in os.walk('./data/math401/save'):\n",
    "#     for file in files:\n",
    "#         with open(os.path.join(dir,file),'r') as f:\n",
    "#             data = json.load(f)\n",
    "#         for item in data['data']:\n",
    "\n",
    "#             if item['is_correct']:\n",
    "#                 item['is_correct'] = 1\n",
    "#             else:\n",
    "#                 item['is_correct'] = 0\n",
    "#         with open(os.path.join(dir,file),'w') as f:\n",
    "#             json.dump(data,f,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_accuracy(file:Union[str,Path],return_tuple:bool = False)->Union[float,tuple[str,float]]:\n",
    "    \"\"\"_summary_\n",
    "        the function calculates the accuracy of the model answers on the `math50` dataset saved in `file`\n",
    "\n",
    "    Args:\n",
    "        `file` (Union[str,Path]): the path to the JSON `file` containing a model answer results\n",
    "        `return_tuple` (bool, optional): if the value is True,the function will return a tuple (modelName,accuracy),else only return accuracy `[0,1]`. \n",
    "                    Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Union[float,tuple[str,float]]: if return_tuple is True,return a tuple containing both modelName and accuracy in format `(modelName:str,accuracy:float)`,else only return the accuracy in [0,1]\n",
    "    \"\"\"\n",
    "    with open(file,'r') as f:\n",
    "        data = json.load(f)\n",
    "    correct = 0\n",
    "    for item in data['data']:\n",
    "        correct += item['is_correct']\n",
    "    accuracy =  correct/len(data['data'])\n",
    "    if return_tuple:\n",
    "        return (data['model'],accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def calculate_nan_ratio(file:Union[str,Path],return_tuple:bool = False)->Union[float,tuple[str,float]]:\n",
    "    \"\"\"_summary_\n",
    "        the function calculates the no number ratio of the LLM answers on the `math50` dataset saved in `file`\n",
    "\n",
    "    Args:\n",
    "        `file` (Union[str,Path]): the path to the JSON `file` containing a model answer results\n",
    "        `return_tuple` (bool, optional): if the value is True,the function will return a tuple (modelName,nan_ratio),else only return nan_ratio `[0,1]`. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Union[float,tuple[str,float]]: if return_tuple is True,return a tuple containing both modelName and nan_ratio in format `(modelName:str,nan_ratio:float)`,else only return the nan_ratio in [0,1]\n",
    "    \"\"\"\n",
    "    with open(file,'r') as f:\n",
    "        data = json.load(f)\n",
    "    nan = 0\n",
    "    for item in data['data']:\n",
    "        if item['extract_answer'] is None:\n",
    "            nan += 1\n",
    "    nan_ratio = nan/len(data['data'])\n",
    "    if return_tuple:\n",
    "        return (data['model'],nan_ratio)\n",
    "    return nan_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RE(y_true,y_pred):\n",
    "    return min(10,abs(y_true-y_pred)/max(abs(y_true),1))\n",
    "def calculate_RE(file:Union[str,Path],return_tuple:bool = False)->Union[List[float],tuple[str,List[float]]]:\n",
    "    with open(file,'r') as f:\n",
    "        data = json.load(f)\n",
    "    RE_list = []\n",
    "    for item in data['data']:\n",
    "        ret = 0\n",
    "        y_true = item['expected_output']\n",
    "        y_pred = item['extract_answer']\n",
    "        if y_pred is None:\n",
    "            ret = 10\n",
    "        else:\n",
    "            ret = RE(y_true,y_pred)\n",
    "        RE_list.append(ret)\n",
    "    if return_tuple:\n",
    "        return (data['model'],RE_list)\n",
    "    return RE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list = {'eval':'math','eval_dataset':'math50.json','data':[]}\n",
    "# for dir,subdir ,files in os.walk('./data/math401/save'):\n",
    "#     for file in files:\n",
    "#         tmp = calculate_accuracy(os.path.join(dir,file),return_tuple=True)\n",
    "#         nan_ratio = calculate_nan_ratio(os.path.join(dir,file))\n",
    "#         RE_List = calculate_RE(os.path.join(dir,file))\n",
    "#         data_list['data'].append({'model':tmp[0],'Accuracy':tmp[1],'Nan_Ratio':nan_ratio,'RE_List':RE_List[:]})\n",
    "# with open('./data/math401/math50_eval_result.json','w') as f:\n",
    "#     json.dump(data_list,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalplus.data import get_human_eval_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_human_eval_plus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.get(\"HUMANEVAL_OVERRIDE_PATH\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/codeEval/data.json','r') as f:\n",
    "    data_eval = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 'HumanEval/12',\n",
       " 'prompt': 'from typing import List, Optional\\n\\n\\ndef longest(strings: List[str]) -> Optional[str]:\\n    \"\"\" Out of list of strings, return the longest one. Return the first one in case of multiple\\n    strings of the same length. Return None in case the input list is empty.\\n    >>> longest([])\\n\\n    >>> longest([\\'a\\', \\'b\\', \\'c\\'])\\n    \\'a\\'\\n    >>> longest([\\'a\\', \\'bb\\', \\'ccc\\'])\\n    \\'ccc\\'\\n    \"\"\"\\n',\n",
       " 'entry_point': 'longest',\n",
       " 'canonical_solution': '\\n    if not strings:\\n        return None\\n\\n    maxlen = max(len(x) for x in strings)\\n    for s in strings:\\n        if len(s) == maxlen:\\n            return s\\n\\n',\n",
       " 'test': \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([]) == None\\n    assert candidate(['x', 'y', 'z']) == 'x'\\n    assert candidate(['x', 'yyy', 'zzzz', 'www', 'kkkk', 'abc']) == 'zzzz'\\n\",\n",
       " 'contract': '\\n    assert type(strings) == list, \"invalid inputs\" # $_CONTRACT_$\\n    assert all([isinstance(v, str) for v in strings]), \"invalid inputs\" # $_CONTRACT_$\\n',\n",
       " 'base_input': [[[]],\n",
       "  [['x', 'y', 'z']],\n",
       "  [['x', 'yyy', 'zzzz', 'www', 'kkkk', 'abc']]],\n",
       " 'atol': 0,\n",
       " 'plus_input': [[['', 'a', 'aa', 'aaa']],\n",
       "  [['123456789', '1234', '12345', '123']],\n",
       "  [['a', 'b', 'aa', 'bb']],\n",
       "  [['dog', 'cat', 'horse', 'cow']],\n",
       "  [['apple', 'banana', 'pear']],\n",
       "  [['123', '12', '1234', '1', '12345']],\n",
       "  [['aa', 'bb', 'cc', 'aaa', 'bb', 'cccc']],\n",
       "  [['aaa', 'aa', 'a', 'aaaa']],\n",
       "  [['a']],\n",
       "  [['aa', 'z', 'p', 'q']],\n",
       "  [['aa', 'bb', 'cc', 'aaa', '123', 'cccc', 'cc', 'cccc']],\n",
       "  [['dog', 'cat', 'horse', 'cow', 'q']],\n",
       "  [['', 'a', 'aa', 'aaa', 'aa']],\n",
       "  [['apple', 'banana', 'banna', 'banana']],\n",
       "  [['aa', 'bb', 'cc', 'aaa', '123', 'cccc', 'cccc', 'ccaaa']],\n",
       "  [['', 'a', 'cow', 'aaa', 'aa']],\n",
       "  [['aa', 'z', 'p', 'qq']],\n",
       "  [['aa', 'apple', 'p', 'qq', 'apple']],\n",
       "  [['dog', 'cat', 'horse']],\n",
       "  [[]],\n",
       "  [['apple', 'banana', 'pear', 'horse', 'pear']],\n",
       "  [['aa', 'bb', 'cc', 'aaa', '1233', 'cccc', 'cccc', 'ccaaa']],\n",
       "  [['aa', 'bb', 'cc', 'aaa', '123', 'cccc', 'cc', 'cccc', '123']],\n",
       "  [['', 'a', '1234', 'dog', 'aa']],\n",
       "  [['aa', 'apple', 'p', 'qq', 'apple', 'p']],\n",
       "  [['cat', 'horse']],\n",
       "  [['dog', 'cat', 'horse', 'cow', 'hore', 'horse']],\n",
       "  [['aa', 'apple', 'p', 'qq', 'apple', 'p', 'p', 'aa']],\n",
       "  [['apple', 'banana', 'banna', 'banana', 'banana']],\n",
       "  [['apple', 'banana', 'pear', 'horse', 'pear', 'apple']],\n",
       "  [['aa', 'z', 'p', 'qq', 'aa', '']],\n",
       "  [['aa', 'cc', 'aaa', '123', 'cccc', 'cc', 'cccc', '123', 'aa']],\n",
       "  [['aa', 'bb', 'cc', 'aaa', 'bb', 'cccc', 'aa', 'aa']],\n",
       "  [['dog', 'cat']],\n",
       "  [['apple', 'p', 'qq', 'apple', 'p', 'pear']],\n",
       "  [['aaa', 'z', 'p', 'qq', 'qqq']],\n",
       "  [['', 'a', 'aa', 'aaa', 'aa', 'a']],\n",
       "  [['', 'hore', '', 'nWa', 'aaa', 'pear', 'wRQ', 'qq']],\n",
       "  [['', 'a', 'aaa', 'aa', 'a']],\n",
       "  [['aa', 'bb', 'cc', 'aaa', '123', 'cccc', 'ccaaa', 'ccaaa', 'aa']],\n",
       "  [['aa', 'bb', 'cc', 'aaa', '123', 'cccc', 'cc', '123']],\n",
       "  [['odog', 'catt']],\n",
       "  [['aa', 'bb', 'cc', 'aaa', 'bb', 'cccc', 'cccc']],\n",
       "  [['aa', 'bb', 'cc', 'aaa', 'bb', 'cccc', 'qaa', 'aa']],\n",
       "  [['dog', 'a', 'aa', 'aaa', 'aa', 'a', 'a']],\n",
       "  [['apple', 'banaana', 'pear', 'horse', 'pear', 'apple']],\n",
       "  [['', 'a', 'aaaa', 'a']],\n",
       "  [['dopearg', 'a', 'aa', 'aaa', 'aa', 'a', 'a']],\n",
       "  [['', 'a', 'aaa']],\n",
       "  [['dog', 'cat', 'horse', 'cow', 'cat']],\n",
       "  [['aaa', 'aa', 'a', 'aaaa', 'aa', 'qq']],\n",
       "  [['aa', 'bb', 'cc', 'aaa', 'bb', 'cccc', 'aa', 'aa', 'aaa']],\n",
       "  [['apple', 'banana', 'banna', 'banana', 'z']],\n",
       "  [['odog', 'ctatt']],\n",
       "  [['apple', 'banana', 'pear', 'horse', 'pear', 'odogpear', 'pear']],\n",
       "  [['', 'a', 'aa', 'aaa', '']],\n",
       "  [['', 'a', 'aaa', 'aa', 'a', 'bba']],\n",
       "  [['cat', 'horse', 'horcate']],\n",
       "  [['aa', 'p', 'qq', 'apple', 'p']],\n",
       "  [['aa', 'apple', 'p', 'qq', 'apple', 'pbanaana']],\n",
       "  [['apple', 'banana', 'banna', 'banana', 'z', 'babbnna']],\n",
       "  [['horse']],\n",
       "  [['dog', 'a', 'aaa', 'aa', 'a', 'a']],\n",
       "  [['aa', 'apple', 'p', 'qq', 'apple', 'p', 'aa', 'alpple']],\n",
       "  [['apple', 'banaa', 'pear']],\n",
       "  [['apple', 'banana', 'pear', 'pear', 'apple']],\n",
       "  [['aa',\n",
       "    'bb',\n",
       "    'cc',\n",
       "    'aaa',\n",
       "    '123',\n",
       "    'cccc',\n",
       "    'ccaaa',\n",
       "    'ccaaa',\n",
       "    'aa',\n",
       "    'ccaabanaanaa']],\n",
       "  [['1', 'a', 'cow', 'aaa', 'aa', 'a']],\n",
       "  [['apple', 'banana', 'horse', 'pear']],\n",
       "  [['p', 'cat', 'horse', 'cow']],\n",
       "  [['dog', 'cat', 'horse', 'cow', 'cat', 'cat']],\n",
       "  [['dog', 'cat', 'hrorse', 'cow', 'q']],\n",
       "  [['odog', 'catt', 'catt']],\n",
       "  [['apple', 'banaa', 'pear', 'abanaa']],\n",
       "  [['dog', 'cat', 'horse', 'w', 'q']],\n",
       "  [['apple', 'pear', 'horse', 'pear', 'apple']],\n",
       "  [['aa', 'apple', 'p', 'qq', 'apple', 'aa']],\n",
       "  [['apple', 'banana', 'banna', 'zbanna']],\n",
       "  [['a', 'a']],\n",
       "  [['1', 'a', 'cow', 'aaa', 'aa', 'a', '11234564789', 'babbnnaa']],\n",
       "  [['apple', 'banana', 'pear', 'banaana', 'apple']],\n",
       "  [['123', '12', '1234', '1', '12345', '123']],\n",
       "  [['aa', 'apple', 'p', 'qq', 'apple', 'p', 'ppp']],\n",
       "  [['aa', 'bb', 'cc', 'aaa', '123', 'cccc', 'cc', '123', '12345']],\n",
       "  [['apple', 'banana', 'pear', 'ppphorse', 'pear', 'odogpear', 'pear']],\n",
       "  [['1', 'a', 'bannacow', 'aaa', 'aa', 'a']],\n",
       "  [['1', 'a', 'bannaccow', 'aaa', 'aa', 'a']],\n",
       "  [['aa', 'apple', 'p', 'qq', 'apple', 'p', 'apple']],\n",
       "  [['apple', 'banana', 'zbanna']],\n",
       "  [['apple', 'banana']],\n",
       "  [['aa',\n",
       "    'bb',\n",
       "    'cc',\n",
       "    'aaa',\n",
       "    '123',\n",
       "    'cccc',\n",
       "    'cc',\n",
       "    '123',\n",
       "    '12345',\n",
       "    'cccc',\n",
       "    '3123']],\n",
       "  [['banana', 'pear', 'banaana', 'apple']],\n",
       "  [['odog', 'ctatat']],\n",
       "  [['apple', 'banaa', 'pear', 'apple']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '😀😀😀', '         ']],\n",
       "  [['', '        ', '   ', '     ', '\\t', '   \\t']],\n",
       "  [['', 'öäü', 'ß', 'Ø', 'æ', 'œ', '\\uf8ff']],\n",
       "  [['abc', 'defghijklmnop', '', 'qr']],\n",
       "  [['  a  ', 'bb', 'ccc']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii']],\n",
       "  [['hello', 'HOW', 'are', 'yOu', 'DOiNG', 'tODAY?']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '😀😀😀']],\n",
       "  [['abc', 'defghijklmnop', 'eeeeeeeeee', '', 'qr']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh']],\n",
       "  [['', '◯◯◯', 'bună ziua', '          ', ' ', '😀😀😀', '         ']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh']],\n",
       "  [['Apple',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['abc', 'defghijklmnop', '', 'qr', 'defghijklmnop']],\n",
       "  [['こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    'hello',\n",
       "    'r',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['abc', 'defghijklmnop', 'eeeeeeeeee', '']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'привет,',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhh']],\n",
       "  [['bc', 'defghijklmnop', 'eeeeeeeeee', '']],\n",
       "  [['', '        ', '   ', '     ', '\\t', '   ']],\n",
       "  [['abc', 'defghijklmnop', 'eeeeeeeeee', 'œ']],\n",
       "  [['hello', 'HOW', 'aare', 'tODAY?']],\n",
       "  [['eeeeeeeeeeabc', 'abc', 'defghijklmnop', 'eeeeeeeeee', 'defop', 'œ']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grrape',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['œdefghijklmnop', 'abc', 'defghijklmnop', 'eeeeeeeeee', 'œ']],\n",
       "  [['Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii']],\n",
       "  [['', '        ', '   ', '  Grrape   ', '\\t', '   \\t']],\n",
       "  [['Apple',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['◯◯◯', 'bună ziua', ' ', '😀😀😀', '         ']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22']],\n",
       "  [['bc', 'defghijklmnop', ' ', 'Fig', 'defghip', '']],\n",
       "  [['666666abc', 'defghijklmnop', '', 'qr', 'defghijklmnop', 'defghijklmnop']],\n",
       "  [['  a  ', 'bb']],\n",
       "  [['hello', 'HOW', 'are', 'yOu', 'DOiNG', 'tODAY?', 'yOu', 'DOiNG']],\n",
       "  [['abc', 'defghijklAvocadomnop', 'eeeeeeeeee', '', 'qr']],\n",
       "  [['привет,', 'defghijklmnop', '', 'qr', 'defghijklmnop', 'defghijklmnop']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '4444',\n",
       "    '9999999999',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '22']],\n",
       "  [['defghijklmnop', '', 'qr', 'defghijklmnop', 'yOu']],\n",
       "  [['abc', 'eeeeeeeeee', '', 'defghijklmnop']],\n",
       "  [['', 'bună ziua', '          ', ' ', '😀😀😀', '         ', 'bună ziua']],\n",
       "  [['hello',\n",
       "    'HOW',\n",
       "    'uyOuggggggggMangoggggg',\n",
       "    'are',\n",
       "    'uyOu',\n",
       "    'DOiNG',\n",
       "    'tODAY?',\n",
       "    'DOiNG']],\n",
       "  [['', 'bună ziua', '          ', ' ', '55555😀😀😀', '         ', 'bună ziua']],\n",
       "  [['', '◯◯◯', '          ', ' ', '😀', '         ']],\n",
       "  [['',\n",
       "    '        ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    '  Grrape   ',\n",
       "    '\\t',\n",
       "    '   \\t']],\n",
       "  [['defghijklmnop', '', 'hello', 'r', 'defghijklmnop', 'defghijklmnop']],\n",
       "  [['eeeeeeeeeee', 'bc', 'defghijklmnop', 'eeeeeeeeee', '']],\n",
       "  [['Apple',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Apple']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggMangoggggg']],\n",
       "  [['abc', 'defghijklmnop', 'привет,', 'qr', 'defghijklmnop']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '']],\n",
       "  [['HOW', 'are', 'yOu', 'DOiNG', 'tODAY?']],\n",
       "  [['defghijkllmnop',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    'hello',\n",
       "    'r',\n",
       "    'defghijklmnop',\n",
       "    'bb',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [[' ', '', '        ', '  Grrape   ', '\\t', '   \\t']],\n",
       "  [['eeeeeeeeeeabc',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'eeeeeeeeee',\n",
       "    'defop',\n",
       "    'defghijklminop',\n",
       "    'œ',\n",
       "    'eeeeeeeeeee',\n",
       "    'defghijklmnop']],\n",
       "  [['1',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22']],\n",
       "  [['hello',\n",
       "    'HOW',\n",
       "    'uyOuggggggggMangoggggg',\n",
       "    'are',\n",
       "    'Helbblo',\n",
       "    'uyOu',\n",
       "    'DOiNG',\n",
       "    'tODAY?',\n",
       "    'DOiNG']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '😀😀😀', '         ', '◯◯◯']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '😀😀😀', '         ', '◯◯']],\n",
       "  [['hello', 'areHOW', 'are', 'yOu', 'DOiNG', 'tODAY?']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Hola,',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['',\n",
       "    '        ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    '  Grrape   ',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '\\t',\n",
       "    '   \\t']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', 'Durian']],\n",
       "  [['', '◯◯◯', ' ', '', '         ']],\n",
       "  [['Apple',\n",
       "    'Cherrry',\n",
       "    'Avocado',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Hola,',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['Apple',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'defghijklminop',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['Apple',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Dur',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Grape']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defghijklmnop',\n",
       "    'yOu']],\n",
       "  [['abc', 'defghijklAvocadomnop', 'eeeeeeeeee', 'Orange', '', 'qr']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Graape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['   ', '', '        ', '   ', '\\t', '   ']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'hhhhhhhhhhhhhhhhhello',\n",
       "    'r',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ffffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii']],\n",
       "  [['666666abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    '666666bc',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['', '        ', '   ', '     ', '   \\t']],\n",
       "  [['œdefghijklmnop',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'eeeeeeeeee',\n",
       "    'œ',\n",
       "    'eeeeeeeeee']],\n",
       "  [['こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'прccccccccивет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Blueberry',\n",
       "    'hhhhhhhhhhhhhhh',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Graape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['bc', 'areHOW', 'defghijklmnop', ' ', 'Fig', 'defghip', 'HOW', '']],\n",
       "  [['ccccпривет,cccc',\n",
       "    'aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggMangoggggg']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'hello',\n",
       "    'r',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'HelloBonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['dœdefghijklmnopep',\n",
       "    'œdefghijklmnop',\n",
       "    'abc',\n",
       "    'dep',\n",
       "    'defghijklmnop',\n",
       "    'eeeeeeeeee',\n",
       "    'œ']],\n",
       "  [['HOW', 'are', 'yOu', 'tODAY?']],\n",
       "  [['◯ß◯◯', '', '◯◯◯', 'Hola,Mango', ' ']],\n",
       "  [['', '        ', '◯◯◯', '   ', '     ', '\\t', '   \\t']],\n",
       "  [['bc', '◯◯◯', 'bună ziua', ' ', '😀😀😀', '         ']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'aaaaa',\n",
       "    'ddddddddd',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggMangoggggg']],\n",
       "  [['aaaaa',\n",
       "    'aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'iiiiiiiiiiiiiiiiiii']],\n",
       "  [['ccccпривет,cccc',\n",
       "    'aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'œ',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggMangoggggg']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grrape',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'MangoCherrry',\n",
       "    'Orange']],\n",
       "  [['Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['defopß', '', 'öäü', 'ß', 'Ø', 'æ', 'œ', '\\uf8ff']],\n",
       "  [['æ',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['', '◯◯◯', 'bună ziua', 'bună ziuddddddddda', ' ', '  ', 'Durian']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'こんにちは, Bonjour, Hel        lo, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    'привет']],\n",
       "  [['',\n",
       "    '         ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    '  Grrape   ',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '\\t',\n",
       "    '   \\t']],\n",
       "  [['1',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '22']],\n",
       "  [['abc', 'defghijklmnop', 'привет,999999999', 'qr', 'defghijklmnop']],\n",
       "  [['   ', '', '        ', '   ', '88888888\\t', '   ', '   ']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Helolo, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'こんにちは, Bonjour, Hel        lo, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    'привет']],\n",
       "  [['Apple',\n",
       "    'Banana',\n",
       "    'lo,',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'defghijklminop',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['   ',\n",
       "    '',\n",
       "    '        ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    '   ',\n",
       "    '88888888\\t',\n",
       "    '   ',\n",
       "    '   ']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Blueberry',\n",
       "    'hhhhhhhhhhhhhhh',\n",
       "    'Fig',\n",
       "    'Graape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Banana']],\n",
       "  [['defghijklmnop', 'eeeeeeeeee', 'qr', 'defghkijklmnop', 'yOu']],\n",
       "  [['hello', 'HOW', 'tODAYпривет,D?', 'aare', 'tODAY?']],\n",
       "  [['  ', '◯ß◯◯', '', '◯◯◯', ' ']],\n",
       "  [[' ', '', 'hhhhhhhhhhhhhhhh', '  Grrape   ', 'bc', '   \\t']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Blueberry',\n",
       "    'hhhhhhhhhhhhhhh',\n",
       "    'Durian',\n",
       "    'Graape',\n",
       "    'Kiwii',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['abc', 'defghijklmnop', '', 'hello', 'defghijklmnop', 'defghijklmnop']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defghijklmnop',\n",
       "    'yOu',\n",
       "    'defghijklmnop']],\n",
       "  [['666666abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    '666666bc',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    '66666abc',\n",
       "    'defghijklmnop']],\n",
       "  [['areHOW  a  ', 'bb', 'ccc']],\n",
       "  [['eeeeeeeeeeabc',\n",
       "    'abc',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defghijklmnpop',\n",
       "    'eeeeeeeeee',\n",
       "    'defop',\n",
       "    'œ']],\n",
       "  [['bc', 'defghijmklmnop', 'eeeeeeeeee', '']],\n",
       "  [['  a  ',\n",
       "    'hello',\n",
       "    'HOW',\n",
       "    'uyOuggggggggMangoggggg',\n",
       "    'are',\n",
       "    'uyOu',\n",
       "    'DOiNG',\n",
       "    'tODAY?',\n",
       "    'DOiNG']],\n",
       "  [['666666abc',\n",
       "    'defkghijklmnop',\n",
       "    '',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['abc',\n",
       "    'defghijklmnop',\n",
       "    'Helbblo',\n",
       "    'hello',\n",
       "    'r',\n",
       "    'defghijkilmnop',\n",
       "    '◯◯',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['', '◯◯◯', 'bună ziua', '😀😀😀', '         ']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Helolo, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'こんにちは, Bonjour, Hel        lo, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['666666', 'æ', 'ccc']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defghijklmnop',\n",
       "    'yOu',\n",
       "    'yOu']],\n",
       "  [['dœdefghijklmnopep', 'abc', 'dep', 'bună ziua', 'eeeeeeeeee', 'œ']],\n",
       "  [['abc', 'defghijklmnop', '', 'こんにちは,', 'defghijklmnop', 'defghijklmnop']],\n",
       "  [['◯◯◯', 'bună ziua', 'defghijkllmnop', ' ', '😀😀😀', '         ']],\n",
       "  [['areHOW  a  ', 'MangoCherrry', 'ccc']],\n",
       "  [['fghijklmnop',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defghijklmnop',\n",
       "    'yOu']],\n",
       "  [['abc',\n",
       "    'defghijklmnop',\n",
       "    'eeeeeeeeee',\n",
       "    'defop',\n",
       "    'defghijklminop',\n",
       "    'œ',\n",
       "    'eeeeeeeeeee',\n",
       "    'defghijklmnop']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '4444',\n",
       "    '9999999999',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '22']],\n",
       "  [['666666', 'æ', '666666']],\n",
       "  [['  a  ', 'bb', 'ccc', 'bb', 'bb']],\n",
       "  [['HOW', 'yOu', 'DOiNG', 'tODAY?']],\n",
       "  [['◯◯◯', 'bună ziua', ' ', '😀😀😀', '         ', 'bună ziua']],\n",
       "  [['', 'öäü', 'ß', 'Ø', '', 'œ', '\\uf8ff']],\n",
       "  [['defghijmklmnop',\n",
       "    '',\n",
       "    'bună ziua',\n",
       "    '          ',\n",
       "    ' ',\n",
       "    '55555😀😀😀',\n",
       "    '         ',\n",
       "    'bună ziua',\n",
       "    '55555😀😀😀']],\n",
       "  [['abc', 'defghijklmnop', 'hello', '', 'defghijklmnop', 'defghijklmnop']],\n",
       "  [['HOW', ' ', 'DOiNG']],\n",
       "  [['abc', 'привет,999999999', 'qr', 'defghijklmnop']],\n",
       "  [['abc',\n",
       "    'Blueberry',\n",
       "    'defghijklmnop',\n",
       "    'Helbblo',\n",
       "    'hello',\n",
       "    'r',\n",
       "    'defghijkilmnop',\n",
       "    '◯◯',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['666666abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    '666666bc',\n",
       "    'defghijklmnop',\n",
       "    '66666abc',\n",
       "    'defghijklmnop']],\n",
       "  [['◯ß◯◯', '', '◯◯◯', 'œ', 'привет, Hola, Bonjour, こんにちは, Hello', ' ']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'HelloBonjour, こんにちは, Hola, привет',\n",
       "    'dep',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['666666', 'æ', 'ccc', '666666']],\n",
       "  [['defopß', '◯◯◯', 'bună ziua', ' ', 'Durian']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'hello',\n",
       "    'r',\n",
       "    'defghijklmnop',\n",
       "    'Helolo,',\n",
       "    'defghijklmnop']],\n",
       "  [['eeeeeeeeeeabc', 'abc', 'eeeeeeeeee', 'defop', 'œ']],\n",
       "  [['Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет']],\n",
       "  [['1',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '9999999999',\n",
       "    '22']],\n",
       "  [['defg  klmnop',\n",
       "    'defghijklmnop',\n",
       "    'fghijklmnopyOu',\n",
       "    '',\n",
       "    'a',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defghijklmnop',\n",
       "    'yOu',\n",
       "    'defghijklmnop']],\n",
       "  [['666666abc',\n",
       "    'qqr',\n",
       "    'defkghijklmnop',\n",
       "    '',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['defghijklmnop', '', 'r', 'defghijklmnop', 'defghijklmnop']],\n",
       "  [['', 'привет, Hola, Bonjour, こんにちは, Hello', 'ß', 'Ø', '', 'œ', '\\uf8ff']],\n",
       "  [['abc', 'defghijklmnop', 'abcHelolo,', 'qr', 'abbc', 'defghijklmnop']],\n",
       "  [['Apple',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Dur',\n",
       "    'Grape',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Grape']],\n",
       "  [['',\n",
       "    '◯◯◯',\n",
       "    'bună ziua',\n",
       "    '          ',\n",
       "    '7777777',\n",
       "    ' ',\n",
       "    '😀😀😀',\n",
       "    '         ',\n",
       "    '          ']],\n",
       "  [['◯◯◯',\n",
       "    'defghijkilmnopbună ziua',\n",
       "    'defghijkllmnop',\n",
       "    ' ',\n",
       "    '😀😀😀',\n",
       "    '         ']],\n",
       "  [['hello', 'tODAYпривет,D?', 'aare', 'tODAY\\t?']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mangodefghijkilmnopbună ziua привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mangodefghijkilmnopbună ziua привет']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'MangoCherrry',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh']],\n",
       "  [['ccccпривет,cccc',\n",
       "    'aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'areHOWfffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggMangoggggg']],\n",
       "  [['HelloBonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'привет, Hola, ちは, Hello',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    'HelloBonjour, こんにちは, Hola, привет']],\n",
       "  [['abc',\n",
       "    'defghijklmnop',\n",
       "    'привет,999999999',\n",
       "    'abcc',\n",
       "    'qr',\n",
       "    'defghijklmnop']],\n",
       "  [['dœdefghijklmnopep', 'abc', 'bună ziua', 'eeeeeeeeee', 'œ']],\n",
       "  [['abc', 'defghijklAvocadomnop', 'eeeeeeeeee', 'Orange', '', 'qr', 'abc']],\n",
       "  [['abc',\n",
       "    'defghijklmnop',\n",
       "    'eeeeeeeeee',\n",
       "    'defop',\n",
       "    'defghijklminop',\n",
       "    '',\n",
       "    'eeeeeeeeeHello, Bonjour, こんにちは, Hola, приветee',\n",
       "    'defghijklmnop']],\n",
       "  [['',\n",
       "    '         ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defkghijklmnop',\n",
       "    '  Grrape   ',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '\\t',\n",
       "    '   \\t']],\n",
       "  [['',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defkghijklmnop',\n",
       "    '  Grrape   ',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '\\t',\n",
       "    '   \\t']],\n",
       "  [['HOW', '', 'bună ziua', '          ', ' ', '😀😀😀', 'bună ziua']],\n",
       "  [['tODAY\\t?',\n",
       "    'defghijklAvocadomnop',\n",
       "    'eeeeeeeeee',\n",
       "    'Orange',\n",
       "    '',\n",
       "    'qaaaaar']],\n",
       "  [['', '        ', '◯◯◯', '   ', '     ', '\\t']],\n",
       "  [['Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Dun',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['  a  ',\n",
       "    'bb',\n",
       "    'defop',\n",
       "    'ccc',\n",
       "    'bb',\n",
       "    'bb',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'bb']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'Cherry',\n",
       "    'cccccccc',\n",
       "    'MangoCherrry',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggggggg']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Helolo, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['', 'bună ziua', '          ', ' ', '😀😀😀', 'bună ziua']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'привет, aaaaelbblo',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defghijklmnop',\n",
       "    'прdefkghijklmnopивет, aaaaelbblo',\n",
       "    'yOu',\n",
       "    'yOu']],\n",
       "  [['  a  ', 'bb', 'Lemon']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '', 'bună ziua']],\n",
       "  [[' ', '', '        ', '◯◯◯', '  Grrape   ', '\\t', '   \\t', '  Grrape   ']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'ffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggManggoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhh',\n",
       "    'ggggggggMangoggggg']],\n",
       "  [['abc',\n",
       "    'Blueberry',\n",
       "    'defghijklmnop',\n",
       "    'Helbblo',\n",
       "    'hhhhhhhhhhhhhhh',\n",
       "    'hello',\n",
       "    'r',\n",
       "    'defghijkilmnop',\n",
       "    '◯◯',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['abc',\n",
       "    'defgdefghijkilmnopbună ziuahijklmnop',\n",
       "    'eeeeeeeeee',\n",
       "    'defop',\n",
       "    'defghijklminop',\n",
       "    'defghijklmino',\n",
       "    'œ',\n",
       "    'eeeeeeeeeee',\n",
       "    'defghijklmnop']],\n",
       "  [['abc', 'bună ziua', 'eeeeeeeeee', 'œ']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'tODAY',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет',\n",
       "    'こんにちは, Bonjour, Hel        lo, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['◯ß◯◯',\n",
       "    '',\n",
       "    '◯◯◯',\n",
       "    'œggggggggggggg',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello']],\n",
       "  [['◯◯◯', 'bună ziua', ' ', '         ']],\n",
       "  [['hello',\n",
       "    'HOW',\n",
       "    'uyOuggggggggMangoggggg',\n",
       "    'are',\n",
       "    '   \\t',\n",
       "    'DOiNG',\n",
       "    'tziuahijklmnopODAY?',\n",
       "    'DOiNG',\n",
       "    'DOiNG']],\n",
       "  [['Apple',\n",
       "    'Banana',\n",
       "    'lo,',\n",
       "    'Blueberryy',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'defghijklminop',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['abc', '', 'defghijklmnop']],\n",
       "  [['abc', 'defghijklmnop', '\\t', 'eeeeeeeeee', 'œ']],\n",
       "  [['œdefghijklmnop',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'eeeeeeeeee',\n",
       "    'œ',\n",
       "    'eeeeeeeeee',\n",
       "    'defghijklmnop']],\n",
       "  [['666666abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    'defkghijklmnop',\n",
       "    '666666bc',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    '66666abc',\n",
       "    'defghijklmnop']],\n",
       "  [['eeeeeeeeeee', 'bc', 'defghijklmnop', 'привет, Hola, ちは, Hello', '']],\n",
       "  [['abc', 'defghijklAvocadomnop', 'eeeeeeeeee', 'Orange', '', 'qr', 'qr']],\n",
       "  [['defopß', '', '', 'öäü', 'ß', 'Ø', 'æ', 'œ', '\\uf8ff']],\n",
       "  [['abc', 'defghijklmnop', 'eeeeeeeeee', '', 'eeeeeeeeee']],\n",
       "  [['bc', 'defghijklmnop', 'eeeeeeeeee', 'eeeeeeee', '']],\n",
       "  [['',\n",
       "    '         ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    '  Gr rape   ',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '\\t',\n",
       "    '   \\t']],\n",
       "  [['eeeeeeeeeeabc',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'eeeeeeeeee',\n",
       "    'defop',\n",
       "    'defghijklminop',\n",
       "    'œ',\n",
       "    'eeeeeeeeeee',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['22',\n",
       "    '4444',\n",
       "    '9999999999',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    'defghip',\n",
       "    '999999999',\n",
       "    '22']],\n",
       "  [['',\n",
       "    '         ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defkghijklmnop',\n",
       "    '  Grrape   ',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '   \\t']],\n",
       "  [['aaaaa',\n",
       "    'aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'fffffffffff',\n",
       "    'iiiiiiiiiiiiiiiiiii']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'Cherry',\n",
       "    'cccccccc',\n",
       "    'MangoCherrry',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggggggg',\n",
       "    'cccccccc',\n",
       "    'ddddddddd']],\n",
       "  [[' ', '', 'hhhhhhhhhhhhhhhh', '  Grrape   ', 'bc', '   \\t', '   \\t']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '😀😀😀', '         ', 'rape']],\n",
       "  [['\\t', 'eeeeeeeeeee', 'bbbc', 'defghijklmnop', '']],\n",
       "  [['HOW', 'are', 'yOu', 'tODAY?', 'yOu']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '4444',\n",
       "    '55  a  555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22']],\n",
       "  [['◯◯◯Apple', 'bună ziua', '😀😀😀', '         ']],\n",
       "  [['defghijklAvocadomnop',\n",
       "    'eeeeeeeeee',\n",
       "    'Orange',\n",
       "    '',\n",
       "    'abc',\n",
       "    'defghijklAvocadomnop']],\n",
       "  [['hello',\n",
       "    'uyOuggggggggMangoggggg',\n",
       "    'DiOiNG',\n",
       "    'are',\n",
       "    '   \\t',\n",
       "    'DOiNG',\n",
       "    'tziuahijklmnopODAY?',\n",
       "    'DOiNG',\n",
       "    'DOiNG']],\n",
       "  [['œdefghijklmnop', 'abc', 'defghijklmnop', '          ', 'œ']],\n",
       "  [['', 'hello', 'defghijklmnop', 'defghijklmnop']],\n",
       "  [['', '◯◯◯', '', '         ', '         ']],\n",
       "  [['abc', 'bună zdœdefghijklmnopepiua', 'eeeeeeeeee', 'œ']],\n",
       "  [['HOW', 'are', 'yOu', 'ziua', 'tODAY?', 'yOu', 'are']],\n",
       "  [['abc', 'defghijklmnop', 'eeeeeeeeee', 'aaaaa', '']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '77777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '22']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '10000000000']],\n",
       "  [['◯◯◯◯', '', '◯◯◯', 'bună ziua', '', ' ', '']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'Grape',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh']],\n",
       "  [['abc', 'defghijklmnop', 'Hel', 'eeeeeeeeee', 'œ']],\n",
       "  [['eeeeeeeeeee', 'bc', 'defghijklmnop', 'привет, Hola, ちは, Hello', '', '']],\n",
       "  [['', '◯◯◯', 'bună ziua          ', 'bună ziua', '']],\n",
       "  [['HW', 'HOW', ' ', 'DOiNG']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'привет,',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggggabccggg',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhh']],\n",
       "  [['  a  ',\n",
       "    'bb',\n",
       "    'defop',\n",
       "    'ccc',\n",
       "    'bbb',\n",
       "    'bb',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'bb']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '', 'bună ziua', 'bună ziua']],\n",
       "  [['666666abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    '666666bc',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['areHOW  a  ', 'MangoCherrry', 'ccddddddddd', 'ccc']],\n",
       "  [['', '◯◯◯', 'bună ziua', '😀😀😀', '         ', '']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'r',\n",
       "    'defghijklmnop',\n",
       "    'Helolo,',\n",
       "    'dHelloBonjour,efghijklmnop']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    '666666bc',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defghijklmnop',\n",
       "    'yOu',\n",
       "    'defghijklomnop',\n",
       "    'defghijklmnop']],\n",
       "  [[' ', '', '        ', '  Grrape   ', 'ß', '   \\t', ' ', ' ']],\n",
       "  [['Banana',\n",
       "    'Blueberry',\n",
       "    'Chrerry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['',\n",
       "    '         ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defkghijklmnop',\n",
       "    '  Grrape   ',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '555',\n",
       "    '   \\t',\n",
       "    '   \\t',\n",
       "    '',\n",
       "    '\\t']],\n",
       "  [['uyOu',\n",
       "    'bc',\n",
       "    'areHOW',\n",
       "    'defghijklmnop',\n",
       "    ' ',\n",
       "    'Fig',\n",
       "    'defghip',\n",
       "    'HOWW',\n",
       "    'HOW',\n",
       "    '']],\n",
       "  [['tODAY\\t?',\n",
       "    'defghijklAvocadomnop',\n",
       "    'eeeeeeeeee',\n",
       "    'Orange',\n",
       "    '',\n",
       "    'qaaaaar',\n",
       "    'eeeeeeeeee']],\n",
       "  [['◯◯◯◯', '', '◯◯◯', 'bună ziua', '', ' ', '10000000000']],\n",
       "  [['', 'Hola,', '◯◯◯', 'bună ziua', ' ', '😀😀😀', '         ', 'rape']],\n",
       "  [['  a  ', 'bb', 'HW', 'ccc']],\n",
       "  [['', '◯◯◯', '', '         ', '         ', '         ']],\n",
       "  [['   \\t', '  ', '😀', '', '◯◯◯', ' ']],\n",
       "  [['',\n",
       "    '         ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    '  Gr rape   ',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '\\t',\n",
       "    '4444']],\n",
       "  [['HOW', 'こんにちは,', 'yOu', 'tODAY?']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'aaaa']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ']],\n",
       "  [['◯ß◯◯', '◯◯◯', 'œ', 'привет, Hola, Bonjour, こんにちは, Hello', ' ']],\n",
       "  [['1', '4444', '55555', '7777777', '999999999', '10000000000', '22']],\n",
       "  [['1',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '77777777',\n",
       "    '999cccccccc999999',\n",
       "    '10000000000',\n",
       "    '22']],\n",
       "  [['', '◯◯◯', '◯◯◯◯', '', '         ', '         ', '         ']],\n",
       "  [['bc', 'defghijklmnop', 'hhhhhhhhhhhhhhhhhello', 'eeeeeeeeee', '']],\n",
       "  [['abc',\n",
       "    'bbbc',\n",
       "    '',\n",
       "    'こんにちは,',\n",
       "    'Hola,Mango',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['', '◯◯◯', '', '         ', '         ', '         ', '         ']],\n",
       "  [['Helolo, Bonjour, こんにちは, Holaöäü, привет',\n",
       "    'Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Helolo, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Helloa, Hola, привет',\n",
       "    'привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Graape',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'defopß',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grrape',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'MangoCherrry',\n",
       "    'Orange']],\n",
       "  [['aaaa',\n",
       "    'bggggggggManggogggggbbb',\n",
       "    'cccccccc',\n",
       "    'Grape',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'cccccccc']],\n",
       "  [['bb',\n",
       "    '1',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '9999999999',\n",
       "    '22']],\n",
       "  [['こんにちは,', 'yOu', 'aaaa', 'aaaa ', 'yOu']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'привет,',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggggabccggg',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhh']],\n",
       "  [['defopß', 'öäü', 'ß', 'Ø', 'æ', 'œ', '\\uf8ff']],\n",
       "  [['dœdefghijklmnopep', 'Dun', 'abc', 'dep', 'bună ziua', 'eeeeeeeeee', 'œ']],\n",
       "  [['abc',\n",
       "    'defghijklAvocadomnop',\n",
       "    'eeeeeeeeee',\n",
       "    'Orange',\n",
       "    '999999999',\n",
       "    '',\n",
       "    'qr',\n",
       "    'abc']],\n",
       "  [['1',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    'Hello',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '9999999999',\n",
       "    '22']],\n",
       "  [['abc',\n",
       "    'defghijklmnop',\n",
       "    'привет,999999999',\n",
       "    'abcc',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    'qr']],\n",
       "  [['',\n",
       "    '         ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defkghijklmnop',\n",
       "    '  Grrape   ',\n",
       "    '\\t',\n",
       "    '  ziuahijklmnop \\t',\n",
       "    '   \\t',\n",
       "    '555',\n",
       "    '   \\t',\n",
       "    '   \\t',\n",
       "    '',\n",
       "    '\\t']],\n",
       "  [['abc', '\\t', 'eeeeeeeeee', 'œ']],\n",
       "  [['',\n",
       "    '         ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    '  Gr rape   ',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '\\t',\n",
       "    '4444',\n",
       "    '         ']],\n",
       "  [['abc',\n",
       "    '1',\n",
       "    'defghijklmnop',\n",
       "    'привет,999999999',\n",
       "    'abcc',\n",
       "    'qr',\n",
       "    'defghijklmnop']],\n",
       "  [['привет', '  a  ', 'bb']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'ffabcfffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh']],\n",
       "  [['666666abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    '666666bc',\n",
       "    'qr',\n",
       "    '66666abc',\n",
       "    'defghijklmnop']],\n",
       "  [['666666abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    '666666bc',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    '66666abc',\n",
       "    'defghijklmnbună zdœdefghijklmnopepiuaop']],\n",
       "  [['10000000000',\n",
       "    ' ',\n",
       "    '',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    '  Grrape   ',\n",
       "    'bc',\n",
       "    '   \\t',\n",
       "    '   \\t']],\n",
       "  [['', 'öäü', 'ß', 'Ø', 'æ', 'œ', '\\uf8ff', '']],\n",
       "  [['22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000']],\n",
       "  [['◯ß◯◯', '', '◯◯◯', 'œggggggggggggg']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'HelloBonjour, こんにちは, Hola, привет',\n",
       "    'eeeeeeeeeee',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'defgdefghijkilmnopbună ziuahijklmnop',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'eeeeeeeeee']],\n",
       "  [['defghijklmnop',\n",
       "    'こんにちは, Bonjour, Hel        lo, Hola, привет',\n",
       "    'defkghijklmnop',\n",
       "    '666666bc',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    '66666abc',\n",
       "    'defghijklmnop',\n",
       "    'defkghijklmnop']],\n",
       "  [['666666abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    'defkghijklmnop',\n",
       "    '666666bc',\n",
       "    'defghijklmnop',\n",
       "    '66666abc',\n",
       "    'bbbc',\n",
       "    'defghijklmnop']],\n",
       "  [['aabc',\n",
       "    'defghijklmnop',\n",
       "    'abcHelolo,',\n",
       "    'ziuddddddddda',\n",
       "    'qr',\n",
       "    'abbc',\n",
       "    'qr']],\n",
       "  [['',\n",
       "    '         ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defkghijklmnop',\n",
       "    '  Grrape   ',\n",
       "    '\\t',\n",
       "    '  ziuahijklmnop \\t',\n",
       "    '   \\t',\n",
       "    '555',\n",
       "    '   \\t',\n",
       "    '   \\t',\n",
       "    '',\n",
       "    '\\t',\n",
       "    '\\t',\n",
       "    '',\n",
       "    '   \\t']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Helolo, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'こんにちは, Bonjour, Hel        lo, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    'привет',\n",
       "    'привет']],\n",
       "  [['Helolo, Bonjour, こんにちは, Holaöäü, привет',\n",
       "    'Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Helolo, Bonjour, こんにちは, Holaöärивет',\n",
       "    'Helolo, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Helloa, Hola, привет',\n",
       "    'привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Hola,',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Avocado']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'ffabcfffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'hhhhhhhhhhhhhhhhh',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh']],\n",
       "  [['',\n",
       "    'Hola,',\n",
       "    '◯◯◯',\n",
       "    'bună ziua',\n",
       "    ' привет,',\n",
       "    ' ',\n",
       "    '😀😀😀',\n",
       "    '         ',\n",
       "    'rape']],\n",
       "  [['hello', 'HOW', 'bună ziuaaare', 'tODAY?']],\n",
       "  [['abc', 'defghijklmnop', 'eeeeeeпрdefkghijklmnopивет,eeee', '', 'qr']],\n",
       "  [['defopß', 'üöäü', 'ß', 'æ', 'œ', '\\uf8ff']],\n",
       "  [['œdefghijklmnop', 'abc', '          ', 'œ']],\n",
       "  [['abc',\n",
       "    'Blueberry',\n",
       "    'fffffffffff',\n",
       "    'defghijklmnop',\n",
       "    'Helbblo',\n",
       "    'hello',\n",
       "    'r',\n",
       "    'defghijkilmnop',\n",
       "    '◯◯',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['Hello, Hlola, Bonjour, こんにちは, привет',\n",
       "    'HelloBonjour, こんにちは, Hola, привет',\n",
       "    'dep',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['aaaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'fffffffffff',\n",
       "    'iiiiiiiiiiiiiiiiiii']],\n",
       "  [['',\n",
       "    '         ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defkghijklmnop',\n",
       "    '  Grrape   ',\n",
       "    '\\t',\n",
       "    '  ziuklmnop \\t',\n",
       "    '   \\t',\n",
       "    '555',\n",
       "    '   \\t',\n",
       "    '   \\t',\n",
       "    '',\n",
       "    '\\t']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'こんにちは, Bonjour, Hel        lo, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'ffabcfffffffff',\n",
       "    'bună ziua',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh']],\n",
       "  [['eeeeeeeeeee', 'bc', 'defghijklmnop', 'eeeeeeeeee', '', 'eeeeeeeeeee']],\n",
       "  [['acbc', 'eeeeeeeeee', 'Orange', '', 'OranUNQHge', 'qr', 'qr']],\n",
       "  [['bbbc', '', 'こんにちは,', 'Hola,Mango', 'defghijklmnop', 'defghijklmnop']],\n",
       "  [['abc',\n",
       "    '\\t',\n",
       "    'defghijklAvocadomnop',\n",
       "    'eeeeeeeeee',\n",
       "    'eeeeeeeee',\n",
       "    '',\n",
       "    'adefghijklmino',\n",
       "    'qr']],\n",
       "  [['eeeeeeeeeee', 'bc', 'привет, Hola, ちは, Hello', '']],\n",
       "  [['bb', 'HW', 'ccc']],\n",
       "  [['hello', 'HOW', 'are', 'yOu', 'DOiNG', 'tODAY?', 'tODAY?']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'Cherry',\n",
       "    'aaa',\n",
       "    'cccccccc',\n",
       "    'MangoCherrry',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggggggg',\n",
       "    'aaaa']],\n",
       "  [['abc',\n",
       "    'defgdefghijkilmnopbună ziuahijklmnop',\n",
       "    'eeeeeeeeee',\n",
       "    'defop',\n",
       "    'defghijklminop',\n",
       "    'eeeeeeeee',\n",
       "    'defghijklmino',\n",
       "    'œ',\n",
       "    'eeeeeeeeeee',\n",
       "    'defghiljklmnop']],\n",
       "  [['bc', '◯◯◯', 'ziuahijklmnop', 'bună ziua', ' ', '         ']],\n",
       "  [['abc',\n",
       "    'defghijklAvocadomnop',\n",
       "    'eeeeeeeeee',\n",
       "    'Orange',\n",
       "    'a  ziuahijklmnop \\tbc',\n",
       "    '',\n",
       "    'qr',\n",
       "    'abc']],\n",
       "  [['œdefghijklmnop', 'abc', 'defghijklmnop', 'eeeeeeeeee']],\n",
       "  [['',\n",
       "    'DiOiNG',\n",
       "    '        ',\n",
       "    '◯◯◯',\n",
       "    '   ',\n",
       "    '     ',\n",
       "    '     ',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '        ']],\n",
       "  [['Apple',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'defghijklminop',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'eeeeeeeeee',\n",
       "    'Orange']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Graape',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'defopß',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grrape',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'eqqre',\n",
       "    'MangoCherrry',\n",
       "    'Orange']],\n",
       "  [['bc', 'eeeeeeeeee', '']],\n",
       "  [['Cherrry',\n",
       "    '666666abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    'ggggggggggggg',\n",
       "    'defghijklmnop',\n",
       "    '66666abc',\n",
       "    'defghijklmnop']],\n",
       "  [['eeeeeeeeeeabc', 'abc', '999999999', 'defop', 'œ', 'eeeeeeeeee']],\n",
       "  [['aaaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'MangoCherrry',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMßangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh']],\n",
       "  [['urian',\n",
       "    'Apple',\n",
       "    'Banana',\n",
       "    'lo,',\n",
       "    'Blueberryy',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'defghijklminop',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['defghijkllmnop',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    'hello',\n",
       "    'Orange',\n",
       "    'defghijklmnop',\n",
       "    'bb',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['◯ß◯◯', '◯◯◯', 'aaaaelbblo', ' ']],\n",
       "  [['abc', 'eeeeeeeedefgdefghijkilmnopbunăee', '', 'qr']],\n",
       "  [['defghijdefghijklmnpopklmnop',\n",
       "    '',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defghijklmnop',\n",
       "    'yOu']],\n",
       "  [['Apple',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Lemon',\n",
       "    'tODAYпривет,D?',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Apple']],\n",
       "  [['22',\n",
       "    '4444',\n",
       "    '9999999999',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '22',\n",
       "    '666666']],\n",
       "  [['aaaaa',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'こんにちは, Bonjour, Hel        lo, Hola, привет',\n",
       "    '  ',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['',\n",
       "    '◯◯◯',\n",
       "    '',\n",
       "    '         ',\n",
       "    '         ',\n",
       "    '◯◯◯◯',\n",
       "    '         ',\n",
       "    '         ']],\n",
       "  [['◯ß◯◯', 'bbbc', '◯◯◯', 'aaaaelbblo', ' ']],\n",
       "  [['hello', 'HOW', 'are', 'yOu', 'DOiNG', 'tO?', 'HOW']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'Cherry',\n",
       "    'cccccccc',\n",
       "    'MangoCherrry',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'Cherrry',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggggggg']],\n",
       "  [['acbc', 'eeeeeeeeee', '', 'OranUNQHge', 'qr', 'qr', 'eeeeeeeeee']],\n",
       "  [['', '        ', '◯◯◯', '   ', '     ', '\\t', '']],\n",
       "  [['bc', '◯◯◯', 'bună ziua', ' ', '😀😀😀', 'Hlola,', '         ']],\n",
       "  [['abc', 'defghijklmnop', 'abcc', 'qr', 'defghijklmnop']],\n",
       "  [['666666abc', 'defkghijklmnop', '', 'defghijklmnop', 'defghijklmnop']],\n",
       "  [['666666abc', '', 'defghijklmnop', '66666abc', 'defghijklmnop']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '4444',\n",
       "    '9999999999',\n",
       "    '55555',\n",
       "    '6999cccccccc99999966666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '222',\n",
       "    '22']],\n",
       "  [['',\n",
       "    '◯◯◯',\n",
       "    'bună ziua          ',\n",
       "    'bună ziua',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет']],\n",
       "  [['abc', 'defghijklmnop', '', 'qr', 'defghijklmndop']],\n",
       "  [['666666abc',\n",
       "    'qqr',\n",
       "    'defkghijklmnop',\n",
       "    '',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    '']],\n",
       "  [['cccc', 'areHOW  a  ', 'bb', 'ccc']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'y',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defghijklmnop',\n",
       "    'yOu',\n",
       "    'yOu']],\n",
       "  [['',\n",
       "    '        ',\n",
       "    '◯◯◯',\n",
       "    '   ',\n",
       "    '     ',\n",
       "    '\\t',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    '',\n",
       "    '◯◯◯']],\n",
       "  [['666666', '666666', '666666']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '😀😀😀', '         ', 'rape', 'bună ziua']],\n",
       "  [['666666abc',\n",
       "    '',\n",
       "    '666666bc',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '         ', '◯◯']],\n",
       "  [['HOW',\n",
       "    'bună zdœdefghijklmnopepiua',\n",
       "    'bună ziua',\n",
       "    '          ',\n",
       "    ' ',\n",
       "    '😀😀😀',\n",
       "    'bună ziua']],\n",
       "  [['abc',\n",
       "    'defghijklAvocadomnop',\n",
       "    'eeeeeeeeee',\n",
       "    'Orange',\n",
       "    '55  a  555',\n",
       "    '',\n",
       "    'qr',\n",
       "    'abc']],\n",
       "  [['Blueberryy',\n",
       "    '◯ß◯◯',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    'hello',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['',\n",
       "    '         ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    '  Gr rape   ',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '\\t',\n",
       "    '4444',\n",
       "    '         ',\n",
       "    '4444']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'Cherry',\n",
       "    'cccccccc',\n",
       "    'MangoCherrry',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'gggggggggggggg',\n",
       "    'Cherrry',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'Chrerry',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggggggg']],\n",
       "  [['◯◯◯aabc',\n",
       "    '◯◯◯',\n",
       "    'bună ziua',\n",
       "    'defghijkllmnop',\n",
       "    ' ',\n",
       "    '😀😀😀😀',\n",
       "    '         ']],\n",
       "  [['',\n",
       "    'dep',\n",
       "    '',\n",
       "    '         ',\n",
       "    '         ',\n",
       "    '         ',\n",
       "    '         ',\n",
       "    '         ']],\n",
       "  [['Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет']],\n",
       "  [['hello', 'defghijklmnop']],\n",
       "  [['', 'Kiwi', '◯◯◯', '', '          ', '         ', '         ']],\n",
       "  [['eeeeeeeee', 'defghijklmnop', 'eeeeeeeeee', '', 'qr']],\n",
       "  [['defghijmklmnop',\n",
       "    '',\n",
       "    'bună ziua',\n",
       "    '          ',\n",
       "    ' ',\n",
       "    '88888888',\n",
       "    '         ',\n",
       "    'bună ziua',\n",
       "    '55555😀😀😀']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'ffabcfffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'hhhhhhhhhhhhhhhhh',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhbună ziuaaareh',\n",
       "    'hhhhhhhhhhhhhhhhh']],\n",
       "  [['defghijklmnop', '', 'hello', 'defghijklmnop', 'defghijklmnop']],\n",
       "  [['acbc', 'eeeeeeeeee', 'Orange', '', 'OranUNQHge', 'qr', 'qr', 'acbc']],\n",
       "  [['bc',\n",
       "    'hhhhhhhhhhhhhhhhhhello',\n",
       "    'eeeeeeee',\n",
       "    'hhhhhhhhhhhhhhhhhello',\n",
       "    'eeeeeeeeee',\n",
       "    '']],\n",
       "  [['        ', '   ', '     ', '\\t', '   ']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'こんにちは, Bonjour, Hello, Ho1la, привет',\n",
       "    'привет',\n",
       "    'こんにちは, Bonjour, Hel        lo, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    'привет']],\n",
       "  [['◯ß◯◯', '◯◯◯', 'aaaaelbblo']],\n",
       "  [['  a  ', 'bb', '  a  ', '  a  ']],\n",
       "  [['   ',\n",
       "    '',\n",
       "    '        ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    '   ',\n",
       "    '88888888\\t',\n",
       "    '   ',\n",
       "    '   ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    '        ']],\n",
       "  [['œdefghijklmnbună zdœdefghijklmnopepiuaopdefghijklmnop',\n",
       "    'abc',\n",
       "    'defghijklmnop']],\n",
       "  [['Apple',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['hello', 'HOW', 'tziuahijklmnopODAY?', 'yOu', 'DOiNG', 'tO?', 'HOW']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'hello',\n",
       "    'r',\n",
       "    'hhello',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは,e Bonjour, Hello, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет']],\n",
       "  [['Orange       ',\n",
       "    '',\n",
       "    'bună ziua',\n",
       "    '          ',\n",
       "    ' ',\n",
       "    '😀😀😀',\n",
       "    '         ',\n",
       "    'bună ziua']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defghlijklmnop',\n",
       "    'defghijklmnop',\n",
       "    'yOu']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defghijklmnop',\n",
       "    'yOu',\n",
       "    'yOu',\n",
       "    'defghijklmnop']],\n",
       "  [['HOdefgW', 'are', 'yOu', 'DOiNG', 'tODAY?']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'ипривет',\n",
       "    'こんにちは, Bonjour, Hel        lo, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    'привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['abc',\n",
       "    'bbbc',\n",
       "    '',\n",
       "    'こんにちは,',\n",
       "    'Hola,Mango',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop',\n",
       "    '']],\n",
       "  [['bc', '◯◯◯', 'bună ziua', ' ', '😀😀😀', 'Hlola,', '         ', '😀😀😀']],\n",
       "  [['œdefghijklmnop', 'abc', 'œ']],\n",
       "  [['', '◯◯◯', 'bună ziua', '😀😀😀']],\n",
       "  [['', '◯◯◯', '', '         ', '◯◯◯◯', '         ', '         ']],\n",
       "  [['aaaaa',\n",
       "    'aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'deeeeeeeeeeabcdddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'iiiiiiiiiiiiiiiiiii']],\n",
       "  [['adefghijklmприветeeino',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '9999999999',\n",
       "    '22']],\n",
       "  [['defopß',\n",
       "    'üöäü',\n",
       "    'ß',\n",
       "    'gggggggggggggg',\n",
       "    'defghijkilmnopbună ziua',\n",
       "    'œ',\n",
       "    '\\uf8ff']],\n",
       "  [['',\n",
       "    '◯◯◯',\n",
       "    'bună ziua',\n",
       "    '          ',\n",
       "    '7777777',\n",
       "    ' ',\n",
       "    '         ',\n",
       "    '          ']],\n",
       "  [['◯◯◯', 'bună ziua', ' ', '         ', 'bună ziua', '         ']],\n",
       "  [['  a  ',\n",
       "    'bb',\n",
       "    'defop',\n",
       "    'ccc',\n",
       "    'bb',\n",
       "    'bb',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'bb',\n",
       "    'defop']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '4444',\n",
       "    '9999999999',\n",
       "    '55555',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '22']],\n",
       "  [['  a  ', 'qr  a  ', 'bb']],\n",
       "  [['abc',\n",
       "    'eeeeeeeeee',\n",
       "    'defghijklminop',\n",
       "    'eeeeeeeee',\n",
       "    'defghijklmino',\n",
       "    'œ',\n",
       "    'eeeeeeeeeee',\n",
       "    'defghiljklmnop',\n",
       "    'defghiljklmnop']],\n",
       "  [['',\n",
       "    '◯◯Blueberry◯',\n",
       "    '◯◯◯',\n",
       "    '',\n",
       "    '         ',\n",
       "    '◯◯◯◯',\n",
       "    '         ',\n",
       "    '         ',\n",
       "    '         ']],\n",
       "  [[' ', 'Hola,Mango', 'hhhhhhhhhhhhhhhh', '  Grrape   ', 'bc']],\n",
       "  [['abc',\n",
       "    'defghijklAvocadomnop',\n",
       "    'eeeeeeeeee',\n",
       "    '',\n",
       "    'qr',\n",
       "    'defghijklAvocadomnop']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'Cherry',\n",
       "    'cccccccc',\n",
       "    'MangoCherrry',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggggggg',\n",
       "    'cccccccc',\n",
       "    'ddddddddd']],\n",
       "  [['◯◯◯', 'bună ziua', ' ', '    œdefghijklmnop', 'bună ziua', '         ']],\n",
       "  [[' ', 'Hola,Mango', 'r', 'hhhhhhhhhhhhhhhh', '  Grrape   ', 'bc']],\n",
       "  [['', '◯◯◯', '😀😀😀', '         ', '']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '😀😀😀', '◯◯◯']],\n",
       "  [['◯ß◯◯', 'bbbc', '◯◯◯', 'aaaaaelbblo', ' ']],\n",
       "  [['defghijklmnop',\n",
       "    'defghihhhhhhhhhhhhhhhjklmnop',\n",
       "    '',\n",
       "    'y',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defghijklmnop',\n",
       "    'yOu',\n",
       "    'yOu']],\n",
       "  [['666666abc',\n",
       "    'defghijklmnbună',\n",
       "    'defkghijklmnop',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['areHOW  a  ', 'qRqCuk', 'tODAY', 'ccc', 'bb']],\n",
       "  [['', '◯◯◯', '', '         ', '◯◯◯◯', '       ', '         ', '         ']],\n",
       "  [['tODAY\\t?',\n",
       "    'defghijklAvocadomnop',\n",
       "    'eeeeeeeeee',\n",
       "    'Orange',\n",
       "    '',\n",
       "    'qaaaaar',\n",
       "    'eeeeeeeeee',\n",
       "    'eeeeeeeeee']],\n",
       "  [['',\n",
       "    '         ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    '  Gr rape   ',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '\\t',\n",
       "    '4444',\n",
       "    '\\t']],\n",
       "  [['',\n",
       "    '◯◯defghijklmnbună zdœdefghijklmnopepiuaop',\n",
       "    'bună ziua',\n",
       "    ' ',\n",
       "    'Durian']],\n",
       "  [['Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにIAtbeuOちは, Bonjour, Hello, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет']],\n",
       "  [['hhhhhhhhhhhhhпрccccccccиветhhh',\n",
       "    'aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'areHOWfffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggMangoggggg']],\n",
       "  [['', '◯◯◯', ' ', 'こんにIAtbeuOちは,', '', '         ']],\n",
       "  [['defghijklmnop',\n",
       "    'defghihhhhhhhhhhhhhhhjklmnop',\n",
       "    '',\n",
       "    'y',\n",
       "    'привет, Hola, Bonjour, こんにちは,ち Helbblo',\n",
       "    'defghijklmnop',\n",
       "    'yOu',\n",
       "    'yOu',\n",
       "    'y']],\n",
       "  [['defghijklmnop',\n",
       "    'Blueberry',\n",
       "    'привет, aaaaelbblo',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'qRqCuk',\n",
       "    'прdefkghijklmnopивет, aaaaelbblo',\n",
       "    'yOu',\n",
       "    'yOu',\n",
       "    'qRqCuk']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '😀😀😀', '         ', '◯']],\n",
       "  [['eeeeeeeeeeabc', 'abc', '999999999', 'œ', 'eeeeeeeeee']],\n",
       "  [['◯◯◯', 'bună ziua', 'bună ggggggggManggoggggg', ' ', '         ']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Helolo, Bonjour, こんにちは, Hola, привет',\n",
       "    'привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['666666abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    '6c6666abc',\n",
       "    'defkghijklmnop',\n",
       "    '666666bc',\n",
       "    'defghijklmnop',\n",
       "    '66666abc',\n",
       "    'bbbc',\n",
       "    'defghijklmnop']],\n",
       "  [['defghijklmnop', '', 'hello', 'r', 'defghijklmnop']],\n",
       "  [['eeeeeeeeeeabc', 'abc', 'eeeeeeeeee', 'defop', 'œ', 'œ', 'œ']],\n",
       "  [['666666abc',\n",
       "    'defghijklmnop',\n",
       "    '',\n",
       "    '666666bc',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    '66666abc',\n",
       "    'q',\n",
       "    'defghijklmnop']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'tODAY',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет',\n",
       "    'こんにちは, Bonjour, Hel        lo, Hola, привет',\n",
       "    'fghijklmnopyOu',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['defghijklmnop',\n",
       "    '',\n",
       "    'r',\n",
       "    'defghijklmnop',\n",
       "    'Helolo,',\n",
       "    'dHelloBonjour,efghijklmnop',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['◯ß◯◯', '◯◯◯', 'œgggggggggggagg', '◯◯◯']],\n",
       "  [['æ',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    'æ']],\n",
       "  [['HOW', 'こんにちは,', 'tODAY?']],\n",
       "  [['',\n",
       "    'Hola,',\n",
       "    'hhhhhhhhhhhhhhh',\n",
       "    'bună ziua',\n",
       "    ' ',\n",
       "    '😀😀😀',\n",
       "    '         ',\n",
       "    'rape']],\n",
       "  [['acbc',\n",
       "    'eeeeeeeeee',\n",
       "    'ggggggggManggoggggg',\n",
       "    'OranUNQHge',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'eeeeeeeeee']],\n",
       "  [['HOW', 'are', 'yOu', 'DOiNG']],\n",
       "  [['hello', 'HOW', 'yOu', 'DOiNG', 'tODAY?', 'yOu', 'DOiNG']],\n",
       "  [['прdefkghijklmnopивет,', '', '◯◯◯', 'bună ziua', '😀😀😀']],\n",
       "  [['',\n",
       "    'bună ziua',\n",
       "    '          ',\n",
       "    ' Orange',\n",
       "    '😀😀😀',\n",
       "    '         ',\n",
       "    'bună ziua']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Hola,',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Durianddddddddd',\n",
       "    'Avocado',\n",
       "    'Grape']],\n",
       "  [['        ', '   ', '     ', '\\t\\t', '   ']],\n",
       "  [['',\n",
       "    'bună ziua',\n",
       "    '          ',\n",
       "    ' ',\n",
       "    '55555😀😀😀',\n",
       "    '         ',\n",
       "    'bună ziua',\n",
       "    'bună ziua']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'HelloBonjour, こんにちは, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['9999999999', 'areHOW  a  ', 'bb', 'ccc']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['dœdefghijklmnopep',\n",
       "    'abc',\n",
       "    'dep',\n",
       "    'bună ziua',\n",
       "    'eeeeeeeeee',\n",
       "    'eeeeeeeeeHello,',\n",
       "    'œ']],\n",
       "  [['defghijmklmnop',\n",
       "    '',\n",
       "    'bună ziua',\n",
       "    '        привет, ',\n",
       "    '          ',\n",
       "    ' ',\n",
       "    '55555😀😀😀',\n",
       "    '         ',\n",
       "    'bună ziua',\n",
       "    ' ']],\n",
       "  [['こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola,Mango привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет']],\n",
       "  [['', '◯◯◯', '          ', ' ', '😀😀😀', '         ', '', '          ']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'MangoCherrry',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggggggg']],\n",
       "  [['Apple',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['fIdBykS', 'MangoCherrry', 'ccddddddddd', 'ccc', 'ccc']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'Cherry',\n",
       "    'MangoCherrry',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'ggggggggMangoggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'ggggggggggggg']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет']],\n",
       "  [['acbc',\n",
       "    '6c6666abc',\n",
       "    'eeeeeeeeee',\n",
       "    'ggggggggManggoggggg',\n",
       "    'OranUNQHge',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'eeeeeeeeee']],\n",
       "  [['666666abc',\n",
       "    'ndefghijklmnop',\n",
       "    'defghijklmnbună',\n",
       "    'defkghijklmnop',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['hello',\n",
       "    'HOW',\n",
       "    'uyOuggggggggMangoggggg',\n",
       "    'defghijklmnbună',\n",
       "    'are',\n",
       "    '   \\t',\n",
       "    'DOiNG',\n",
       "    'tziuahijklmnopODAY?',\n",
       "    'DOiNG',\n",
       "    'DOiNG']],\n",
       "  [['eeeeeeeeeeabc',\n",
       "    ' привет,abc',\n",
       "    'defghijklmnop',\n",
       "    'eeeeeeeeee',\n",
       "    'defop',\n",
       "    'defghijklminop',\n",
       "    'œ',\n",
       "    'eeeeeeeeeee',\n",
       "    'defghijklmnop']],\n",
       "  [['',\n",
       "    '         ',\n",
       "    'привет, Hola, Bonjour, こんにちは, Helbblo',\n",
       "    'defkghijklmnop',\n",
       "    '  Grrape   ',\n",
       "    '\\t',\n",
       "    '   \\t',\n",
       "    '555',\n",
       "    '   \\t',\n",
       "    '   \\t',\n",
       "    '',\n",
       "    '\\t',\n",
       "    '\\t',\n",
       "    '',\n",
       "    '   \\t']],\n",
       "  [['bb',\n",
       "    '1',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '9999999999',\n",
       "    '222',\n",
       "    '22']],\n",
       "  [['defghijklomnop',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет']],\n",
       "  [['acbc',\n",
       "    'eeeeeeeeee',\n",
       "    'ggggggggManggoggggg',\n",
       "    'OranUNQHge',\n",
       "    'zdœdefghijklmnopepiuaopdefghijklmnopqr',\n",
       "    'qr',\n",
       "    'eeeeeeeeee']],\n",
       "  [['bb',\n",
       "    '1',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '9999999999',\n",
       "    '222',\n",
       "    '22']],\n",
       "  [['こんにちはは,', 'こんにちは,', 'tODAY?', 'こんにちはは,']],\n",
       "  [['',\n",
       "    '        ',\n",
       "    '   ',\n",
       "    '  Grrape   ',\n",
       "    '\\t',\n",
       "    '            ',\n",
       "    '   \\t',\n",
       "    '   ']],\n",
       "  [['defghijklmnop',\n",
       "    'defghijklHolaöärиветmnop',\n",
       "    '',\n",
       "    '666666bc',\n",
       "    'qr',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop',\n",
       "    'defghijklmnop']],\n",
       "  [['a', 'bb', 'ccc', 'ddd']],\n",
       "  [['abc']],\n",
       "  [['x', 'y', 'z', '']],\n",
       "  [['qeeeeeeeeee', 'abc', 'defghijklmnop', 'Bonjour,', '', 'qr', 'qr']],\n",
       "  [['  a  ', '  a  ']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'Bonjour,']],\n",
       "  [['qeeeeeeeeee', 'abc', 'defghijklmnop', 'Bonjour,', '', 'qr', 'Bonjour,']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'Bonjour,',\n",
       "    'Bonjour,']],\n",
       "  [['ccc']],\n",
       "  [['', '        ', '    \\t', '   ', '     ', '\\t', '   \\t']],\n",
       "  [['', 'bună ziua', ' ', '😀😀😀', '         ', '◯◯◯']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'qeeeeHola,eee',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'qr']],\n",
       "  [['abc', 'defghijklmnop', 'Apple', 'qr']],\n",
       "  [['iiiiiiiiiiiiiiiiiii', '  a  ', 'bb', 'ccc', 'bb', 'bb']],\n",
       "  [['', '◯◯◯', ' ', '😀😀😀', '         ']],\n",
       "  [['   ', 'bună ziua', ' ', '😀😀😀', '         ', '◯◯◯', '◯◯◯']],\n",
       "  [['', '   ', '   ', '     ', '\\t', '   \\t']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '10000000000',\n",
       "    '7777777']],\n",
       "  [['   ', 'bună ziua', ' ', '😀😀😀', '         ', '◯◯◯', '◯◯◯', '◯◯◯']],\n",
       "  [['ccc', 'ccc']],\n",
       "  [['iiiiiiiiiiiiiiiiiii', 'Banana', '10000000000', 'bb', 'ccc', 'bb', 'bb']],\n",
       "  [['   ', 'bună ziua', ' ', '😀😀😀', '         ', '◯◯◯', 'tODAY?', '◯◯◯']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '666666']],\n",
       "  [[' ', '   ', ' ', '😀😀😀', '         ', '◯◯◯', '◯', '◯◯◯', '◯◯◯']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '555555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '666666']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'aœbc',\n",
       "    'qeeeeHola,eee',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'qr']],\n",
       "  [['   ', ' ', '😀😀😀', '         ', '◯◯◯', 'tODAY?', '◯◯◯']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    'Hello, Hola, Beeeeeeeeeeonjour, こんにちは, привет']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999']],\n",
       "  [['bb', 'ccc']],\n",
       "  [['abc', 'fffffffffff', 'Apple', 'Ø', 'qr', 'qr', 'fffffffffff']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'qeeeeeeeeee',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'Bonjour,']],\n",
       "  [['Aplple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Lemonœ',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Orange']],\n",
       "  [['aziuabc', 'fffffffffff', 'Apple', 'Ø', 'qr', 'qr', 'fffffffffff']],\n",
       "  [['hello', 'chellocc', 'ccc', 'ccc', 'ccc']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Duriaccccccccn']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Durian',\n",
       "    'fffffffffff',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['hello', 'HOW', 'are', 'yOu', 'tODAY?']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Duriaccccccccn']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '666666',\n",
       "    '333']],\n",
       "  [['', '   ', '   ', '     ', '\\t', '   \\t', '']],\n",
       "  [[' ', '', ' ', '😀😀😀', '         ', '◯◯◯', '◯◯◯', '◯', '◯◯◯', '◯◯◯']],\n",
       "  [['', 'öäü', 'ß', 'Ø', 'œ', '\\uf8ff']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'Bonjour,']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'hhhhhhhhhhhhhhhh']],\n",
       "  [['', '◯◯◯', ' ', '😀😀😀', '         ', ' ']],\n",
       "  [['   ', ' ', '😀😀😀', '         ', '◯◯◯', 'tODAY?', '◯◯◯', '◯◯◯', 'tODAY?']],\n",
       "  [['', 'bună ziua', '◯◯◯◯', ' ', '😀😀😀', '         ', '◯◯◯']],\n",
       "  [['', '        ', '    \\t', '   ', '     ']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '66666Ø',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '1',\n",
       "    '2']],\n",
       "  [['bbccc']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Applle',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Duriaccccccccn']],\n",
       "  [['iiiiiiiiiiiiiiiiiii',\n",
       "    'Mango',\n",
       "    '10000000000',\n",
       "    'bb',\n",
       "    '◯',\n",
       "    'ccc',\n",
       "    'bb',\n",
       "    'bb']],\n",
       "  [['Appl',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Duriaccccccccn']],\n",
       "  [['are', 'bb', 'ccc']],\n",
       "  [['Apple',\n",
       "    'MMango',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Graziuape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['ß', 'öäü', 'ß', 'Ø', 'œ', '\\uf8ff']],\n",
       "  [['Apple',\n",
       "    'MMango',\n",
       "    'Avocado',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    '◯◯◯◯',\n",
       "    'Fig',\n",
       "    'Graziuape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Fig']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '1']],\n",
       "  [['iiiiiiiiiiiiiiiiiii', 'Mango', '10000000000', 'bb', '◯', 'ccc', 'bb']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '999999999']],\n",
       "  [['szgkhWMLx',\n",
       "    'zRFADUSNC◯',\n",
       "    'JNGmHOkr',\n",
       "    'PxKKem',\n",
       "    'æ',\n",
       "    'qEK',\n",
       "    'TyUNzlo',\n",
       "    '4444',\n",
       "    'NEs',\n",
       "    'TSNvGfDd']],\n",
       "  [['', '◯◯◯', '  ', ' ', '😀😀😀', '         ']],\n",
       "  [['こんにちは, Bonjour, Hello, Hola, привет', 'ccc', 'ccc']],\n",
       "  [['szgkhWMLx',\n",
       "    'zRFADUSNC◯',\n",
       "    'TSNvGfyOuDd',\n",
       "    'JNGmHOkr',\n",
       "    'PxKKem',\n",
       "    'æ',\n",
       "    'qEK',\n",
       "    'TyUNzlo',\n",
       "    '4444',\n",
       "    'NEs',\n",
       "    'TSNvGfDd',\n",
       "    'szgkhWMLx']],\n",
       "  [['', '        ', '     ', '22', '   \\t']],\n",
       "  [['defghijklmnop', 'Apple']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'привет,',\n",
       "    'hhhhhhhhhhhhhhhh122',\n",
       "    '4444',\n",
       "    '◯',\n",
       "    '999999bbbbbb999',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'szgkhWMLx',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['defghijklmnop', '◯◯◯', '  ', ' ', '😀😀😀', '         ']],\n",
       "  [['  a   ']],\n",
       "  [['', 'Bonjour,', 'öäü', 'ß', 'Ø', 'œ', '\\uf8ff']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'qeeeeHola,eee',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '        ',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'qr']],\n",
       "  [['привет',\n",
       "    '1',\n",
       "    '',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '4444',\n",
       "    '888888888',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '999999999',\n",
       "    '']],\n",
       "  [['chellocc', 'ccc', 'ccc', 'ccc', 'ccc']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '😀😀😀', '55555         ', '◯◯◯']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '7777777']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '22',\n",
       "    '33',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    'Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '1',\n",
       "    '2']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'првет,',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '6Aplple66666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '999999999']],\n",
       "  [['こんにちは, Bonjour, Hello, Hola, привет', 'cccc', 'ccc', 'ccc']],\n",
       "  [['Apple', 'bbccc']],\n",
       "  [['ß', '◯', 'ß', 'Ø', 'œ', '\\uf8ff']],\n",
       "  [['ß', 'öäü', 'ß', 'Ø', 'œ', 'szgkhWMLx']],\n",
       "  [['Apple',\n",
       "    'MMango',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Graziuape',\n",
       "    'Kiwi',\n",
       "    'Liiiiiiiiiiiiiiiiiiiemon',\n",
       "    'Mango']],\n",
       "  [['Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'DOiNG',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Orangre',\n",
       "    'Duriaccccccccn']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Mango',\n",
       "    'Avocado']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Avocado']],\n",
       "  [['defghijklmnop', 'kdefghijklmnop', 'Apple', 'kdefghijklmnop']],\n",
       "  [['9999◯◯◯◯99999',\n",
       "    '1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '666666']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'Bonjour,',\n",
       "    'Bonjour,']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'qeeeeHola,eee',\n",
       "    'Bonjour,',\n",
       "    '       ',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'qr']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'qeeeeHola,eee',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '        ',\n",
       "    'qr',\n",
       "    'tODAY?',\n",
       "    'qr',\n",
       "    'Bonjour,']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Durian',\n",
       "    'F',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    '333',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['ß', 'öäüchellocc', 'ß', 'Ø', 'œ', '\\uf8ff']],\n",
       "  [['  a   ', '  a   ']],\n",
       "  [['cccc', 'ccc', 'ccc']],\n",
       "  [['Appl',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Grapこんにちは,',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Duriaccccccccn']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', 'qEK', '         ', '◯◯◯']],\n",
       "  [['', '        ', '    \\t', '   ', '     ', '    \\t']],\n",
       "  [['ß', '◯', 'Ø', 'œ', '\\uf8ff']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    'Beeeeeeeeeeonjour,',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '7777777']],\n",
       "  [['   ', 'bună ziua', '😀😀😀', '         ', '◯◯◯', 'tODAY?', '◯◯◯']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '22',\n",
       "    '33',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    'Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '99999999',\n",
       "    '10000000000',\n",
       "    '1',\n",
       "    '2',\n",
       "    '2',\n",
       "    '4444']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    '77777',\n",
       "    'qr',\n",
       "    'Bonjour,']],\n",
       "  [['   ',\n",
       "    ' ',\n",
       "    '😀😀😀',\n",
       "    '         ',\n",
       "    '◯◯◯',\n",
       "    'tODAY?',\n",
       "    '◯◯◯',\n",
       "    '◯◯◯',\n",
       "    'tODAY?',\n",
       "    'tODAY?']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'aœbc',\n",
       "    'qeeeeHola,eee',\n",
       "    'defghijklmnop',\n",
       "    'hello',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'qr']],\n",
       "  [['',\n",
       "    'првет,',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '6Aplple66666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '999999999',\n",
       "    '']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'bbbbbb']],\n",
       "  [['', '        ', '    \\t', '   ', '\\t', '   \\t']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '44',\n",
       "    'Beeeeeeeeeeonjour,',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '7777777']],\n",
       "  [['abc', 'dBlueberryefghijklmnop', '', 'qr', 'Grapこんにちは,']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'qeeeeHola,eee',\n",
       "    'defghijklmnop',\n",
       "    '999999999',\n",
       "    'Bonjour,',\n",
       "    '        ',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'qr']],\n",
       "  [['Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'DOiNG',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'Orangre',\n",
       "    'Duriaccccccccn']],\n",
       "  [['cccc', 'ccKiwic', 'ccc', 'ccc']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '66666Ø',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '1',\n",
       "    '2']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Duriaccccccccn']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '77777',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '44',\n",
       "    'Beeeeeeeeeeonjour,',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '7777777']],\n",
       "  [['bbbbbb',\n",
       "    'cccccccc',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'Liiiiiiiiiiiiiiiiiiiemon',\n",
       "    'Grapこんにちは,',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'hhhhhhhhhhhhhhhh']],\n",
       "  [['\\uf8ff6Aplple66666', 'ß', 'öäü', 'ß', 'Ø', 'œ', '\\uf8ff']],\n",
       "  [['bbbbbb',\n",
       "    'cccccccc',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'Liiiiiiiiiiiiiiiiiiiemon',\n",
       "    'Grapこんにちは,',\n",
       "    'iiiiiiiiiiiiiiiiiiiAvocado',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    '4444',\n",
       "    'hhhhhhhhhhhhhhhh']],\n",
       "  [['Apple',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'Bonjour,']],\n",
       "  [['',\n",
       "    'првет,',\n",
       "    'привет,',\n",
       "    '9999999999',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '6Aplple66666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '999999999',\n",
       "    '']],\n",
       "  [['9999999999',\n",
       "    '1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000']],\n",
       "  [['Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'ziua',\n",
       "    'Duriaccccccccn',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'DOiNG',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'Orangre',\n",
       "    'Duriaccccccccn',\n",
       "    'Grape']],\n",
       "  [['abc', 'defghijklmnop', 'Apple', ' ', 'qr']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Hello',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Kiwi']],\n",
       "  [['', 'bună ziua', ' ', '         ', '◯◯◯']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    'привет,']],\n",
       "  [['', 'MMango', '     ', '22', '   \\t']],\n",
       "  [['', '        ', '     ', '22', '   \\t', '']],\n",
       "  [['ccc', 'cc']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'првет,',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '6Aplple66666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '999999999',\n",
       "    '999999999']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    'bbbbbb',\n",
       "    '',\n",
       "    'qr',\n",
       "    'Bonjour,',\n",
       "    'qeeeeeeeee',\n",
       "    'Bonjour,']],\n",
       "  [['hello', 'HOW', '😀😀😀', 'are', 'yOu', 'DOiNG', 'tODAY?']],\n",
       "  [['defghijklmnop', '  ', ' ', '😀😀😀', '         ', ' ']],\n",
       "  [['NEs',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'Mango',\n",
       "    '10000000000',\n",
       "    'bb',\n",
       "    '◯',\n",
       "    'ccc',\n",
       "    'bb',\n",
       "    'bb']],\n",
       "  [['Hello, Bonjour, こんにちは, Hola, приNEsвет',\n",
       "    'こんにちは, Bonjour,u Hello, Hola, привет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '77777',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '44',\n",
       "    'Beeeeeeeeeeonjour,',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '77777777',\n",
       "    '22',\n",
       "    '7777777']],\n",
       "  [['Hello, Bonjour, こんにちは, Hola, привет', 'ccc', 'ccc']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '3333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '10000000000',\n",
       "    '666666',\n",
       "    '333']],\n",
       "  [['Avocado',\n",
       "    'Banana',\n",
       "    'Avocado',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Or',\n",
       "    'DOiNG',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Orangre',\n",
       "    'Duriaccccccccn']],\n",
       "  [['', '◯◯◯', ' ', '😀😀😀', '         ', '']],\n",
       "  [['Apple',\n",
       "    'MMango',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Graziuape',\n",
       "    'Kiwi',\n",
       "    'Liiiiiiiiiiiiiiiiiiiemon',\n",
       "    'Mango',\n",
       "    'Duriaccccccccn']],\n",
       "  [['aziuabc',\n",
       "    'fffffffffff',\n",
       "    'Apple',\n",
       "    'Ø',\n",
       "    'qqr',\n",
       "    'qr',\n",
       "    'fffffffffff',\n",
       "    'fffffffffff']],\n",
       "  [['こんにちは, Bonjour, Hello, Hola, привет', 'cccc', 'ccc', 'cccc']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Orangne',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Duriaccccccccn']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '88888888']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '999999999',\n",
       "    'привет,']],\n",
       "  [['Hello, Bonjour, こんにちは, Hola, приNEsвет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, приNEsвет',\n",
       "    'こんにちは, Bonjour,u Hello, Hola, привет',\n",
       "    'こんにちは, Bonjour,u Hello, Hola, прbună ziuaвет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'Hello, Bonjour, こんにちは, Hola, приNEsвет']],\n",
       "  [['abc', 'defghijklmnop', 'Appple', ' ', 'qr']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '4444']],\n",
       "  [['iiiiiiiiiiiiiiiiiii',\n",
       "    'Banana',\n",
       "    '10000000000',\n",
       "    'bb',\n",
       "    'ccc',\n",
       "    'bb',\n",
       "    'bb',\n",
       "    '10000000000']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'AvoJNGmHOkrdo',\n",
       "    'Avocado']],\n",
       "  [['   ', ' ', 'Appl', '😀😀😀', '         ', '◯◯◯', 'tODAY?', '◯◯◯']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'Cherry',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'bbbbbb']],\n",
       "  [['', 'Bonjour,', 'öäü', 'ß', 'Bonj', 'Ø', 'œ', '\\uf8ff']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Orange',\n",
       "    'Mango',\n",
       "    'Avocado']],\n",
       "  [['Apple',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'Bonjour,',\n",
       "    'Bonjour,']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '4444',\n",
       "    '77771227',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999']],\n",
       "  [['', 'bună ziua', '◯◯◯◯', ' ', '😀😀😀', '         ', '◯◯◯', '😀😀😀']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'qeeeeHola,eee',\n",
       "    'defghijklmnop',\n",
       "    '999999999',\n",
       "    'Bonjour,',\n",
       "    '        ',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'qr']],\n",
       "  [['a', '        ', '    \\t', '   ', '     ']],\n",
       "  [['  a  ', '  a  ', '  a  ']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    'bbbbbb',\n",
       "    '',\n",
       "    'qr',\n",
       "    'Bonjour,',\n",
       "    'qeeeeeeeee',\n",
       "    'Bonjour,',\n",
       "    'Bonjour,']],\n",
       "  [['こんにちは, Bonjour, Hello, Hola, привет', 'cccc', 'ccc']],\n",
       "  [['',\n",
       "    'bună ziua',\n",
       "    '◯◯◯◯',\n",
       "    ' ',\n",
       "    'приNEsвет',\n",
       "    '😀😀😀',\n",
       "    '         ',\n",
       "    'bună ziua']],\n",
       "  [['Apple']],\n",
       "  [['55555', 'Apple', 'bbccc', 'bbccc']],\n",
       "  [['iiiiiiiiiiiiiiiiiii',\n",
       "    'Mango',\n",
       "    '10000000000',\n",
       "    'bb',\n",
       "    '◯',\n",
       "    'ccc',\n",
       "    'Banana']],\n",
       "  [['iiiiiiiiiiiiiiiiiii', '        ', '10000000000', 'bb', '◯', 'ccc', 'bb']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '22',\n",
       "    '3333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '66666Ø',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '1',\n",
       "    '2',\n",
       "    '1',\n",
       "    '999999999']],\n",
       "  [['defghijklmnop', '  ', ' ', '😀😀😀', '         ', ' ', '😀😀😀']],\n",
       "  [['aziuabc',\n",
       "    'fffffffffff',\n",
       "    '122',\n",
       "    'Ø',\n",
       "    'qqr',\n",
       "    '',\n",
       "    'qr',\n",
       "    'fffffffffff',\n",
       "    'fffffffffff',\n",
       "    'fffffffffff',\n",
       "    'qqr']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '666666',\n",
       "    '66qeeeeeeeee6666',\n",
       "    '333']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '66666Durian6',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '10000000000',\n",
       "    '7777777']],\n",
       "  [['Apple',\n",
       "    'MMango',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'првет,',\n",
       "    'Graziuape',\n",
       "    'Kiwi',\n",
       "    'Liiiiiiiiiiiiiiiiiiiemon',\n",
       "    'Mango']],\n",
       "  [['qeeeeeeeeee', 'abc', 'defghijklmnop', 'Bonjour,', '', 'qr', 'qr', 'qr']],\n",
       "  [['Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello']],\n",
       "  [['ccccc', 'こんにちは, Bonjour, Hello, Hola, привет', 'cccc', 'ccc', 'ccc']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'привет,',\n",
       "    '',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '1']],\n",
       "  [['22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000']],\n",
       "  [['', '◯◯◯', ' ', '😀😀😀', '    \\t']],\n",
       "  [[' ', '', ' ', '😀😀😀', '◯◯◯', '◯◯◯', '◯', '◯◯◯', '◯◯◯', '◯◯◯']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '555555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'TyUNzlo',\n",
       "    '10000000000',\n",
       "    '666666',\n",
       "    '7777777']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '44',\n",
       "    'Beeeeeeeeeeonjour,',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '9999999999',\n",
       "    '7777777']],\n",
       "  [['Appl',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Grachelloccpe',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Duriaccccccccn']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'Cherry',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'bbbbbb',\n",
       "    'bbbbbb']],\n",
       "  [['   ', 'bună ziua', ' ', '😀😀😀', '         ', '◯◯◯', 'tODAY?']],\n",
       "  [['defghijklmnop', '  ', ' ', '😀😀😀', '         ', 'Appple', ' ']],\n",
       "  [['cæccc',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'cccc',\n",
       "    'ccc',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет']],\n",
       "  [['◯66666Ø◯◯', '   ', 'bună ziua', '😀😀😀', '         ', '◯◯◯', 'tODAY?']],\n",
       "  [['ß', '◯', 'ß', 'ßß', 'Ø', '\\uf8ff']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'qeeeeHola,eee',\n",
       "    'Bonjour,',\n",
       "    '       ',\n",
       "    'BonAvoJNGmHOkrdojour,',\n",
       "    'qr',\n",
       "    'BonjourDurian,',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'BonAvoJNGmHOkrdojour,']],\n",
       "  [['MMango', 'Durian', '     ', '22', '   \\t', '22']],\n",
       "  [['', '◯◯◯', '😀😀😀', '         ', '', '']],\n",
       "  [['', '        ', '     ', '22', '9999◯◯◯◯99999']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '666666',\n",
       "    '66qeeehelloeeeeee6666',\n",
       "    '333']],\n",
       "  [['Hello, Bonjour, こんにちは, Hola, пр77771227иNEsвет',\n",
       "    'こんにちは, Bonjour,u Hello, Hola,H привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, приNEsвет',\n",
       "    'こんにちは, Bonjour,u Hello, Hola, привет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello']],\n",
       "  [['Apple',\n",
       "    'MMango',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'првет,',\n",
       "    'Graziuape',\n",
       "    'Kiwi',\n",
       "    'Liiiiiiiiiiiiiiiiiiiemon',\n",
       "    'Mango',\n",
       "    'Banana']],\n",
       "  [['Apple',\n",
       "    'MMango',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'првет,',\n",
       "    'Graziuape',\n",
       "    'Kiwi',\n",
       "    'Liiiiiiiiiiiiiiiiiiiemon',\n",
       "    'Mango',\n",
       "    'Avocado']],\n",
       "  [['Or', '  a  ', 'bb', 'ccc', 'bb', 'bb', 'bb', 'bb']],\n",
       "  [['', 'öäü', 'ß', 'Ø', 'æ', 'œ', '\\uf8ff', 'œ']],\n",
       "  [['Aplple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Lemonœ',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['', 'bună ziua', '◯◯◯◯', ' ', '😀😀😀', '         ', ' ']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'првет,',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '444',\n",
       "    '55555',\n",
       "    '6Aplple66666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '999999999',\n",
       "    '999999999']],\n",
       "  [['Apple',\n",
       "    'MMango',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'GraziGraziuapeuape',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'првет,',\n",
       "    'Graziuape',\n",
       "    'Kiwi',\n",
       "    'Liiiiiiiiiiiiiiiiiiiemon',\n",
       "    'Mango',\n",
       "    'Banana']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    'Avocado',\n",
       "    '666666',\n",
       "    '66qeeehelloeeeeee6666',\n",
       "    '333']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    'bbbbbb',\n",
       "    '',\n",
       "    'qr',\n",
       "    'BonjourDuriaccccccccn,',\n",
       "    'qeeeeeeeee',\n",
       "    'Bonjour,',\n",
       "    'Bonjour,']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '77777',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '44',\n",
       "    'Beeeeeeeeeeonjour,',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '77777777',\n",
       "    '22',\n",
       "    '7777777',\n",
       "    '666666',\n",
       "    '1']],\n",
       "  [['abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'Bonjour,']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '99999abc',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '4444',\n",
       "    '1']],\n",
       "  [['Or', '  a  ', 'bb', 'ccc', 'bb', 'bb', 'bb', '99999abc', 'bb', 'bb']],\n",
       "  [['', 'öäü', 'ß', 'Ø', 'æ', 'œ', '\\uf8ff', 'œ', 'œ']],\n",
       "  [['', 'öäü', 'ß', 'Ø', 'œ', '\\uf8ff', '']],\n",
       "  [['         ', '', '        ', '    \\t', '   ', '     ', '\\t', '   \\t']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '22',\n",
       "    '33',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    'Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '99999999',\n",
       "    '10000000000',\n",
       "    'прqeeeeeeeeeивет,',\n",
       "    '1',\n",
       "    '2',\n",
       "    '2',\n",
       "    '4444']],\n",
       "  [['', 'öäü', 'ß', 'Ø', 'æ◯', 'œ', '\\uf8ff', 'Ø']],\n",
       "  [['iiiiiiiiiiiiiiiiiii', 'Mango', '10000000000', 'bb', '◯', 'ccc', 'Banan']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'F',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Avocado']],\n",
       "  [['Hello, Bonjour, こんにちは, Hola, приNEsвет',\n",
       "    'こんにちは, Bonjour,u Hello, Hola, привет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'Hello, Bonjour, こんにちは, Hola, приNEsвет']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    'bbbbbb',\n",
       "    '',\n",
       "    'qr',\n",
       "    'BonjourDuriaccccccccn,',\n",
       "    'qeeeeeeeee',\n",
       "    'Bonjour,']],\n",
       "  [['9999999999',\n",
       "    '1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '4',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000']],\n",
       "  [['Appl',\n",
       "    'Avocado',\n",
       "    'cccccccc',\n",
       "    'Banana',\n",
       "    'Cyherry',\n",
       "    'Blueberrприветy',\n",
       "    'Duriaccccccccn',\n",
       "    'Grachelloccpe',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Duriaccccccccn']],\n",
       "  [['9999999999',\n",
       "    '1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '4',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000']],\n",
       "  [['44',\n",
       "    '1',\n",
       "    'првет,',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '6Aplple66666',\n",
       "    '77777',\n",
       "    '999999999',\n",
       "    '999999999',\n",
       "    '6Aplple66666']],\n",
       "  [['ccccc',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'cccc',\n",
       "    '888888888',\n",
       "    'ccc',\n",
       "    'ccc']],\n",
       "  [['abc', 'defghijklmnop', 'Bonjour,', '', 'qeeeeHola,eee', 'Bonjour,']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'Appple',\n",
       "    'Bonjour,',\n",
       "    'Bonjour,']],\n",
       "  [['Hola,H',\n",
       "    '1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '555555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    'ß',\n",
       "    'bbccc',\n",
       "    '666666',\n",
       "    '555555']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '66666Ø',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '1',\n",
       "    '2',\n",
       "    '1']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['  a  ', 'bb', 'ccc', 'bb', 'bb', 'bb', 'bb']],\n",
       "  [['Apple',\n",
       "    'MMango',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Graziuape',\n",
       "    'Kiwi',\n",
       "    'Liiiiiiiiiiiiiiiiiiiemon',\n",
       "    'Mango',\n",
       "    'Mango']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyhry',\n",
       "    'Durian',\n",
       "    'fffffffffff',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Blueberry']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'DuriaccccccccnHello,',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Duriaccccccccn']],\n",
       "  [['iiiiiiiiiiiiiiiiiii',\n",
       "    'Mango',\n",
       "    'iiiiiiiiiiiiiii',\n",
       "    '10000000000',\n",
       "    'bb',\n",
       "    '◯',\n",
       "    'ccc',\n",
       "    'bb',\n",
       "    'bb']],\n",
       "  [['tODAY?',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет']],\n",
       "  [['are', 'bb', 'cccc', 'ccc']],\n",
       "  [['are', '', 'Bonjour,', 'öäü', 'ß', 'Ø', 'œ', 'Graziuape', '\\uf8ff']],\n",
       "  [['Apple',\n",
       "    'Avocao',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Fig']],\n",
       "  [['44',\n",
       "    'qeeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    'Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'qr',\n",
       "    'Bonjour,']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    'bbbbbb',\n",
       "    'qr',\n",
       "    'BonjourDuriaccccccccn,',\n",
       "    'qeeeeeeeee',\n",
       "    'Bonjour,',\n",
       "    'Bonjour,',\n",
       "    'qr']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'привет,',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'hhhhhhhhhhhhhhhh122',\n",
       "    '◯',\n",
       "    '999999bbbbbb999',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '']],\n",
       "  [['cccc', 'ccKiwic', 'ccc']],\n",
       "  [['   ', 'bună ziua', ' ', '   ', '         ', '◯◯◯', '◯◯◯']],\n",
       "  [['  a  ', 'bb', 'ccc', '  a  ', 'bb']],\n",
       "  [['ccccc',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'ccc',\n",
       "    'ccc',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'ccc']],\n",
       "  [['', '        ', '   ', '     ', '\\t']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'привет,',\n",
       "    'hhhhhhhhhhhhhhhh122',\n",
       "    '44444',\n",
       "    '◯',\n",
       "    '999999bbbbbb999',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '',\n",
       "    '77777']],\n",
       "  [['iiiiiiiiiiiiiiiiiii',\n",
       "    'Mango',\n",
       "    'iiiiiiiiiiiiiii',\n",
       "    '10000000000',\n",
       "    'bb',\n",
       "    '◯',\n",
       "    'ccc',\n",
       "    'bb',\n",
       "    'b']],\n",
       "  [[' ', '   ', ' ', '😀😀😀', '         ', '◯◯◯', '◯', '◯◯◯', '◯◯◯', ' ']],\n",
       "  [['DOiNG', '◯◯◯', 'bună ziua', ' ', '55555         ', '◯◯◯']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000']],\n",
       "  [['  a  ', 'bb', 'ccc', 'bb', 'bb', 'bb']],\n",
       "  [['', 'Bonjour,', 'öäü', 'ß', 'Ø', 'œ', '\\uf8ff', 'Ø']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'BonAvoJNGmH,Okrdojour,',\n",
       "    'qeeeeHola,eee',\n",
       "    'Bonjour,',\n",
       "    '       ',\n",
       "    'BonAvoJNGmHOkrdojour,',\n",
       "    'qr',\n",
       "    'BonjourDurian,',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'BonAvoJNGmHOkrdojour,',\n",
       "    'qeeeeeeeeee']],\n",
       "  [['defghijklmnop', '  ', ' ', '😀😀😀', '         ']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '4444',\n",
       "    '77771227',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888']],\n",
       "  [['cccc', 'TSNvGfDd', 'ccKiwic', 'ccc']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '77777',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '777aœbc777',\n",
       "    '44',\n",
       "    'Beeeeeeeeeeonjour,',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '77777777',\n",
       "    '22',\n",
       "    '7777777']],\n",
       "  [['    ', 'bună ziua', '😀😀😀', '         ', '◯◯◯', 'tODAY?', '◯◯◯']],\n",
       "  [['', 'Bonjour,', 'öäü', 'ß', 'Ø', 'œ']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'ccccccccc',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'bbbbbb']],\n",
       "  [['', 'bună ziua', '◯◯◯◯', ' ', '😀😀😀', '55555', '         ', '◯◯◯']],\n",
       "  [['Apple', 'abc', 'defghijklmnop', 'Bonjour,', '', 'Bonjour,', 'Bonjour,']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777b777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '666666',\n",
       "    '333',\n",
       "    '1']],\n",
       "  [['ccccc',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'cccc',\n",
       "    '888888888',\n",
       "    'ccc']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'првет,',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '4444',\n",
       "    'iiiiiiiiiiiiiiiiiiiAvocado',\n",
       "    '6Aplple66666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    ' 999999999',\n",
       "    '999999999',\n",
       "    '999999999']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    'bbbbbb',\n",
       "    '',\n",
       "    'qr',\n",
       "    'BonjourDuriaccccccccn,',\n",
       "    'qeeeeeeeee',\n",
       "    'Bonjour,',\n",
       "    'Bonjour,']],\n",
       "  [['1',\n",
       "    '9999999999',\n",
       "    '',\n",
       "    'привет,',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'hhhhhhhhhhhhhhhh122',\n",
       "    '◯',\n",
       "    '999999bbbbbb999',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '']],\n",
       "  [['', 'BonjourDuriaccccccccn,', 'bună ziua', ' ', '         ', '◯◯◯']],\n",
       "  [['1',\n",
       "    'привтет,',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '99999abc',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '4444',\n",
       "    '1']],\n",
       "  [['   ', 'bună ziua', ' ', '   ', ' a', '         ', '◯◯◯', '◯◯◯']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '66666Ø',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '1',\n",
       "    '2',\n",
       "    '1',\n",
       "    '7777777']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    '44Orange',\n",
       "    'Kiwi',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'Mango',\n",
       "    'Orange']],\n",
       "  [['55', 'Apple', 'bbccc', 'bbccc']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Avocado']],\n",
       "  [['Or', '  a  ', 'bb', 'ccc', 'bb', 'bb', 'Beeeeeeeeeeonjour,', 'bb']],\n",
       "  [['Apple',\n",
       "    'MMango',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'првет,',\n",
       "    'Graziuape',\n",
       "    'Kiwi',\n",
       "    'Liiiiiiiiiiiiiiiiiiiemon',\n",
       "    'Mango',\n",
       "    'Banana']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '11',\n",
       "    '88888888',\n",
       "    '7777777']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'qeeeeHola,eee',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'qr']],\n",
       "  [['   ', 'bună ziua', ' ', '       ', ' a', '         ', '◯◯◯', '◯◯◯']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '22',\n",
       "    '33',\n",
       "    '444',\n",
       "    '66qeeeeeeeee6666',\n",
       "    'Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '99999999',\n",
       "    '10000000000',\n",
       "    '1',\n",
       "    '2',\n",
       "    '2',\n",
       "    '4444']],\n",
       "  [['', 'öäü', 'ß', 'Ø', 'æ', 'œ', '\\uf8ff', 'öäü']],\n",
       "  [['Or', '  a  ', 'ccc', 'bb', 'bb', '99999999', 'bb']],\n",
       "  [['iiiiiiiiiiiiiiiiiii',\n",
       "    'Mango',\n",
       "    '10000000000',\n",
       "    'bb',\n",
       "    '◯',\n",
       "    'ccc',\n",
       "    'bbCherry']],\n",
       "  [['Avocado',\n",
       "    'Bananпрвет,a',\n",
       "    'Avocado',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Or',\n",
       "    'DOiNG',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Orangre',\n",
       "    'Duriaccccccccn',\n",
       "    'Orangre']],\n",
       "  [['Avocado',\n",
       "    'Bananпрвет,a',\n",
       "    'Avocado',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Or',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Orangre',\n",
       "    'Duriaccccccccn',\n",
       "    'Orangre',\n",
       "    'Bananпрвет,a']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '77777',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '44',\n",
       "    'Beeeeeeeeeeonjour,',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '77777777',\n",
       "    '22',\n",
       "    '7777777',\n",
       "    '666666',\n",
       "    '7755777',\n",
       "    '1',\n",
       "    '7777777']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Blueberry',\n",
       "    'Durian',\n",
       "    '◯◯◯◯',\n",
       "    'Fig',\n",
       "    'Graziuape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Fig']],\n",
       "  [['1',\n",
       "    'привет,',\n",
       "    '122',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '11',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '   ',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    'привет,']],\n",
       "  [['22',\n",
       "    '333',\n",
       "    'прbună',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '88888888']],\n",
       "  [['Apple',\n",
       "    'MMango',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'GraziGraziuapeuape',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'првет,',\n",
       "    'Graziuape',\n",
       "    'Kiwi',\n",
       "    'Liiiiiiiiiiiiiiiiiiiemon',\n",
       "    'Mango',\n",
       "    'Banana',\n",
       "    'Avocado']],\n",
       "  [['', '◯◯◯', ' ', '😀😀😀', '   ', '', '']],\n",
       "  [['qeeeeeeeeeee',\n",
       "    'qeeeeeeeeee',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'Bonjour,']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    '44Orange',\n",
       "    'Kiwi',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    '44Orange']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '77777',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '44',\n",
       "    'Beeeeeeeeeeonjour,',\n",
       "    '999999999',\n",
       "    ' a',\n",
       "    '10000000000',\n",
       "    '22',\n",
       "    '7777777']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'Cherry',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'bbbbbb',\n",
       "    'bbbbbb',\n",
       "    'eeeeeeeeee']],\n",
       "  [['cccc', 'こんにちは, Bonjour,u Hello, Hola, прbună ziuaвет', 'ccc']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Orange',\n",
       "    'Mango',\n",
       "    'Avocado',\n",
       "    'Cyherry']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    '😀😀😀',\n",
       "    'iiiiiiiiiiiiiiiiiii',\n",
       "    'bbbbbbb',\n",
       "    'eeeeeeeeee']],\n",
       "  [['abc', 'defghijklmnop', ' ', 'qr', ' ']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Kiwi',\n",
       "    'Applle',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Duriaccccccccn']],\n",
       "  [['', 'bună ziua', ' ', '         ', '◯◯◯', ' ']],\n",
       "  [['  a    ']],\n",
       "  [['  a  ', 'bb', 'ccc', 'kdefghijklmnop', '  a  ', 'bb']],\n",
       "  [['こんにちは, Bonjour, Hello, Hola, привет', 'cccc', 'ccc', 'ccc', 'ccc']],\n",
       "  [['cccc', 'ccKiwic', 'ccc', 'ccc', 'ccc']],\n",
       "  [['defghijklmnop']],\n",
       "  [['6666666',\n",
       "    '1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '11',\n",
       "    '88888888',\n",
       "    '7777777']],\n",
       "  [['Aplple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Lemonœ',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Grape']],\n",
       "  [['tODAY?',\n",
       "    '\\uf8ff6Aplple66666',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет']],\n",
       "  [['', 'MMango', '     ', '22', '']],\n",
       "  [['Apple', 'bbccc', 'bbccc', 'bbccc']],\n",
       "  [['1',\n",
       "    '9999999999',\n",
       "    '',\n",
       "    'привет,',\n",
       "    'hhHello, Bonjour, こんにちは, Hola, пр77771227иNEsветhhhhhhhhhhhhhh',\n",
       "    'hhhhhhhhhhhhhhhh122',\n",
       "    '◯',\n",
       "    '999999bbbbbb999',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'aœbc',\n",
       "    'qeeeeHola,eee',\n",
       "    '         qr',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'qr']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'defghijklmnop']],\n",
       "  [['◯◯◯', ' ', '😀😀😀', '    \\t']],\n",
       "  [[' ',\n",
       "    '',\n",
       "    ' ',\n",
       "    '😀😀😀',\n",
       "    '         ',\n",
       "    'привет,',\n",
       "    '◯◯◯',\n",
       "    '◯◯◯',\n",
       "    '◯',\n",
       "    '◯◯◯',\n",
       "    '◯◯◯']],\n",
       "  [['iiiiiiiiiiiiiiiiiii',\n",
       "    'Mango',\n",
       "    '10000000000',\n",
       "    'bb',\n",
       "    '◯',\n",
       "    'ccc',\n",
       "    'bb',\n",
       "    'bbb']],\n",
       "  [[' ', '   ', '  ', '         ', '◯◯◯', '◯', '◯◯◯', '◯◯◯', ' ']],\n",
       "  [['iiiiiiiiiiiiiiiiiii',\n",
       "    'Mango',\n",
       "    'Appple',\n",
       "    '10000000000',\n",
       "    'bb',\n",
       "    '◯',\n",
       "    'ccc',\n",
       "    'bbCherry']],\n",
       "  [['Hello, Hola, Bonjour, こんにちは, привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, привет',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет555555',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello',\n",
       "    'ສະບາຍດີ, Bonjour, こんにちは, Hola, привет']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'BonAvoJNGmH,Okrdojour,',\n",
       "    'qeeeeHola,eee',\n",
       "    'Bonjour,',\n",
       "    '       ',\n",
       "    'BonAvoJNGmHOkrdojour,',\n",
       "    'qr',\n",
       "    'BonjourDurian,',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'BonAvoJNGmHOFkrdojour,',\n",
       "    'qeeeeeeeeee',\n",
       "    'qeeeeeeeeee']],\n",
       "  [['', 'bună ziua', '', '◯◯◯◯', ' ', '😀😀😀', '         ', ' ']],\n",
       "  [['Apple',\n",
       "    'MMango',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Graziuape',\n",
       "    'Kiwi',\n",
       "    'Liiiiiiiiiiiiiiiiiiiemon',\n",
       "    'Mango',\n",
       "    'ggggggggggggg']],\n",
       "  [['Durian', 'ccc']],\n",
       "  [['abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    '',\n",
       "    'BonjourDuriaccccccccn,',\n",
       "    'qeeeeHola,eee',\n",
       "    'Bonjour,']],\n",
       "  [['ziua', '  a  ', 'bb', 'ccc', 'bb', 'bb', 'Beeeeeeeeeeonjour,', 'bb']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Avocado',\n",
       "    'Mango']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '66Avocao',\n",
       "    '88888888',\n",
       "    'aaaa',\n",
       "    '10000000000',\n",
       "    '666666',\n",
       "    '66qeeehelloeeeeee6666',\n",
       "    '333']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Orangne',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'qeeeeeeeee',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Duriaccccccccn',\n",
       "    'Kiwi']],\n",
       "  [['22',\n",
       "    '333',\n",
       "    '44444',\n",
       "    '555555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '666666']],\n",
       "  [['Avocado',\n",
       "    'Bananпрвет,a',\n",
       "    'Avocado',\n",
       "    'NDOiNG',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Or',\n",
       "    'DOiNG',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Orangre',\n",
       "    'Duriaccccccccn',\n",
       "    'Orangre']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyhry',\n",
       "    'Durian',\n",
       "    'fffffffffff',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Oranege',\n",
       "    'Blueberry']],\n",
       "  [['', '    \\t', '   ', '     ', '\\t', '   \\t']],\n",
       "  [['   ', ' ', '😀😀😀', '         ', '◯◯◯', 'tODAY?', '😀😀😀', '◯◯◯', 'tODAY?']],\n",
       "  [['ziua',\n",
       "    '  a  ',\n",
       "    'bb',\n",
       "    'ccc',\n",
       "    'bb',\n",
       "    'bb',\n",
       "    'B9999999999eeeeeeonjour,',\n",
       "    'bb']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '77777',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '44',\n",
       "    'Beeeeeeeeeeonjour,',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '77777777',\n",
       "    '9999◯◯◯◯99999',\n",
       "    '7777777',\n",
       "    '666666',\n",
       "    '1']],\n",
       "  [['1',\n",
       "    'привтет,',\n",
       "    '22',\n",
       "    '333',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '99999abc',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '44444',\n",
       "    '4444',\n",
       "    '1',\n",
       "    '7777777']],\n",
       "  [['', 'öäü', 'ß', 'Ø', 'œ', '\\uf8ff', '', 'œ', '\\uf8ff']],\n",
       "  [['qeeeeeeeeee', 'defghijklmnop', '', 'qr', 'qr', 'defghijklmnop']],\n",
       "  [['1',\n",
       "    '',\n",
       "    'привет,',\n",
       "    '',\n",
       "    '4444',\n",
       "    '55555',\n",
       "    '666666',\n",
       "    '77777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '1',\n",
       "    '88888888']],\n",
       "  [['', '        ', '    \\t', '   ', '\\t55', '\\t', '   \\t']],\n",
       "  [['Hello, Bonjour, こんにちは, Hola, пр77771227иNEsвет',\n",
       "    'こんにちは, Bonjour,u Hello, Hola,H привет',\n",
       "    'Hello, Bonjour, こんにちは, Hola, приNEsвет',\n",
       "    'привет, Hola, Bonjour, こんにちは, Hello']],\n",
       "  [['', 'öäü', '', 'Ø', 'œ', '\\uf8ff', '', 'œ', '\\uf8ff']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'qeeeeHola,eee',\n",
       "    'Beeeeeeeeeeonjour,',\n",
       "    'Bonjour,',\n",
       "    '       ',\n",
       "    'BonAvoJNGmHOkrdojour,',\n",
       "    'qr',\n",
       "    'BonjourDurian,',\n",
       "    'qr',\n",
       "    'qr',\n",
       "    'BonAvoJNGmHOkrdojour,']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cherry',\n",
       "    'Fig',\n",
       "    'Cyhry',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Avocado',\n",
       "    'Mango']],\n",
       "  [['iiiiiiiiiiiiiiiiiii', '  a  ', 'bb', 'ccc', 'bb', 'bb', 'ccc']],\n",
       "  [['\\uf8ff6Aplple66666', 'ß', 'öäü', 'Ø', 'œ', '\\uf8ff']],\n",
       "  [['', ' ', '         ', '◯◯◯']],\n",
       "  [['Apple',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'Bonjour,',\n",
       "    'Bonjour,']],\n",
       "  [['are', 'bb', 'ccc', 'ccc']],\n",
       "  [['', '◯◯◯', 'bună ziua', ' ', '😀😀😀', '55555         ']],\n",
       "  [['Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'ziua',\n",
       "    'Duriaccccccccn',\n",
       "    'Avocadqro',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'DOiNG',\n",
       "    '55555',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'hhhhhhhhhhhhhhhh',\n",
       "    'Orangre',\n",
       "    'Duriaccccccccn',\n",
       "    'Grape']],\n",
       "  [['Hello', 'dBlueberryefghijklmnop', '', 'qr', 'Grapこんにちは,']],\n",
       "  [['Avocado',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Duriaccccccccn',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    'Kiwi',\n",
       "    'Lemon',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    'Orangre',\n",
       "    'Duriaccccccccn']],\n",
       "  [['Apple',\n",
       "    'Appple',\n",
       "    'Banana',\n",
       "    'Blueberry',\n",
       "    'Cyherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    '44Orange',\n",
       "    'Kiwi',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    '44Orange',\n",
       "    'Durian']],\n",
       "  [['qeeeeeeeeee',\n",
       "    'abc',\n",
       "    'defghijklmnop',\n",
       "    'Bonjour,',\n",
       "    'bbbbbb',\n",
       "    '',\n",
       "    'qr',\n",
       "    'BonjourDuriaccccccccn,',\n",
       "    'qeeeeeeeee',\n",
       "    'Bonjour,',\n",
       "    'DOiNG',\n",
       "    'Bonjour,']],\n",
       "  [['aaaa',\n",
       "    'bbbbbb',\n",
       "    'cccccccc',\n",
       "    'ddddddddd',\n",
       "    'eeeeeeeeee',\n",
       "    'fffffffffff',\n",
       "    'ggggggggggggg',\n",
       "    'hhhhhhhhhhhhhhhh']],\n",
       "  [['Apple',\n",
       "    'Avocado',\n",
       "    'Banana',\n",
       "    '555555',\n",
       "    'Cyherry',\n",
       "    'Durian',\n",
       "    'Fig',\n",
       "    'Grape',\n",
       "    '44Orange',\n",
       "    'bQYg',\n",
       "    'Kiwi',\n",
       "    'こんにちは, Bonjour, Hello, Hola, привет',\n",
       "    'Mango',\n",
       "    'Orange',\n",
       "    '44Orange']],\n",
       "  [['22',\n",
       "    '33         3',\n",
       "    '44444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '88888888',\n",
       "    '999999999',\n",
       "    '666666']],\n",
       "  [['1',\n",
       "    '22',\n",
       "    '333',\n",
       "    '77777',\n",
       "    '4444',\n",
       "    '666666',\n",
       "    '7777777',\n",
       "    '44',\n",
       "    'Beeeeeeeeeeonjour,',\n",
       "    '999999999',\n",
       "    '10000000000',\n",
       "    '77777777',\n",
       "    '22',\n",
       "    '666666',\n",
       "    '1']],\n",
       "  [['ccfffffffffff', '  a  ', 'bb', 'ccc', 'kdefghijklmnop', '  a  ', 'bb']]]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_eval['HumanEval/12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/codeEval/data.jsonl','w') as fw:\n",
    "#     for item in data.keys():\n",
    "#         fw.write(json.dumps(data[item])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {}\n",
    "# for dir,subdir ,files in os.walk('./data/math401/save'):\n",
    "#     for file in files:\n",
    "#         tmp = calculate_accuracy(os.path.join(dir,file),return_tuple=True)\n",
    "#         nan_ratio = calculate_nan_ratio(os.path.join(dir,file))\n",
    "#         RE_List = calculate_RE(os.path.join(dir,file))\n",
    "#         data[tmp[0]] = {'Accuracy':tmp[1],'Nan_Ratio':nan_ratio,'RE_List':RE_List[:]}\n",
    "# df = pd.DataFrame(data).T.sort_index()\n",
    "# df.to_json('./data/math401/math50_eval_result_df.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval = []\n",
    "with open('./data/codeEval/code_sanitize/qwen-72b.jsonl') as f:\n",
    "    for line in f.readlines():\n",
    "        data_eval.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from typing import List\\ndef parse_nested_parens(paren_string: str) -> List[int]:\\n    result = []\\n    for group in paren_string.split():\\n        stack = []\\n        max_depth = 0\\n        for char in group:\\n            if char == '(':\\n                stack.append(char)\\n                if len(stack) > max_depth:\\n                    max_depth = len(stack)\\n            elif char == ')':\\n                stack.pop()\\n        result.append(max_depth)\\n    return result\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_eval[1]['solution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_globals = {}\n",
    "exec(data_eval[1]['solution'],exec_globals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HumanEval/6'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = exec_globals['parse_nested_parens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/codeEval/data.json') as f:\n",
    "    data_o = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 'HumanEval/6',\n",
       " 'prompt': 'from typing import List\\n\\n\\ndef parse_nested_parens(paren_string: str) -> List[int]:\\n    \"\"\" Input to this function is a string represented multiple groups for nested parentheses separated by spaces.\\n    For each of the group, output the deepest level of nesting of parentheses.\\n    E.g. (()()) has maximum two levels of nesting while ((())) has three.\\n\\n    >>> parse_nested_parens(\\'(()()) ((())) () ((())()())\\')\\n    [2, 3, 1, 3]\\n    \"\"\"\\n',\n",
       " 'entry_point': 'parse_nested_parens',\n",
       " 'canonical_solution': '\\n    \\n    def count_depth(s: str) -> int:\\n        max_depth, cnt = 0, 0\\n        for ch in s:\\n            if ch == \"(\": cnt += 1\\n            if ch == \")\": cnt -= 1\\n            max_depth = max(max_depth, cnt)\\n        return max_depth\\n    \\n    return [count_depth(s) for s in paren_string.split(\" \") if s != \"\"]\\n\\n',\n",
       " 'test': \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate('(()()) ((())) () ((())()())') == [2, 3, 1, 3]\\n    assert candidate('() (()) ((())) (((())))') == [1, 2, 3, 4]\\n    assert candidate('(()(())((())))') == [4]\\n\",\n",
       " 'contract': '\\n    assert type(paren_string) == str, \"invalid inputs\" # $_CONTRACT_$\\n    cnt = 0 # $_CONTRACT_$\\n    for ch in paren_string: # $_CONTRACT_$\\n        assert ch in [\"(\", \")\", \" \"], \"invalid inputs\"  # $_CONTRACT_$\\n        if ch == \"(\": cnt += 1 # $_CONTRACT_$\\n        if ch == \")\": cnt -= 1 # $_CONTRACT_$\\n        assert cnt >= 0, \"invalid inputs\" # $_CONTRACT_$\\n    assert cnt == 0, \"invalid inputs\"\\n',\n",
       " 'base_input': [['(()()) ((())) () ((())()())'],\n",
       "  ['() (()) ((())) (((())))'],\n",
       "  ['(()(())((())))']],\n",
       " 'atol': 0,\n",
       " 'plus_input': [[''],\n",
       "  ['((()))'],\n",
       "  ['(())(()())'],\n",
       "  ['(())(()(()))((()()))'],\n",
       "  ['(()()(((())))(()(())))()'],\n",
       "  ['()((()))'],\n",
       "  ['(())'],\n",
       "  ['()()()'],\n",
       "  ['()(())'],\n",
       "  ['(((())(()(()))((()()))))(()(()))((()()))'],\n",
       "  ['(()()(()(())((()()(((())))(()(())))())(((()))))(()(())))()'],\n",
       "  ['((()(())(()(()))((()()))))'],\n",
       "  ['(()()(((())))(()(())(((())(()(()))((()()))))(()(()))((()()))))()'],\n",
       "  ['((()()(((())))(()(())))())((()()))'],\n",
       "  ['(()()(((())((()()(((())))(()(())))())(((()))))(()(()))))()'],\n",
       "  ['()(()()(((())))(()(())(((())(()(()))((()()))))(()(()))((()()))))()((()))'],\n",
       "  ['((()(())((()(()))((()())))))'],\n",
       "  ['((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))'],\n",
       "  ['((((((())(())))())((()()()(()(((()(()))))))))()(((())(()(()))((()()()))()))((()))()(()))()'],\n",
       "  ['()()()()()()'],\n",
       "  ['((((((()))(()()((()))))(()))))'],\n",
       "  ['(((())))'],\n",
       "  ['((()())()())'],\n",
       "  ['()()()()()'],\n",
       "  ['((((())()))()(()))(())'],\n",
       "  ['((())()()()((((())(())))))'],\n",
       "  ['(((((((()()()((()))(())()((()))((()())(())))))))()())()())'],\n",
       "  ['((((())())))(())(())'],\n",
       "  ['()(((())))'],\n",
       "  ['(((((((())))))))'],\n",
       "  ['(((((()(((()))))(()))()()())(())))()(())(())'],\n",
       "  ['((())())()()'],\n",
       "  ['((())()()((((())(())))))'],\n",
       "  ['(()(())()())'],\n",
       "  ['((((())(())))()()())((()))(())'],\n",
       "  ['((()))()()()'],\n",
       "  ['((((())())))(())'],\n",
       "  ['(((((((((((((((())))))))))))))))'],\n",
       "  ['((((((((((((())()()()))()))))(()))(())))))'],\n",
       "  ['(((((((())((((())(())))))))())))()'],\n",
       "  ['((((())((())))()(())))'],\n",
       "  ['((((((((((()))))))((()))()))))'],\n",
       "  ['(()(())())'],\n",
       "  ['()'],\n",
       "  ['((((((((((())))))))((()))((((((((())((((())(())))(((()()((())((()))(()((((()))()())))))())((((())))((()((((((())))))))))())))))()((((())))))))))))'],\n",
       "  ['((((((((()(()))))))(((()))()))))'],\n",
       "  ['((((((((((((((()))))))((()))()))))))))'],\n",
       "  ['((((((((((((((()))))))((()))())((((((((()(()))))))(((()))())))))))))))'],\n",
       "  ['((((())())(((((((())((((())(()))))(((()()((())((()))(()((((()))()())))))())((((())))((()((((((())))))))))())))))()((((()))))))))(())(())'],\n",
       "  ['((((())((()))())(())))'],\n",
       "  ['((())()())'],\n",
       "  ['()()()()()((((((((((()))))))((()))()))))()'],\n",
       "  ['((((((((((())))))((()))))(()))))'],\n",
       "  ['((((((((((())))))))((()))((((((((())((((())(())))(((()()((())((()))(()((((()))()())))))())((((()))))((()(((((((())))))))))())))))()((((())))))))))))'],\n",
       "  ['((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()(((((())))))))))))'],\n",
       "  ['(((((()()()((()))(())()((()))())))))(()((((((((((()))))))((())))))))'],\n",
       "  ['((((((()))(()()((())))))))'],\n",
       "  ['(((((((()))))(()))))'],\n",
       "  ['()()()()'],\n",
       "  ['(((((()()()((()))(())()((()))((()())((((((()))(()()((()))))(()))))(())))))))'],\n",
       "  ['((((((()))(()()((())(((((()()()((()))(())()((()))((()())(())))))))))))))'],\n",
       "  ['(((())((((((()(()))))))((((((((((((()))))))((())(()))())))((()))))))((()))))'],\n",
       "  ['((((((((()(())))()))(((())))()))))'],\n",
       "  ['((((((((((()))))))((()))())))((())()()))'],\n",
       "  ['(((((((())((((())(())))(((()()((())((()))(()(((((()))()())))))))((((())))((()((((((())))))))))())))))())((((()))))))'],\n",
       "  ['(((((((((())((((())(())))(((()()((())((()))(()((((()))()())))))())((((())))((()((((((())))))))))())))))()((((()))))))((((())())))(())(())((((((((()))))))((())))())))((())()()))']]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_o['HumanEval/6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__builtins__': {'__name__': 'builtins',\n",
       "  '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\",\n",
       "  '__package__': '',\n",
       "  '__loader__': _frozen_importlib.BuiltinImporter,\n",
       "  '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'),\n",
       "  '__build_class__': <function __build_class__>,\n",
       "  '__import__': <function __import__>,\n",
       "  'abs': <function abs(x, /)>,\n",
       "  'all': <function all(iterable, /)>,\n",
       "  'any': <function any(iterable, /)>,\n",
       "  'ascii': <function ascii(obj, /)>,\n",
       "  'bin': <function bin(number, /)>,\n",
       "  'breakpoint': <function breakpoint>,\n",
       "  'callable': <function callable(obj, /)>,\n",
       "  'chr': <function chr(i, /)>,\n",
       "  'compile': <function compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1, *, _feature_version=-1)>,\n",
       "  'delattr': <function delattr(obj, name, /)>,\n",
       "  'dir': <function dir>,\n",
       "  'divmod': <function divmod(x, y, /)>,\n",
       "  'eval': <function eval(source, globals=None, locals=None, /)>,\n",
       "  'exec': <function exec(source, globals=None, locals=None, /)>,\n",
       "  'format': <function format(value, format_spec='', /)>,\n",
       "  'getattr': <function getattr>,\n",
       "  'globals': <function globals()>,\n",
       "  'hasattr': <function hasattr(obj, name, /)>,\n",
       "  'hash': <function hash(obj, /)>,\n",
       "  'hex': <function hex(number, /)>,\n",
       "  'id': <function id(obj, /)>,\n",
       "  'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x0000019E5CC0E0D0>>,\n",
       "  'isinstance': <function isinstance(obj, class_or_tuple, /)>,\n",
       "  'issubclass': <function issubclass(cls, class_or_tuple, /)>,\n",
       "  'iter': <function iter>,\n",
       "  'len': <function len(obj, /)>,\n",
       "  'locals': <function locals()>,\n",
       "  'max': <function max>,\n",
       "  'min': <function min>,\n",
       "  'next': <function next>,\n",
       "  'oct': <function oct(number, /)>,\n",
       "  'ord': <function ord(c, /)>,\n",
       "  'pow': <function pow(base, exp, mod=None)>,\n",
       "  'print': <function print>,\n",
       "  'repr': <function repr(obj, /)>,\n",
       "  'round': <function round(number, ndigits=None)>,\n",
       "  'setattr': <function setattr(obj, name, value, /)>,\n",
       "  'sorted': <function sorted(iterable, /, *, key=None, reverse=False)>,\n",
       "  'sum': <function sum(iterable, /, start=0)>,\n",
       "  'vars': <function vars>,\n",
       "  'None': None,\n",
       "  'Ellipsis': Ellipsis,\n",
       "  'NotImplemented': NotImplemented,\n",
       "  'False': False,\n",
       "  'True': True,\n",
       "  'bool': bool,\n",
       "  'memoryview': memoryview,\n",
       "  'bytearray': bytearray,\n",
       "  'bytes': bytes,\n",
       "  'classmethod': classmethod,\n",
       "  'complex': complex,\n",
       "  'dict': dict,\n",
       "  'enumerate': enumerate,\n",
       "  'filter': filter,\n",
       "  'float': float,\n",
       "  'frozenset': frozenset,\n",
       "  'property': property,\n",
       "  'int': int,\n",
       "  'list': list,\n",
       "  'map': map,\n",
       "  'object': object,\n",
       "  'range': range,\n",
       "  'reversed': reversed,\n",
       "  'set': set,\n",
       "  'slice': slice,\n",
       "  'staticmethod': staticmethod,\n",
       "  'str': str,\n",
       "  'super': super,\n",
       "  'tuple': tuple,\n",
       "  'type': type,\n",
       "  'zip': zip,\n",
       "  '__debug__': True,\n",
       "  'BaseException': BaseException,\n",
       "  'Exception': Exception,\n",
       "  'TypeError': TypeError,\n",
       "  'StopAsyncIteration': StopAsyncIteration,\n",
       "  'StopIteration': StopIteration,\n",
       "  'GeneratorExit': GeneratorExit,\n",
       "  'SystemExit': SystemExit,\n",
       "  'KeyboardInterrupt': KeyboardInterrupt,\n",
       "  'ImportError': ImportError,\n",
       "  'ModuleNotFoundError': ModuleNotFoundError,\n",
       "  'OSError': OSError,\n",
       "  'EnvironmentError': OSError,\n",
       "  'IOError': OSError,\n",
       "  'WindowsError': OSError,\n",
       "  'EOFError': EOFError,\n",
       "  'RuntimeError': RuntimeError,\n",
       "  'RecursionError': RecursionError,\n",
       "  'NotImplementedError': NotImplementedError,\n",
       "  'NameError': NameError,\n",
       "  'UnboundLocalError': UnboundLocalError,\n",
       "  'AttributeError': AttributeError,\n",
       "  'SyntaxError': SyntaxError,\n",
       "  'IndentationError': IndentationError,\n",
       "  'TabError': TabError,\n",
       "  'LookupError': LookupError,\n",
       "  'IndexError': IndexError,\n",
       "  'KeyError': KeyError,\n",
       "  'ValueError': ValueError,\n",
       "  'UnicodeError': UnicodeError,\n",
       "  'UnicodeEncodeError': UnicodeEncodeError,\n",
       "  'UnicodeDecodeError': UnicodeDecodeError,\n",
       "  'UnicodeTranslateError': UnicodeTranslateError,\n",
       "  'AssertionError': AssertionError,\n",
       "  'ArithmeticError': ArithmeticError,\n",
       "  'FloatingPointError': FloatingPointError,\n",
       "  'OverflowError': OverflowError,\n",
       "  'ZeroDivisionError': ZeroDivisionError,\n",
       "  'SystemError': SystemError,\n",
       "  'ReferenceError': ReferenceError,\n",
       "  'MemoryError': MemoryError,\n",
       "  'BufferError': BufferError,\n",
       "  'Warning': Warning,\n",
       "  'UserWarning': UserWarning,\n",
       "  'DeprecationWarning': DeprecationWarning,\n",
       "  'PendingDeprecationWarning': PendingDeprecationWarning,\n",
       "  'SyntaxWarning': SyntaxWarning,\n",
       "  'RuntimeWarning': RuntimeWarning,\n",
       "  'FutureWarning': FutureWarning,\n",
       "  'ImportWarning': ImportWarning,\n",
       "  'UnicodeWarning': UnicodeWarning,\n",
       "  'BytesWarning': BytesWarning,\n",
       "  'ResourceWarning': ResourceWarning,\n",
       "  'ConnectionError': ConnectionError,\n",
       "  'BlockingIOError': BlockingIOError,\n",
       "  'BrokenPipeError': BrokenPipeError,\n",
       "  'ChildProcessError': ChildProcessError,\n",
       "  'ConnectionAbortedError': ConnectionAbortedError,\n",
       "  'ConnectionRefusedError': ConnectionRefusedError,\n",
       "  'ConnectionResetError': ConnectionResetError,\n",
       "  'FileExistsError': FileExistsError,\n",
       "  'FileNotFoundError': FileNotFoundError,\n",
       "  'IsADirectoryError': IsADirectoryError,\n",
       "  'NotADirectoryError': NotADirectoryError,\n",
       "  'InterruptedError': InterruptedError,\n",
       "  'PermissionError': PermissionError,\n",
       "  'ProcessLookupError': ProcessLookupError,\n",
       "  'TimeoutError': TimeoutError,\n",
       "  'open': <function io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
       "  'copyright': Copyright (c) 2001-2023 Python Software Foundation.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 2000 BeOpen.com.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
       "  All Rights Reserved.\n",
       "  \n",
       "  Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
       "  All Rights Reserved.,\n",
       "  'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
       "      for supporting Python development.  See www.python.org for more information.,\n",
       "  'license': See https://www.python.org/psf/license/,\n",
       "  'help': Type help() for interactive help, or help(object) for help about object.,\n",
       "  'execfile': <function _pydev_bundle._pydev_execfile.execfile(file, glob=None, loc=None)>,\n",
       "  'runfile': <function _pydev_bundle.pydev_umd.runfile(filename, args=None, wdir=None, namespace=None)>,\n",
       "  '__IPYTHON__': True,\n",
       "  'display': <function IPython.core.display_functions.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, raw=False, clear=False, **kwargs)>,\n",
       "  'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x0000019E5D06A1F0>>}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(\"\",env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(data_o['HumanEval/6']['prompt']+data_o['HumanEval/6']['canonical_solution'],env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_st = env[data_o['HumanEval/6']['entry_point']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "ret_st = []\n",
    "for inp in  data_o['HumanEval/6']['plus_input']:\n",
    "    inp = inp[:]\n",
    "    tmp = inp[:]\n",
    "    ret.append(fn(*inp))\n",
    "    ret_st.append(fn_st(*tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[''],\n",
       " ['((()))'],\n",
       " ['(())(()())'],\n",
       " ['(())(()(()))((()()))'],\n",
       " ['(()()(((())))(()(())))()'],\n",
       " ['()((()))'],\n",
       " ['(())'],\n",
       " ['()()()'],\n",
       " ['()(())'],\n",
       " ['(((())(()(()))((()()))))(()(()))((()()))'],\n",
       " ['(()()(()(())((()()(((())))(()(())))())(((()))))(()(())))()'],\n",
       " ['((()(())(()(()))((()()))))'],\n",
       " ['(()()(((())))(()(())(((())(()(()))((()()))))(()(()))((()()))))()'],\n",
       " ['((()()(((())))(()(())))())((()()))'],\n",
       " ['(()()(((())((()()(((())))(()(())))())(((()))))(()(()))))()'],\n",
       " ['()(()()(((())))(()(())(((())(()(()))((()()))))(()(()))((()()))))()((()))'],\n",
       " ['((()(())((()(()))((()())))))'],\n",
       " ['((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))'],\n",
       " ['((((((())(())))())((()()()(()(((()(()))))))))()(((())(()(()))((()()()))()))((()))()(()))()'],\n",
       " ['()()()()()()'],\n",
       " ['((((((()))(()()((()))))(()))))'],\n",
       " ['(((())))'],\n",
       " ['((()())()())'],\n",
       " ['()()()()()'],\n",
       " ['((((())()))()(()))(())'],\n",
       " ['((())()()()((((())(())))))'],\n",
       " ['(((((((()()()((()))(())()((()))((()())(())))))))()())()())'],\n",
       " ['((((())())))(())(())'],\n",
       " ['()(((())))'],\n",
       " ['(((((((())))))))'],\n",
       " ['(((((()(((()))))(()))()()())(())))()(())(())'],\n",
       " ['((())())()()'],\n",
       " ['((())()()((((())(())))))'],\n",
       " ['(()(())()())'],\n",
       " ['((((())(())))()()())((()))(())'],\n",
       " ['((()))()()()'],\n",
       " ['((((())())))(())'],\n",
       " ['(((((((((((((((())))))))))))))))'],\n",
       " ['((((((((((((())()()()))()))))(()))(())))))'],\n",
       " ['(((((((())((((())(())))))))())))()'],\n",
       " ['((((())((())))()(())))'],\n",
       " ['((((((((((()))))))((()))()))))'],\n",
       " ['(()(())())'],\n",
       " ['()'],\n",
       " ['((((((((((())))))))((()))((((((((())((((())(())))(((()()((())((()))(()((((()))()())))))())((((())))((()((((((())))))))))())))))()((((())))))))))))'],\n",
       " ['((((((((()(()))))))(((()))()))))'],\n",
       " ['((((((((((((((()))))))((()))()))))))))'],\n",
       " ['((((((((((((((()))))))((()))())((((((((()(()))))))(((()))())))))))))))'],\n",
       " ['((((())())(((((((())((((())(()))))(((()()((())((()))(()((((()))()())))))())((((())))((()((((((())))))))))())))))()((((()))))))))(())(())'],\n",
       " ['((((())((()))())(())))'],\n",
       " ['((())()())'],\n",
       " ['()()()()()((((((((((()))))))((()))()))))()'],\n",
       " ['((((((((((())))))((()))))(()))))'],\n",
       " ['((((((((((())))))))((()))((((((((())((((())(())))(((()()((())((()))(()((((()))()())))))())((((()))))((()(((((((())))))))))())))))()((((())))))))))))'],\n",
       " ['((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()((((()))))))))))((((((()()()((()))(())()(((((())))))))))))'],\n",
       " ['(((((()()()((()))(())()((()))())))))(()((((((((((()))))))((())))))))'],\n",
       " ['((((((()))(()()((())))))))'],\n",
       " ['(((((((()))))(()))))'],\n",
       " ['()()()()'],\n",
       " ['(((((()()()((()))(())()((()))((()())((((((()))(()()((()))))(()))))(())))))))'],\n",
       " ['((((((()))(()()((())(((((()()()((()))(())()((()))((()())(())))))))))))))'],\n",
       " ['(((())((((((()(()))))))((((((((((((()))))))((())(()))())))((()))))))((()))))'],\n",
       " ['((((((((()(())))()))(((())))()))))'],\n",
       " ['((((((((((()))))))((()))())))((())()()))'],\n",
       " ['(((((((())((((())(())))(((()()((())((()))(()(((((()))()())))))))((((())))((()((((((())))))))))())))))())((((()))))))'],\n",
       " ['(((((((((())((((())(())))(((()()((())((()))(()((((()))()())))))())((((())))((()((((((())))))))))())))))()((((()))))))((((())())))(())(())((((((((()))))))((())))())))((())()()))']]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_o['HumanEval/6']['plus_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(ret)\n",
    "acc = 0\n",
    "for i in range(n):\n",
    "    acc += 1 if ret[i] == ret_st[i] else 0\n",
    "acc/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [3],\n",
       " [2],\n",
       " [3],\n",
       " [5],\n",
       " [3],\n",
       " [2],\n",
       " [1],\n",
       " [2],\n",
       " [5],\n",
       " [8],\n",
       " [5],\n",
       " [7],\n",
       " [6],\n",
       " [9],\n",
       " [7],\n",
       " [6],\n",
       " [11],\n",
       " [10],\n",
       " [1],\n",
       " [8],\n",
       " [4],\n",
       " [3],\n",
       " [1],\n",
       " [5],\n",
       " [6],\n",
       " [10],\n",
       " [5],\n",
       " [4],\n",
       " [8],\n",
       " [9],\n",
       " [3],\n",
       " [6],\n",
       " [3],\n",
       " [5],\n",
       " [3],\n",
       " [5],\n",
       " [16],\n",
       " [13],\n",
       " [11],\n",
       " [6],\n",
       " [11],\n",
       " [3],\n",
       " [1],\n",
       " [22],\n",
       " [10],\n",
       " [15],\n",
       " [17],\n",
       " [19],\n",
       " [6],\n",
       " [3],\n",
       " [11],\n",
       " [11],\n",
       " [22],\n",
       " [12],\n",
       " [12],\n",
       " [8],\n",
       " [8],\n",
       " [1],\n",
       " [14],\n",
       " [14],\n",
       " [16],\n",
       " [10],\n",
       " [11],\n",
       " [18],\n",
       " [20]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [3],\n",
       " [2],\n",
       " [3],\n",
       " [5],\n",
       " [3],\n",
       " [2],\n",
       " [1],\n",
       " [2],\n",
       " [5],\n",
       " [8],\n",
       " [5],\n",
       " [7],\n",
       " [6],\n",
       " [9],\n",
       " [7],\n",
       " [6],\n",
       " [11],\n",
       " [10],\n",
       " [1],\n",
       " [8],\n",
       " [4],\n",
       " [3],\n",
       " [1],\n",
       " [5],\n",
       " [6],\n",
       " [10],\n",
       " [5],\n",
       " [4],\n",
       " [8],\n",
       " [9],\n",
       " [3],\n",
       " [6],\n",
       " [3],\n",
       " [5],\n",
       " [3],\n",
       " [5],\n",
       " [16],\n",
       " [13],\n",
       " [11],\n",
       " [6],\n",
       " [11],\n",
       " [3],\n",
       " [1],\n",
       " [22],\n",
       " [10],\n",
       " [15],\n",
       " [17],\n",
       " [19],\n",
       " [6],\n",
       " [3],\n",
       " [11],\n",
       " [11],\n",
       " [22],\n",
       " [12],\n",
       " [12],\n",
       " [8],\n",
       " [8],\n",
       " [1],\n",
       " [14],\n",
       " [14],\n",
       " [16],\n",
       " [10],\n",
       " [11],\n",
       " [18],\n",
       " [20]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalplus.evaluate import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--f=c:\\\\Users\\\\游锦亮\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-19400V4QYjsjrB1Su.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argv.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\Anaconda\\\\envs\\\\vllm\\\\lib\\\\site-packages\\\\ipykernel_launcher.py']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_args = argv\n",
    "argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_args.append('--dataset=humaneval')\n",
    "local_args.append('--samples=./data/codeEval/code_sanitize/qwen-72b.jsonl')\n",
    "local_args.append('--test-details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from ground-truth from C:\\Users\\游锦亮\\AppData\\Local\\evalplus\\evalplus\\Cache\\1376469eb11e2af066a52cb042f854bf.pkl\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:00, 569.87it/s]\n",
      "100%|██████████| 28/28 [00:03<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mhumaneval (base tests)\u001b[0m\n",
      "\u001b[31mpass@1:\t0.000\u001b[0m\n",
      "\u001b[32mhumaneval+ (base + extra tests)\u001b[0m\n",
      "\u001b[32mpass@1:\t0.000\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/codeEval/data.json', 'r') as f:\n",
    "    data_eval = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalplus.gen.util import trusted_exec\n",
    "from evalplus.eval import (\n",
    "    FAIL,\n",
    "    PASS,\n",
    "    compatible_eval_result,\n",
    "    estimate_pass_at_k,\n",
    "    untrusted_check,\n",
    ")\n",
    "from evalplus.gen.util import trusted_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groundtruth(problems, tasks_only_output_not_none):\n",
    "    print(\"Computing expected output...\")\n",
    "    tbegin = time.time()\n",
    "    expected_output = {}\n",
    "    for task_id, problem in problems.items():\n",
    "        oracle = {}\n",
    "        oracle[\"base\"], oracle[\"base_time\"] = trusted_exec(\n",
    "            problem[\"prompt\"] + problem[\"canonical_solution\"],\n",
    "            problem[\"base_input\"],\n",
    "            problem[\"entry_point\"],\n",
    "            record_time=True,\n",
    "            output_not_none=problem[\"entry_point\"] in tasks_only_output_not_none,\n",
    "        )\n",
    "\n",
    "        oracle[\"plus\"], oracle[\"plus_time\"] = trusted_exec(\n",
    "            problem[\"prompt\"] + problem[\"canonical_solution\"],\n",
    "            problem[\"plus_input\"],\n",
    "            problem[\"entry_point\"],\n",
    "            record_time=True,\n",
    "            output_not_none=problem[\"entry_point\"] in tasks_only_output_not_none,\n",
    "        )\n",
    "        expected_output[task_id] = oracle\n",
    "    print(f\"Expected outputs computed in {time.time() - tbegin:.2f}s\")\n",
    "\n",
    "    with open('./test.json', \"w\") as f:\n",
    "        json.dump(expected_output, f,indent=4)\n",
    "\n",
    "    return expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_floats(x) -> bool:\n",
    "    # check if it is float; List[float]; Tuple[float]\n",
    "    if isinstance(x, float):\n",
    "        return True\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return all(isinstance(i, float) for i in x)\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.dtype == np.float64 or x.dtype == np.float32\n",
    "    return False\n",
    "\n",
    "\n",
    "def unsafe_execute(\n",
    "    dataset: str,\n",
    "    entry_point: str,\n",
    "    code: str,\n",
    "    inputs,\n",
    "    expected: List,\n",
    "    time_limits,\n",
    "    atol,\n",
    "    fast_check,\n",
    "    stat: Value,\n",
    "    details: Array,\n",
    "    progress: Value,\n",
    "):\n",
    "    with create_tempdir():\n",
    "        # These system calls are needed when cleaning up tempdir.\n",
    "        import os\n",
    "        import shutil\n",
    "\n",
    "        rmtree = shutil.rmtree\n",
    "        rmdir = os.rmdir\n",
    "        chdir = os.chdir\n",
    "        # Disable functionalities that can make destructive changes to the test.\n",
    "        # allow only 4GB memory usage\n",
    "        maximum_memory_bytes = 4 * 1024 * 1024 * 1024\n",
    "        reliability_guard(maximum_memory_bytes=maximum_memory_bytes)\n",
    "        exec_globals = {}\n",
    "        try:\n",
    "            with swallow_io():\n",
    "                exec(code, exec_globals)\n",
    "                fn = exec_globals[entry_point]\n",
    "                for i, inp in enumerate(inputs):\n",
    "                    try:\n",
    "                        with time_limit(time_limits[i]):\n",
    "                            out = fn(*inp)\n",
    "\n",
    "                        exp = expected[i]\n",
    "                        exact_match = out == exp\n",
    "\n",
    "                        # ================================================ #\n",
    "                        # ============== special oracles ================= #\n",
    "                        if dataset == \"mbpp\":\n",
    "                            if (\n",
    "                                \"are_equivalent\" == entry_point\n",
    "                            ):  # Mbpp/164 special oracle\n",
    "                                exact_match = exact_match or True\n",
    "                            elif \"sum_div\" == entry_point:  # Mbpp/295 special oracle\n",
    "                                exact_match = exact_match or out == 0\n",
    "                            elif entry_point in MBPP_OUTPUT_NOT_NONE_TASKS:\n",
    "                                # exp is True  if not None\n",
    "                                #        False if None\n",
    "                                if isinstance(out, bool):\n",
    "                                    exact_match = out == exp\n",
    "                                else:\n",
    "                                    exact_match = exp == (out is not None)\n",
    "\n",
    "                        if dataset == \"humaneval\":\n",
    "                            if \"find_zero\" == entry_point:\n",
    "                                assert _poly(*inp, out) <= atol\n",
    "                        # ============== special oracles ================= #\n",
    "                        # ================================================ #\n",
    "\n",
    "                        if atol == 0 and is_floats(exp):\n",
    "                            atol = 1e-6  # enforce atol for float comparison\n",
    "                        if not exact_match and atol != 0:\n",
    "                            np.testing.assert_allclose(out, exp, atol=atol)\n",
    "                        else:\n",
    "                            assert exact_match\n",
    "                    except BaseException:\n",
    "                        if fast_check:\n",
    "                            raise\n",
    "\n",
    "                        details[i] = False\n",
    "                        progress.value += 1\n",
    "                        continue\n",
    "\n",
    "                    details[i] = True\n",
    "                    progress.value += 1\n",
    "            stat.value = _SUCCESS\n",
    "        except BaseException:\n",
    "            stat.value = _FAILED\n",
    "        # Needed for cleaning up.\n",
    "        shutil.rmtree = rmtree\n",
    "        os.rmdir = rmdir\n",
    "        os.chdir = chdir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eventlet\n",
    "import time\n",
    "from func_timeout import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(code:str,inputs:List,entry_point:str,record_time=True)->List:\n",
    "    env = {}\n",
    "    n = len(inputs)\n",
    "    try:\n",
    "        exec(code,None, env)\n",
    "    except:\n",
    "        if record_time:\n",
    "            return ([\"SyntaxError\"]*n,[(1<<31)-1]*n)\n",
    "        return [\"SyntaxError\"]*n\n",
    "    if entry_point in env:\n",
    "        fn = env[entry_point]\n",
    "    else:\n",
    "        if record_time:\n",
    "            return ([\"NotImplemented\"]*n,[(1<<31)-1]*n)\n",
    "        return [\"NotImplemented\"]*n\n",
    "    @func_set_timeout(1)\n",
    "    def get(inp,record_time:bool=True):\n",
    "        try:\n",
    "            start = time.perf_counter_ns()\n",
    "            ret = fn(*inp)\n",
    "            end = time.perf_counter_ns()\n",
    "            delta = (end-start)//1000_000\n",
    "        except:\n",
    "            ret = \"SyntaxError\"\n",
    "            delta = (1<<31)-1\n",
    "        if isinstance(ret,NotImplemented) or isinstance(ret,NotImplementedError) or str(ret) == str(NotImplemented):\n",
    "            ret = \"NotImplemented\"\n",
    "        if record_time:\n",
    "            return (ret,delta)\n",
    "        return ret\n",
    "        \n",
    "    ret = []\n",
    "    rtime = []\n",
    "    for i,inp in enumerate(inputs):\n",
    "        try:\n",
    "            res,delta = get(inp)\n",
    "            ret.append(res)\n",
    "            rtime.append(delta)\n",
    "        except:\n",
    "            ret.append(\"TimeLimitExceeding\")\n",
    "            rtime.append((1<<31)-1)\n",
    "    del env[entry_point]\n",
    "    if record_time:\n",
    "        return ret,rtime\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codeExecute(file_path:Union[str,Path],dataset:Union[str,Path],exec_save_path:Union[str,Path] = None,is_force_override = False)->None:\n",
    "    \n",
    "    if isinstance(dataset, str):\n",
    "        dataset = Path(dataset)\n",
    "    if dataset.suffix == \".json\":\n",
    "        with open(dataset,'r') as f:\n",
    "            data_origin = json.load(f)\n",
    "    elif dataset.suffix == '.jsonl':\n",
    "        with open(dataset,'r') as f:\n",
    "            # {\"task_id\":{\n",
    "            #     \"task_id\":\"\",\n",
    "            #     \"prompt\":\"\",\n",
    "            #     \"entry_point\":\"\",\n",
    "            #     \"canonical_solution\":\"\",\n",
    "            #     \"base_input\":\"\",\n",
    "            #     \"plus_input\":\"\"\n",
    "            #     }\n",
    "            # }\n",
    "            data_origin = {}\n",
    "            for line in f:\n",
    "                item = json.loads(line)\n",
    "                data_origin[item['task_id']] = item\n",
    "    else:\n",
    "        raise Exception(f\"{dataset.suffix} is not supported\")\n",
    "    \n",
    "    if isinstance(file_path, str):\n",
    "        file_path = Path(file_path)\n",
    "    if file_path.suffix == \".json\":\n",
    "        with open(file_path,'r') as f:\n",
    "            data_eval = json.load(f)\n",
    "    elif file_path.suffix == '.jsonl':\n",
    "        with open(file_path,'r') as f:\n",
    "            # {\"task_id\":\"solution\",}\n",
    "            data_eval = {}\n",
    "            for line in f:\n",
    "                item = json.loads(line)\n",
    "                task_id = item['task_id']\n",
    "                data_eval[task_id] = item['solution'] if 'solution' in item else data_origin[task_id]['prompt']+item['completion']\n",
    "    else:\n",
    "        raise Exception(f\"{file_path.suffix} is not supported\")\n",
    "    \"\"\"\n",
    "        {\n",
    "            \"{{task_id}}\":{\n",
    "                \"info\":{\n",
    "                    \"task_id\":\"{{task_id}}\",\n",
    "                    \"prompt\":\"{{prompt}}\",\n",
    "                    \"entry_point\":\"{{entry_point}}\",\n",
    "                    \"canonical_solution\":\"{{canonical_solution}}\",\n",
    "                    \"base_input\":\"{{base_input}}\",\n",
    "                    \"plus_input\":\"{{plus_input}}\",\n",
    "                },\n",
    "                \"expected_output\":{\n",
    "                    \"base\":\"{{base}}\",\n",
    "                    \"base_time\":\"{{base_time}}\",\n",
    "                    \"plus\":\"{{plus}}\",\n",
    "                    \"plus_time\":\"{{plus_time}}\",\n",
    "                },\n",
    "                \"code_LLM\":\"{{solution}}\",\n",
    "                \"actual_output\":{\n",
    "                    \"base\":\"{{base}}\",\n",
    "                    \"base_time\":\"{{base_time}}\",\n",
    "                    \"plus\":\"{{plus}}\",\n",
    "                    \"plus_time\":\"{{plus_time}}\",\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    output = {}\n",
    "    save = file_path.stem + \"_execute_results.json\"\n",
    "    if not exec_save_path:\n",
    "        parent = file_path.parent\n",
    "    else:\n",
    "        if isinstance(exec_save_path, str):\n",
    "            exec_save_path = Path(exec_save_path)\n",
    "        parent = exec_save_path if os.path.isdir(exec_save_path) else exec_save_path.parent\n",
    "    if os.path.exists(os.path.join(parent,save)) and not is_force_override:\n",
    "        print(\"The executeResults file already exists\")\n",
    "        return\n",
    "    for task_id,problem in data_origin.items():\n",
    "        oracle = {}\n",
    "        oracle[\"base\"], oracle[\"base_time\"] = execute(\n",
    "            problem[\"prompt\"] + problem[\"canonical_solution\"],\n",
    "            problem[\"base_input\"],\n",
    "            problem[\"entry_point\"],\n",
    "            record_time=True,\n",
    "        )\n",
    "        oracle[\"plus\"], oracle[\"plus_time\"] = execute(\n",
    "            problem[\"prompt\"] + problem[\"canonical_solution\"],\n",
    "            problem[\"plus_input\"],\n",
    "            problem[\"entry_point\"],\n",
    "            record_time=True,\n",
    "        )\n",
    "        if task_id not in output:\n",
    "            output[task_id] = {}\n",
    "        output[task_id]['info'] = problem\n",
    "        output[task_id][\"expected_output\"] = oracle\n",
    "    for task_id,solution in data_eval.items():\n",
    "        oracle = {}\n",
    "        oracle[\"base\"], oracle[\"base_time\"] = execute(\n",
    "            solution,\n",
    "            data_origin[task_id][\"base_input\"],\n",
    "            data_origin[task_id][\"entry_point\"],\n",
    "            record_time=True,\n",
    "        )\n",
    "        oracle[\"plus\"], oracle[\"plus_time\"] = execute(\n",
    "            solution,\n",
    "            data_origin[task_id][\"plus_input\"],\n",
    "            data_origin[task_id][\"entry_point\"],\n",
    "            record_time=True,\n",
    "        )\n",
    "        if task_id not in output:\n",
    "            output[task_id] = {}\n",
    "        output[task_id]['code_LLM'] = solution\n",
    "        output[task_id][\"actual_output\"] = oracle\n",
    "    path.append(output)\n",
    "    with open(os.path.join(parent,save), \"w\") as f:\n",
    "        json.dump(output, f, indent=4,)\n",
    "    print(save)\n",
    "def is_floats(x) -> bool:\n",
    "    # check if it is float; List[float]; Tuple[float]\n",
    "    if isinstance(x, float):\n",
    "        return True\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return all(isinstance(i, float) for i in x)\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.dtype == np.float64 or x.dtype == np.float32\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codeEvaluate(exec_file:Union[str,Path],eval_save_path:Union[str,Path] = None,is_force_override:bool = False):\n",
    "    def equal(exp:List,actual:List)->List[bool]:\n",
    "        ret_correct = []\n",
    "        if is_floats(exp):\n",
    "            for i in range(len(exp)):\n",
    "                if isinstance(actual[i],str) or not np.isclose(exp[i],actual[i],atol=1e-5):\n",
    "                    ret_correct.append(False)\n",
    "                else:\n",
    "                    ret_correct.append(True)\n",
    "        else:\n",
    "            for i in range(len(exp)):\n",
    "                if actual in [\"NotImplemented\",\"TimeLimitExceeding\",\"SyntaxError\"] or actual[i]!= exp[i]:\n",
    "                    ret_correct.append(False)\n",
    "                else:\n",
    "                    ret_correct.append(True)\n",
    "        return ret_correct\n",
    "    if isinstance(exec_file, str):\n",
    "        exec_file = Path(exec_file)\n",
    "    if exec_file.suffix != \".json\":\n",
    "        raise Exception(f\"{exec_file.suffix} is not supported\")\n",
    "    with open(exec_file,'r') as f:\n",
    "        data = json.load(f)\n",
    "    if not eval_save_path:\n",
    "        parent = exec_file.parent\n",
    "    else:\n",
    "        if isinstance(eval_save_path,str):\n",
    "            eval_save_path = Path(eval_save_path)\n",
    "        parent = eval_save_path if os.path.isdir(eval_save_path) else eval_save_path.parent\n",
    "            \n",
    "    save = exec_file.stem.replace('_execute_results','') + \"_eval_results.json\"\n",
    "    if os.path.exists(os.path.join(parent,save)) and not is_force_override:\n",
    "        print(\"The evalResults file already exists\")\n",
    "        return \n",
    "    eval_result = {}\n",
    "    \"\"\"\n",
    "        {\n",
    "            \"percision\":{\n",
    "                \"base\":float,\n",
    "                \"plus\":float\n",
    "            },\n",
    "            \"accuracy_list\":{\n",
    "                \"base_accuracy_list\":List[float],\n",
    "                \"plus_accuracy_list\":List[float]\n",
    "            },\n",
    "            \"syntax_error_ratio\":{\n",
    "                \"base\":float,\n",
    "                \"plus\":float\n",
    "            },\n",
    "            \"syntax_error_list\":{\n",
    "                \"base_syntax_error_list\":List[bool],\n",
    "                \"plus_syntax_error_list\":List[bool]\n",
    "            },\n",
    "            \"notImplemented_ratio_list\":List[float],\n",
    "            \"{{task_id}}\":{\n",
    "                \"base_eval\":List[bool],\n",
    "                \"base_num\":int,\n",
    "                \"base_AC\":int,\n",
    "                \"base_TLE\":int,\n",
    "                \"base_accuracy\":float,\n",
    "                \"base_exp_time\":List[time],\n",
    "                \"base_actual_time\":List[time],\n",
    "                \n",
    "                \"plus_eval\":List[bool],\n",
    "                \"plus_num\":int,\n",
    "                \"plus_AC\":int,\n",
    "                \"plus_TLE\":int,\n",
    "                \"plus_accuracy\":float,\n",
    "                \"plus_exp_time\":List[time],\n",
    "                \"plus_actual_time\":List[bool],\n",
    "                \n",
    "                \"accuracy\":float\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    eval_result['percision'] = {'base':0,'plus':0,\"mean\":0}\n",
    "    eval_result['syntax_error_ratio'] = {'base':0,\"plus\":0,\"mean\":0}\n",
    "    base_accuracy_list = []\n",
    "    plus_accuracy_list = []\n",
    "    accuracy_list = {\"base_accuracy_list\":base_accuracy_list,\"plus_accuracy_list\":plus_accuracy_list}\n",
    "    eval_result['accuracy_list'] = accuracy_list\n",
    "    base_syntax_error_list = []\n",
    "    plus_syntax_error_list = []\n",
    "    eval_result['syntax_error_list'] ={ \"base_syntax_error_list\":base_syntax_error_list,\"plus_syntax_error_list\":plus_syntax_error_list}\n",
    "    notImplemented_list = []\n",
    "    eval_result['notImplemented_ratio_list'] = notImplemented_list\n",
    "    \n",
    "    for task_id,eval in data.items():\n",
    "        oracle = {}\n",
    "        base_exp = eval['expected_output']['base']\n",
    "        base_actual = eval['actual_output']['base']\n",
    "        base_correct = equal(base_exp, base_actual)\n",
    "        \n",
    "        oracle['base_num'] = len(base_correct)\n",
    "        oracle['base_AC'] = sum(base_correct)\n",
    "        oracle['base_TLE'] = base_actual.count(\"TimeLimitExceeding\")\n",
    "        oracle['base_SE'] = base_actual.count(\"SyntaxError\")\n",
    "        oracle['base_NoImplemented'] = base_actual.count(\"NotImplemented\")\n",
    "        oracle['base_accuracy'] = np.mean(base_correct)\n",
    "        base_accuracy_list.append(oracle['base_accuracy'])\n",
    "        base_syntax_error_list.append(oracle['base_SE']/oracle['base_num'])\n",
    "        \n",
    "        plus_exp = eval['expected_output']['plus']\n",
    "        plus_actual = eval['actual_output']['plus']\n",
    "        plus_correct = equal(plus_exp,plus_actual)\n",
    "        \n",
    "        oracle['plus_num'] = len(plus_correct)\n",
    "        oracle['plus_AC'] = sum(plus_correct)\n",
    "        oracle['plus_TLE'] = plus_actual.count(\"TimeLimitExceeding\")\n",
    "        oracle['plus_SE'] = plus_actual.count(\"SyntaxError\")\n",
    "        oracle['plus_NoImplemented'] = plus_actual.count(\"NotImplemented\")\n",
    "        oracle['plus_accuracy'] = np.mean(plus_correct)\n",
    "        plus_accuracy_list.append(oracle['plus_accuracy'])\n",
    "        plus_syntax_error_list.append(oracle['plus_SE']/oracle['plus_num'])\n",
    "        \n",
    "        oracle['accuracy'] = np.mean(base_correct+plus_correct)\n",
    "        \n",
    "        \n",
    "        oracle['base_exp_time'] = eval['expected_output']['base_time']\n",
    "        oracle['base_actual_time'] = eval['actual_output']['base_time']\n",
    "        oracle['plus_exp_time'] = eval['expected_output']['plus_time']\n",
    "        oracle['plus_actual_time'] = eval['actual_output']['plus_time']\n",
    "        \n",
    "        notImplemented_list.append((oracle['base_NoImplemented']+oracle['plus_NoImplemented'])/(oracle['base_num']+oracle['plus_num']))\n",
    "        \n",
    "        eval_result[task_id] = oracle\n",
    "    eval_result['percision']['base'] = np.mean(base_accuracy_list)\n",
    "    eval_result['percision']['plus'] = np.mean(plus_accuracy_list)\n",
    "    eval_result['percision']['mean'] = np.mean(base_accuracy_list+plus_accuracy_list)\n",
    "    eval_result['syntax_error_ratio']['base'] = np.mean(base_syntax_error_list)\n",
    "    eval_result['syntax_error_ratio']['plus'] = np.mean(plus_syntax_error_list)\n",
    "    eval_result['syntax_error_ratio']['mean'] = np.mean(base_syntax_error_list+plus_syntax_error_list)\n",
    "    \n",
    "    with open(os.path.join(parent,save), \"w\") as f:\n",
    "        json.dump(eval_result, f, indent=4,)\n",
    "    print(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baichuan2-13b-base_execute_results.json\n",
      "baichuan2-13b-base_eval_results.json\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "baichuan2-13b-chat_execute_results.json\n",
      "baichuan2-13b-chat_eval_results.json\n",
      "baichuan2-7b-chat_execute_results.json\n",
      "baichuan2-7b-chat_eval_results.json\n",
      "infini-megrez-7b_execute_results.json\n",
      "infini-megrez-7b_eval_results.json\n",
      "llama-2-13b-chat_execute_results.json\n",
      "llama-2-13b-chat_eval_results.json\n",
      "llama-2-70b_execute_results.json\n",
      "llama-2-70b_eval_results.json\n",
      "llama-2-7b-chat_execute_results.json\n",
      "llama-2-7b-chat_eval_results.json\n",
      "qwen-14b-chat_execute_results.json\n",
      "qwen-14b-chat_eval_results.json\n",
      "qwen-72b-chat_execute_results.json\n",
      "qwen-72b-chat_eval_results.json\n",
      "qwen-72b_execute_results.json\n",
      "qwen-72b_eval_results.json\n",
      "qwen-7b-chat_execute_results.json\n",
      "qwen-7b-chat_eval_results.json\n",
      "qwen1.5-14b-chat_execute_results.json\n",
      "qwen1.5-14b-chat_eval_results.json\n",
      "qwen1.5-72b_execute_results.json\n",
      "qwen1.5-72b_eval_results.json\n",
      "qwen1.5-7b-chat_execute_results.json\n",
      "qwen1.5-7b-chat_eval_results.json\n"
     ]
    }
   ],
   "source": [
    "for dir,subdir,files in os.walk('./data/codeEval/code_sanitize'):\n",
    "    for file in files:\n",
    "        if file.endswith('.jsonl'):\n",
    "            codeExecute(os.path.join(dir,file),\"./data/codeEval/data.json\",exec_save_path = './data/codeEval/code_execute',is_force_override=True)\n",
    "            codeEvaluate(os.path.join('./data/codeEval/code_execute',file.replace(\".jsonl\",\"_execute_results.json\")),eval_save_path = './data/codeEval/code_eval',is_force_override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NotImplementedType"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[0]['HumanEval/54']['actual_output']['plus'][9].__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NotImplementedType"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path[0]['HumanEval/54']['actual_output']['plus'][9].__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,1,2,1].count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = {}\n",
    "exec(\"def sum_to_n(n):    return sum(range(1,n+1))\",None,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sum_to_n': <function __main__.sum_to_n(n)>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
